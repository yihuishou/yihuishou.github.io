{"meta":{"title":"骑士の物语","subtitle":null,"description":null,"author":"挥手の骑士","url":"https://yihuishou.github.io","root":"/"},"pages":[{"title":"关于我","text":"","path":"about/index.html","date":"10-15","excerpt":""},{"title":"分类","text":"","path":"categories/index.html","date":"10-15","excerpt":""},{"title":"search","text":"","path":"search/index.html","date":"10-10","excerpt":""},{"title":"标签","text":"","path":"tags/index.html","date":"10-15","excerpt":""}],"posts":[{"title":"","text":"title： Vorze SA 蓝牙协议(Cyclone A10 SA， UFO SA)export_md： falsetags： 随笔abbrlink： 865424390date： 2019-01-04 10：31：56 Vorze SA Series (Cyclone A10 SA， UFO SA)简介Vorze SA系列是Rends Vorze系列玩具的蓝牙版本。 Vorze Cyclone SA它由一个可拆卸的滚筒组成，可以容纳一系列不同纹理的内胆。 UFO SA它有两个带有旋转元件的罩杯组成，可以连接不同纹理的刺激装置。 两者都允许通过蓝牙来控制硬件的旋转方向和速度。 设备识别由于设备共享类似BLE GATT服务ID，因此可以使用其BLE设备名称进行识别。 对于Cyclone SA，蓝牙设备名称是CycSA 对于UFO SA，蓝牙设备名称是UFOSA 蓝牙细节Vorze玩具使用蓝牙BLE与其他机器进行通信。 使用下面的服务UUID 40ee1111-63ec-4b7f-8ce7-712efd55b90e 使用下面的写入数据特征UUID 40ee2222-63ec-4b7f-8ce7-712efd55b90e USB无线发射器Vorze玩具配有USB无线发射器，可以使用BTLE连接来模拟Windows上的串行端口。 这使得玩具可以轻松地用在所有没有BTLE功能的操作系统上，例如Windows XP/7/8、OS X &lt; 10.6或带有Bluez &lt; 5.28的Linux等系统上。 与内置的蓝牙通讯不同，USB无线发射器的串行端口设置似乎对此无线发射器工作非常重要。 串口通信必须以19200波特 8/N/1运行 且无流量控制的方式来运行 使用任何其他波特率都会导致错误，并会导致机器需要重新上电才可恢复。 协议要与Vorze设备进行硬件通信只需要使用简单的单向协议即可。 每个数据包由以下格式的3个字节组成： 0x01 0x01 0xe4 代表的意义是 设备ID字节 保留字节 方向和速度字节 蓝牙通讯协议传输上面的三个字节组成的数组作为一个完整的数据包 设备ID字节在上面的例子中表示为0x01的16进制字节为设备ID 其定义如下： 设备名称 设备ID字节 Cyclone SA 0x01 UFO SA 0x02 PISTON SA 0x03 Bach Smart 0x00 保留字节对于所有Vorze玩具，已经观察到保留字节总是为0x01。 该保留字节是为Bach Smart振动器所使用的，其他设备都会使用0x01。 方向和速度字节在上面的例子中表示为0xe4的字节控制硬件的速度和方向。 方向由字节的首位指定。0表示顺时针转动，1表示逆时针转动。 速度由第3个字节的7个剩余位指定。 0-100的速度变化范围，所有速度设置大于100的参数都将被机器忽略。 例如： 要将Cyclone SA设备ID(字节1：0x01)设置为以50%速度顺时针旋转(字节3：(通过16进制位运算：0x00 &lt;&lt; 7 | 0x32得到0x32)，最终发送的数据包： 0x01 0x01 0x32 要将UFO SA设备ID(字节1：0x02)以100%速度逆时针旋转(字节3：(通过16进制位运算：0x01 &lt;&lt; 7 | 0x64得到0xe4)，最终发送的数据包： 0x02 0x01 0xe4 超过100的速度将被忽略，因此，如果在数据包之后发送了下面的数据包 0x02 0x01 0xef 则玩具将以100%的速度继续旋转，该数据包将被忽略。 对于从CSV文件中读取的十进制数值也可先直接进行位运算再转为16进制数据 1 &lt;&lt; 7 | 100 -&gt; 得到228 228转16进制 -&gt; 得到0xe4 CSV控制文件说明 控制文件为CSV格式。 每行代表一个控制信息，每个字段用英文逗号分割，换行结束。 每行从左至右共三个字段。 第一个字段为脚本执行动作时间，单位为 0.1 秒 例如：第10秒 100 在玩具未收到下一个数据包之前，玩具将一直执行上一个数据包中的内容 第二个字段为玩具旋转方向，0 顺时针转动，1 逆时针转动 第三个字段为玩具驱动力度，理论范围 0 （关闭）- 100 （最大） 对于SA设备来说，驱动力度小于45则驱动力过低，无法正常工作 蓝牙未收到新的数据包前会持续执行上一个数据包中的内容， 由于蓝牙通信延迟，CSV中过短的脚本时间间隔可能会产生问题。 例如： 10,0,5018,0,020,0,50 会被一直执行10,0,50 过短的时间间隔似乎也会对驱动造成影响 例如： 10,0,5015,0,0 则收到指令后不会转动 SA 设备按键的默认七档速度表 档位 数值 0 0 1 42 2 50 3 60 4 68 5 78 6 88 7 100","path":"2020/10/10/2/","date":"10-10","excerpt":"","tags":[]},{"title":"Agent v3.2.1 插件激活码","text":"插件激活码BJ39MB9JHE-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-pMQbCSc0jQ19zic5o5/rx3BXFemJxx5hDzNgYFCeW4kD3lqCQX//GWJKis/qnJ89Fdk27Og6BbqpbP82eFFGOhB6SWy/Icg21o6zd9EEgRtt7XQq8lHqg4d+i60aMJb7XfzEbz27uqVDNJ8zqAx+JLPMFGwM7PSO0IepIx96j14q2mkFz91z+KuPoTfZIroMJe+0VE/b6T5DeSYvHX1F9+gg98QcKKXYH8QcGMU33iqWlLuGJ0MF5IEn2l+zRt05e6oxuXoGRmlHygtsC4SgRSsomjVvs26ssiiH6qLrX7OZ6dyoYc4i+TFlRoFCqLeO9RMEhBSnXzWw6/icVh/w0g==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g== 本体激活码KNBB2QUUR1-eyJsaWNlbnNlSWQiOiJLTkJCMlFVVVIxIiwibGljZW5zZWVOYW1lIjoiZ2hib2tlIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IiIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiQUMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRFBOIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBTIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRNIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkNMIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJTMCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSTSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJXUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSU1UiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiMTI3OTY4NzcvMCIsImdyYWNlUGVyaW9kRGF5cyI6NywiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-1iV7BA/baNqv0Q5yUnAphUmh66QhkDRX+qPL09ICuEicBqiPOBxmVLLCVUpkxhrNyfmOtat2LcHwcX/NHkYXdoW+6aS0S388xe1PV2oodiPBhFlEaOac42UQLgP4EidfGQSvKwC9tR1zL5b2CJPQKZ7iiHh/iKBQxP6OBMUP1T7j3Fe1rlxfYPc92HRZf6cO+C0+buJP5ERZkyIn5ZrVM4TEnWrRHbpL8SVNq4yqfc+NwoRzRSNC++81VDS3AXv9c91YeZJz6JXO7AokIk54wltr42FLNuKbozvB/HCxV9PA5vIiM+kZY1K0w5ytgxEYKqA87adA7R5xL/crpaMxHQ==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g== A82DEE284F-eyJsaWNlbnNlSWQiOiJBODJERUUyODRGIiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiJVbmxpbWl0ZWQgbGljZW5zZSB0aWxsIGVuZCBvZiB0aGUgY2VudHVyeS4iLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJNIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRE0iLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUFMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiODkwNzA3MC8wIiwiZ3JhY2VQZXJpb2REYXlzIjowLCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-5epo90Xs7KIIBb8ckoxnB/AZQ8Ev7rFrNqwFhBAsQYsQyhvqf1FcYdmlecFWJBHSWZU9b41kvsN4bwAHT5PiznOTmfvGv1MuOzMO0VOXZlc+edepemgpt+t3GUHvfGtzWFYeKeyCk+CLA9BqUzHRTgl2uBoIMNqh5izlDmejIwUHLl39QOyzHiTYNehnVN7GW5+QUeimTr/koVUgK8xofu59Tv8rcdiwIXwTo71LcU2z2P+T3R81fwKkt34evy7kRch4NIQUQUno//Pl3V0rInm3B2oFq9YBygPUdBUbdH/KHROyohZRD8SaZJO6kUT0BNvtDPKF4mCT1saWM38jkw==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g== 3AGXEJXFK9-eyJsaWNlbnNlSWQiOiIzQUdYRUpYRks5IiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkFDIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJQUyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJHTyIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJETSIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsImZhbGxiYWNrRGF0ZSI6IjIwODktMDctMDciLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSUzAiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUkQiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUEMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUk0iLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREIiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJmYWxsYmFja0RhdGUiOiIyMDg5LTA3LTA3IiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwiZmFsbGJhY2tEYXRlIjoiMjA4OS0wNy0wNyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9XSwiaGFzaCI6IjEyNzk2ODc3LzAiLCJncmFjZVBlcmlvZERheXMiOjcsImF1dG9Qcm9sb25nYXRlZCI6ZmFsc2UsImlzQXV0b1Byb2xvbmdhdGVkIjpmYWxzZX0=-WGTHs6XpDhr+uumvbwQPOdlxWnQwgnGaL4eRnlpGKApEEkJyYvNEuPWBSrQkPmVpim/8Sab6HV04Dw3IzkJT0yTc29sPEXBf69+7y6Jv718FaJu4MWfsAk/ZGtNIUOczUQ0iGKKnSSsfQ/3UoMv0q/yJcfvj+me5Zd/gfaisCCMUaGjB/lWIPpEPzblDtVJbRexB1MALrLCEoDv3ujcPAZ7xWb54DiZwjYhQvQ+CvpNNF2jeTku7lbm5v+BoDsdeRq7YBt9ANLUKPr2DahcaZ4gctpHZXhG96IyKx232jYq9jQrFDbQMtVr3E+GsCekMEWSD//dLT+HuZdc1sAIYrw==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA5ndaik1GD0nyTdqkZgURQZGW+RGxCdBITPXIwpjhhaD0SXGa4XSZBEBoiPdY6XV6pOfUJeyfi9dXsY4MmT0D+sKoST3rSw96xaf9FXPvOjn4prMTdj3Ji3CyQrGWeQU2nzYqFrp1QYNLAbaViHRKuJrYHI6GCvqCbJe0LQ8qqUiVMA9wG/PQwScpNmTF9Kp2Iej+Z5OUxF33zzm+vg/nYV31HLF7fJUAplI/1nM+ZG8K+AXWgYKChtknl3sW9PCQa3a3imPL9GVToUNxc0wcuTil8mqveWcSQCHYxsIaUajWLpFzoO2AhK4mfYBSStAqEjoXRTuj17mo8Q6M2SHOcwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQBonMu8oa3vmNAa4RQP8gPGlX3SQaA3WCRUAj6Zrlk8AesKV1YSkh5D2l+yUk6njysgzfr1bIR5xF8eup5xXc4/G7NtVYRSMvrd6rfQcHOyK5UFJLm+8utmyMIDrZOzLQuTsT8NxFpbCVCfV5wNRu4rChrCuArYVGaKbmp9ymkw1PU6+HoO5i2wU3ikTmRv8IRjrlSStyNzXpnPTwt7bja19ousk56r40SmlmC04GdDHErr0ei2UbjUua5kw71Qn9g02tL9fERI2sSRjQrvPbn9INwRWl5+k05mlKekbtbu2ev2woJFZK4WEXAd/GaAdeZZdumv8T2idDFL7cAirJwcrbfpawPeXr52oKTPnXfi0l5+g9Gnt/wfiXCrPElX6ycTR6iL3GC2VR4jTz6YatT4Ntz59/THOT7NJQhr6AyLkhhJCdkzE2cob/KouVp4ivV7Q3Fc6HX7eepHAAF/DpxwgOrg9smX6coXLgfp0b1RU2u/tUNID04rpNxTMueTtrT8WSskqvaJd3RH8r7cnRj6Y2hltkja82HlpDURDxDTRvv+krbwMr26SB/40BjpMUrDRCeKuiBahC0DCoU/4+ze1l94wVUhdkCfL0GpJrMSCDEK+XEurU18Hb7WT+ThXbkdl6VpFdHsRvqAnhR2g4b+Qzgidmuky5NUZVfEaZqV/g==","path":"2020/08/18/55226946/","date":"08-18","excerpt":"","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yihuishou.github.io/tags/IDEA/"}]},{"title":"干掉 CMS 未来属于 ZGC","text":"JAVA程序最爽的地方是它的GC机制，开发人员不需要关注内存申请和回收问题。同时，JAVA程序最头疼的地方也是它的GC机制，因为掌握JVM和GC调优是一件非常困难的事情。在ParallelOldGC、CMS、G1之后，JDK11带来的全新的「ZGC」为我们解决了什么问题？Oracle官方介绍它是一个Scalable、Low Latency的垃圾回收器。所以它的目的是「降低停顿时间」，由此会导致吞吐量会有所降低。吞吐量降低问题不大，横向扩展几台服务器就能解决问题了啦。 ZGC目标 如下图所示，ZGC的目标主要有4个： 支持TB量级的堆。这你受得了吗？我们生产环境的硬盘还没有上TB呢，这应该可以满足未来十年内，所有JAVA应用的需求了吧。 最大GC停顿时间不超10ms。这你受得了吗？目前一般线上环境运行良好的JAVA应用Minor GC停顿时间在10ms左右，Major GC一般都需要100ms以上（G1可以调节停顿时间，但是如果调的过低的话，反而会适得其反），之所以能做到这一点是因为它的停顿时间主要跟Root扫描有关，而Root数量和堆大小是没有任何关系的。 奠定未来GC特性的基础。牛逼，牛逼！ 最糟糕的情况下吞吐量会降低15%。这都不是事，停顿时间足够优秀。至于吞吐量，通过扩容分分钟解决。 另外，Oracle官方提到了它最大的优点是：它的停顿时间不会随着堆的增大而增长！也就是说，几十G堆的停顿时间是10ms以下，几百G甚至上T堆的停顿时间也是10ms以下。 ZGC概述 接下来从几个维度概述一下ZGC。 New GCSingle GenerationRegion BasedPartial CompactionNUMA-awareColored PointersLoad BarriersZGC tuningChange LogNew GC ZGC是一个全新的垃圾回收器，它完全不同以往HotSpot的任何垃圾回收器，比如：PS、CMS、G1等。如果真要说它最像谁的话，那应该是Azul公司的商业化垃圾回收器：「C4」，ZGC所采用的算法就是Azul Systems很多年前提出的Pauseless GC，而实现上它介于早期Azul VM的Pauseless GC与后来Zing VM的C4之间。不过需要说明的是，JDK11中ZGC只能运行在Linux64操作系统之上。JDK14新增支持了MacOS和Window平台： 如下图所示，是ZGC和Parallel以及G1的压测对比结果（CMS在JDK9中已经被标记deprecated，更高版本中已经被彻底移除，所以不在对比范围内）。我们可以明显的看到，停顿时间方面，ZGC是100%不超过10ms的，简直是秒天秒地般的存在： 接下来，再看一下ZGC的垃圾回收过程，如下图所示。由图我们可知，ZGC依然没有做到整个GC过程完全并发执行，依然有3个STW阶段，其他3个阶段都是并发执行阶段： Pause Mark Start 这一步就是初始化标记，和CMS以及G1一样，主要做Root集合扫描，「GC Root是一组必须活跃的引用，而不是对象」。例如：活跃的栈帧里指向GC堆中的对象引用、Bootstrap/System类加载器加载的类、JNI Handles、引用类型的静态变量、String常量池里面的引用、线程栈/本地(native)栈里面的对象指针等，但不包括GC堆里的对象指针。所以这一步骤的STW时间非常短暂，并且和堆大小没有任何关系。不过会根据线程的多少、线程栈的大小之类的而变化。 Concurrent Mark/Remap 第二步就是并发标记阶段，这个阶段在第一步的基础上，继续往下标记存活的对象。并发标记后，还会有一个短暂的暂停（Pause Mark End），确保所有对象都被标记。 Concurrent Prepare for Relocate 即为Relocation阶段做准备，选取接下来需要标记整理的Region集合，这个阶段也是并发执行的。接下来又会有一个Pause Relocate Start步骤，它的作用是只移动Root集合对象引用，所以这个STW阶段也不会停顿太长时间。 Concurrent Relocate 最后，就是并发回收阶段了，这个阶段会把上一阶段选中的需要整理的Region集合中存活的对象移到一个新的Region中（这个行为就叫做「Relocate」，即重新安置对象），如上图所示。Relocate动作完成后，原来占用的Region就能马上回收并被用于接下来的对象分配。细心的同学可能有疑问了，这就完了？Relocate后对象地址都发生变化了，应用程序还怎么正常操作这些对象呢？这就靠接下来会详细说明的Load Barrier了。 Single Generation 单代，即ZGC「没有分代」。我们知道以前的垃圾回收器之所以分代，是因为源于“「大部分对象朝生夕死」”的假设，事实上大部分系统的对象分配行为也确实符合这个假设。 那么为什么ZGC就不分代呢？因为分代实现起来麻烦，作者就先实现出一个比较简单可用的单代版本。用符合我们国情的话来解释，大概就是说：工作量太大了，人力又不够，老板，先上个1.0版本吧！！！ Region Based 这一点和G1一样，都是基于Region设计的垃圾回收器，ZGC中的Region也被称为「ZPages」，ZPages被动态创建，动态销毁。不过，和G1稍微有点不同的是，G1的每个Region大小是完全一样的，而ZGC的Region大小分为3类：2MB，32MB，N×2MB，如此一来，灵活性就更好了： Partial Compaction 部分压缩，这一点也很G1类似。以前的ParallelOldGC，以及CMS GC在压缩Old区的时候，无论Old区有多大，必须整体进行压缩（CMS GC默认情况下只是标记清除，只会发生FGC时才会采用Mark-Sweep-Compact对Old区进行压缩），如此一来，Old区越大，压缩需要的时间肯定就越长，从而导致停顿时间就越长。 而G1和ZGC都是基于Region设计的，在回收的时候，它们只会选择一部分Region进行回收，这个回收过程采用的是Mark-Compact算法，即将待回收的Region中存活的对象拷贝到一个全新的Region中，这个新的Region对象分配就会非常紧凑，几乎没有碎片。垃圾回收算法这一点上，和G1是一样的。 NUMA-aware NUMA对应的有UMA，UMA即Uniform Memory Access Architecture，NUMA就是Non Uniform Memory Access Architecture。UMA表示内存只有一块，所有CPU都去访问这一块内存，那么就会存在竞争问题（争夺内存总线访问权），有竞争就会有锁，有锁效率就会受到影响，而且CPU核心数越多，竞争就越激烈。NUMA的话每个CPU对应有一块内存，且这块内存在主板上离这个CPU是最近的，每个CPU优先访问这块内存，那效率自然就提高了： 服务器的NUMA架构在中大型系统上一直非常盛行，也是高性能的解决方案，尤其在系统延迟方面表现都很优秀。ZGC是能自动感知NUMA架构并充分利用NUMA架构特性的。 Colored Pointers Colored Pointers，即颜色指针是什么呢？如下图所示，ZGC的核心设计之一。以前的垃圾回收器的GC信息都保存在对象头中，而ZGC的GC信息保存在指针中。每个对象有一个64位指针，这64位被分为： 18位：预留给以后使用；1位：Finalizable标识，次位与并发引用处理有关，它表示这个对象只能通过finalizer才能访问；1位：Remapped标识，设置此位的值后，对象未指向relocation set中（relocation set表示需要GC的Region集合）；1位：Marked1标识；1位：Marked0标识，和上面的Marked1都是标记对象用于辅助GC；42位：对象的地址（所以它可以支持2^42=4T内存）： 通过对配置ZGC后对象指针分析我们可知，对象指针必须是64位，那么ZGC就无法支持32位操作系统，同样的也就无法支持压缩指针了（CompressedOops，压缩指针也是32位）。 Load Barriers 这个应该翻译成读屏障（与之对应的有写屏障即Write Barrier，之前的GC都是采用Write Barrier，这次ZGC采用了完全不同的方案），这个是ZGC一个非常重要的特性。在标记和移动对象的阶段，每次「从堆里对象的引用类型中读取一个指针」的时候，都需要加上一个Load Barriers。那么我们该如何理解它呢？看下面的代码，第一行代码我们尝试读取堆中的一个对象引用obj.fieldA并赋给引用o（fieldA也是一个对象时才会加上读屏障）。如果这时候对象在GC时被移动了，接下来JVM就会加上一个读屏障，这个屏障会把读出的指针更新到对象的新地址上，并且把堆里的这个指针“修正”到原本的字段里。这样就算GC把对象移动了，读屏障也会发现并修正指针，于是应用代码就永远都会持有更新后的有效指针，而且不需要STW。那么，JVM是如何判断对象被移动过呢？就是利用上面提到的颜色指针，如果指针是Bad Color，那么程序还不能往下执行，需要「slow path」，修正指针；如果指针是Good Color，那么正常往下执行即可： ❝ 这个动作是不是非常像JDK并发中用到的CAS自旋？读取的值发现已经失效了，需要重新读取。而ZGC这里是之前持有的指针由于GC后失效了，需要通过读屏障修正指针。❞ 后面3行代码都不需要加读屏障：Object p = o这行代码并没有从堆中读取数据；o.doSomething()也没有从堆中读取数据；obj.fieldB不是对象引用，而是原子类型。 正是因为Load Barriers的存在，所以会导致配置ZGC的应用的吞吐量会变低。官方的测试数据是需要多出额外4%的开销： 那么，判断对象是Bad Color还是Good Color的依据是什么呢？就是根据上一段提到的Colored Pointers的4个颜色位。当加上读屏障时，根据对象指针中这4位的信息，就能知道当前对象是Bad/Good Color了。 ❝ 「扩展阅读」：既然低42位指针可以支持4T内存，那么能否通过预约更多位给对象地址来达到支持更大内存的目的呢？答案肯定是不可以。因为目前主板地址总线最宽只有48bit，4位是颜色位，就只剩44位了，所以受限于目前的硬件，ZGC最大只能支持16T的内存，JDK13就把最大支持堆内存从4T扩大到了16T。❞ ZGC tuning 启用ZGC比较简单，设置JVM参数即可：-XX:+UnlockExperimentalVMOptions 「-XX:+UseZGC」。调优也并不难，因为ZGC调优参数并不多，远不像CMS那么复杂。它和G1一样，可以调优的参数都比较少，大部分工作JVM能很好的自动完成。下图所示是ZGC可以调优的参数： 下面对部分参数进行更加详细的说明。 UseNUMA ZGC默认是开启支持NUMA的，不过，如果JVM探测到系统绑定的是CPU子集，就会自动禁用NUMA。我们可以通过参数-XX:+UseNUMA显示启动，或者通过参数-XX:-UseNUMA显示禁用。如果运行在NUMA服务器上，并且设置-XX:+UseNUMA，那对性能提升是显而易见的。 UseLargePages配置ZGC使用large page通常就会得到更好的性能，比如在吞吐量、延迟、启动时间等方面。而且没有明显的缺点，除了配置过程复杂一点。因为它需要root权限，这也是默认并没有开启使用large page的原因。 ConcGCThreadsZGC是一个并发垃圾收集器，那么并发GC线程数就非常重要了。如果设置并发GC线程数越多，意味着应用线程数就会越少，这肯定是非常不利于应用系统稳定运行的。这个参数ZGC能自动设置，如果没有十足的把握。最好不要设置这个参数。 ParallelGCThreads这是个并行线程数，与上一个参数ConcGCThreads有所不同，ConcGCThreads表示GC线程和应用线程「并发」执行时GC线程数量。而ParallelGCThreads表示GC时STW阶段的「并行」GC线程数量（例如第一阶段的Root扫描），这时候只有GC线程，没有应用线程。笔者这里解释了JVM中「并发和并行的区别」，也是JVM中比较容易理解错误的地方。 ZUncommit 掌握这个参数之前，我们先说一下JVM申请以及回收内存的行为。以前的垃圾回收器比如ParallelOldGC和CMS，只要JVM申请过的内存，即使发生了GC回收了很多内存空间，JVM也不会把这些内存归还给操作系统。这就会导致top命令中看到的RSS只会越来越高，而且一般都会超过Xmx的值（参考文章：）。 不过，默认情况下，ZGC是会把不再使用的内存归还给操作系统的。这对于那些比较注意内存占用情况的应用和服务器来说，是很有用的。这种行为可以通过JVM参数-XX:-ZUncommit关闭。不过，无论怎么归还，JVM至少会保留Xms参数指定的内存大小，这就是说，当Xmx和Xms一样大的时候，这个参数就不起作用了。 和这个参数一起起作用的还有另一个参数：-「XX:ZUncommitDelay=sec」，默认300秒。这个参数表示不再使用的内存最多延迟多长时间才会被归还给操作系统。因为不再使用的内存不应该立即归还给操作系统，这样会造成频繁的归还和申请行为，所以通过这个参数来控制不再使用的内存需要经过多久的时间才归还给操作系统。","path":"2020/07/21/2412014068/","date":"07-21","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"OpenJDK 和 OracleJDK 的抉择","text":"根据 Oracle 官方的说法（Oracle JDK Releases for Java 11 and Later） 在 Java 11 之后，OracleJDK 和 OpenJDK 的功能基本一致，之前 OracleJDK 中的私有组件大多数也已经被捐赠给开源组织，现在它们之间只有少量的区别。 要比哪个更稳定，OpenJDK 实际上不适合拿来和 OracleJDK 进行对比 OpenJDK 不提供 LTS 服务，而 OracleJDK 每三年都会推出一个 LTS 版进行长期支持。 和 OracleJDK 对比的应该是 AdoptOpenJDK、Zulu、Red Hat OpenJDK 以及 Liberica JDK，它们都是基于 OpenJDK 的发行版， 由不同的商业公司提供商业支持，包括和 OracleJDK 周期相同的 LTS 版。 与这些 OpenJDK 的发行版相比，OracleJDK 并没有本质差异，稳定性也是智者见智仁者见仁的，差异并不大。 相比之下，现在更推荐选择一个 OpenJDK 的发行版使用，而不是选择 OracleJDK： OracleJDK 和这些 OpenJDK 发行版功能基本一致，背后同样有公司提供商业支持，稳定性也难分优劣，Red Hat OpenJDK、Zulu 和 Liberica JDK 都通过了 TCK OracleJDK 修改了协议，除了 开发、测试以及演示用途，其他场合都是要收费的（参见我的这个答案）， 而 Zulu、AdoptOpenJDK 和 Liberica JDK 都提供适用于各种用途的免费版本，并提供 LTS 服务，只有在需要商业支持的时候需要付费 OracleJDK 对一般用户友善程度也不是最高的，新版不再捆绑 JavaFX，同时不提供 32 位构建 现在我最推荐开发者和一般用户使用的是 Liberica JDK​它提供了捆绑 JavaFX 的 full 版，支持 macOS x86_64、Windows x86、Windows x86_64、 Linux x86、Linux x86_64、Alpine Linux x86_64、Linux ARMv8、Linux ARMv7 HardFloat、 Linux PPC64 LE 等平台，对于需要 32 位环境或者需要在小众平台上工作的用户来说很友好。同时它的 exe 安装包能够方便的配置环境变量， 还提供 YUM 和 APT 仓库，提供 Docker 镜像，目前来说应该是对一般用户最友好的 OpenJDK 发行版。 两者主要区别： 授权协议不同：OpenJDK采用GPL V2协议放出，而SUN JDK则采用JRL放出。 两者协议虽然都是开放源代码的，但是在使用上的不同在于GPL V2允许在商业上使用，而JRL只允许个人研究使用。 功能结构不同：OpenJDK源代码不完整，这个很容易想到，在采用GPL协议的OpenJDK中，SUN JDK的一部分源代码因为产权的问题无法开放给OpenJDK使用， 其中最主要的部份就是JMX中的可选元件SNMP部份的代码。因此这些不能开放的源代码 将它作成plug，以供OpenJDK编译时使用，你也可以选择不要使用plug。而Icedtea则为这些不完整的部分开发了相同功能的源代码 (OpenJDK6)，促使OpenJDK更加完整。 部分源代码用开源代码替换：由于产权的问题，很多产权不是SUN的源代码被替换成一些功能相同的开源代码，比如说字体栅格化引擎，使用Free Type代替。 OpenJDK不包含Deployment（部署）功能：Browser Plugin、Java Web Start、以及Java控制面板，这些功能在OpenJDK中是找不到的。 OpenIDK只包含最精简的JDK：OpenJDK不包含其他的软件包，比如Rhino Java DB JAXP等等，并且可以分离的软件包也都是尽量的分离，但是这大多数都是自由软件，你可以自己下载加入。 商标权：这个很容易理解，在安装OpenJDK的机器上，输入“java -version”显示的是OpenJDK，但是如果是使用Icedtea补丁的OpenJDK，显示的是java。","path":"2020/07/21/4075219928/","date":"07-21","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Flutter 音乐播放器开发之路（一）","text":"Dart 播放器插件陈旧坑 Song.class 缺少属性导致启动失败 flute_music_player 0.0.6 版本 需要修改库文件 修正的 class 缺少的属性 class Song &#123; static final Columns=[\"id\",\"artist\", \"title\", \"album\", \"albumId\", \"duration\", \"uri\", \"albumArt\",\"count\",\"isFav\",\"timestamp\"]; int id; String artist; String title; String album; int albumId; int duration; String uri; String albumArt; int count; int timestamp; int isFav; Song(this.id, this.artist, this.title, this.album, this.albumId, this.duration, this.uri, this.albumArt); Song.fromMap(Map m) &#123; id = m[\"id\"]; artist = m[\"artist\"]; title = m[\"title\"]; album = m[\"album\"]; albumId = m[\"albumId\"]; duration = m[\"duration\"]; uri = m[\"uri\"]; albumArt = m[\"albumArt\"]; &#125; Map&lt;String, dynamic&gt; toMap() &#123; Map params = &lt;String, dynamic&gt;&#123; \"id\": id, \"artist\": artist, \"title\": title, \"album\": album, \"albumId\": albumId, \"duration\": duration, \"uri\": uri, \"albumArt\": albumArt, \"count\": count, \"timestamp\": timestamp, \"isFav\": isFav, &#125;; return params; &#125;&#125;","path":"2020/07/20/368594680/","date":"07-20","excerpt":"","tags":[{"name":"Flutter","slug":"Flutter","permalink":"https://yihuishou.github.io/tags/Flutter/"}]},{"title":"XaaS 到底是什么？","text":"Noas没有服务（No a Service， Noas） 在没有云服务的早期互联网，运营商托管主机或者租售主机盈利。 软件开发商购买实体设备托管，自建机房，租用运营商设备， 软件开发完毕部署在自己的服务器上，分发。 Iaas基础架构即服务（Infrastructure as a Service， IaaS） 虚拟化服务器主机不含系统，运营商出售虚拟主机，实体主机可以分隔多台 用来盈利。 Pass平台即服务（Platform as a Service，PaaS） 平台包含系统和软件所需要的运行环境，中间件，这些都作为可出售内容来盈利 Saas软件即服务（Software as a Service，SaaS） 基础软件作为出售的内容来盈利 Faas函数即服务（Function as a Service，FaaS） 拆分软件中的每一个方法（函数）来盈利 根据函数使用来收费 Baas后台即服务（Backend as a Service，BaaS） 整格后台作为一个产品出售来盈利 总结如何产出更多的软件，通过软件细分或整合，不再受限于一次性交易来获取更多的利润。 下一次会拆分成什么呢？","path":"2020/07/15/3650854255/","date":"07-15","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"让 Windows 10 开机自动登录","text":"通常如果系统用户配置了密码，开机必须登录才能进入桌面。但是有时候我们想在首次开机的时候，无需输入密码自动登录到桌面。 若要使用注册表编辑器打开自动登录，请按照下列步骤操作： 单击“开始”，然后单击“运行”。 在 “打开” 框中，键入 “ Regedt32”，然后按 enter。 在注册表中找到以下子项：HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsNT\\CurrentVersion\\Winlogon 双击 “ DefaultUserName “ 条目，键入您的用户名，然后单击”确定”。 双击 “ DefaultPassword” 条目，键入您的密码，然后单击”确定”。 注意如果DefaultPassword值不存在，则必须添加它。 若要添加值，请按照下列步骤操作： 在 “编辑” 菜单上，单击 “新建”，然后指向 “字符串值”。 键入DefaultPassword，然后按 Enter。 双击 “ DefaultPassword”。 在”编辑字符串”对话框中，键入您的密码，然后单击”确定”。 注意 如果未指定 DefaultPassword 字符串，则Windows会自动将AutoAdminLogon键的值从1（true）更改为0（false），从而禁用AutoAdminLogon 功能。 在 “编辑” 菜单上，单击 “新建”，然后指向 “字符串值”。 键入AutoAdminLogon，然后按 Enter。 双击 “ AutoAdminLogon”。 在 “编辑字符串” 对话框中，键入1，然后单击”确定”。 如果已将计算机加入域，则应添加DefaultDomain值，并将该值的数据设置为域的完全限定的域名（FQDN）。 退出注册表编辑器。 单击 “开始”，单击 “关闭”，然后在 “批注”文本框中键入原因。 单击”确定”关闭您的计算机。 重启计算机。您现在可以自动登录。 注意 绕过 AutoAdminLogon 进程，若要以其他用户身份登录，请按住 Shift 键 Windows重新启动或注销后。 如果通过组策略对象 (GPO)或本地策略服务器上定义的登录标识值， 则此注册表更改不起作用。当策略发生更改，以便它不会影响计算机时，自动登录功能按预期的方式工作。 活动活动同步 Exchange (EAS)的密码限制时，自动登录功能将不工作。此行为是设计使然。 这种现象由 Windows 8.1 中的更改并不会影响 Windows 8 或更早版本。 若要解决该问题在 Windows 8.1 或更高版本，请在控制面板中删除 EAS 策略。 在服务器具有不同的用户交互控制台登录更改作为最后登录的用户标记DefaultUserName注册表项。 AutoAdminLogon 依赖的 DefaultUserName条目相匹配的用户和密码。因此，AutoAdminLogon可能会失败。您可以配置一个关机脚本来设置正确的DefaultUserName。 您可以使用 Sysinternals工具自动登录才能启用此功能更容易。此工具还可帮助您使用密码的加密的版本。 下面是直接使用注册表脚本导入设置 Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon]\"DefaultUserName\"=\"Administrator\"\"AutoAdminLogon\"=\"1\"\"DefaultPassword\"=\"your_password\" 保存成xx.reg，导入注册表即可。 域用户类似。 Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Winlogon]\"DefaultDomainName\"=\"domainname\"\"DefaultUserName\"=\"username\"\"AltDefaultUserName\"=\"username\"\"AltDefaultDomainName\"=\"domainname\"\"AutoAdminLogon\"=\"1\"\"CachePrimaryDomain\"=\"domainname\"\"DefaultPassword\"=\"your_password\" 微软官方也提供了一个小工具 Autologon v3.10 来方便配置","path":"2020/07/15/4036766117/","date":"07-15","excerpt":"","tags":[{"name":"Windows","slug":"Windows","permalink":"https://yihuishou.github.io/tags/Windows/"}]},{"title":"给 Flutter 项目初始化构建提个速","text":"通常由于不可描述的网络原因，在使用 Flutter 初次构建安卓应用时会异常缓慢 IDE 卡死在Initializing gradle...是经常会发生的事 目前除了使用代理之外，就只能使用阿里云的国内镜像来让应用构建加速了 Flutter 切换为阿里云镜像总计分三步第一步 下载 gradle 完整安装由于 IDE 自动下载 gradle 安装包经常会出错，所以建议使用下载工具到官网下载完整安装包 完整安装包无需解压，直接复制到用户目录\\.gradle\\wrapper\\dists下即可 第二步 修改 Flutter SDK 全局配置修改 Flutter SDK 中 gradle 的配置文件，使主仓库指向阿里云的镜像仓库 配置文件路径： flutter_sdk/packages/flutter_tools/gradle/flutter.gradle buildscript &#123; repositories &#123; //google() //jcenter() maven &#123; url 'https://maven.aliyun.com/repository/google' &#125; maven &#123; url 'https://maven.aliyun.com/repository/jcenter' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/groups/public' &#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.2.1' &#125;&#125; 第三步 修改 Flutter 项目配置修改 Flutter 项目中 gradle 的配置文件，使主仓库指向阿里云的镜像仓库 配置文件路径： 项目/android/build.gradle buildscript &#123; repositories &#123; //google() //jcenter() maven &#123; url 'https://maven.aliyun.com/repository/google' &#125; maven &#123; url 'https://maven.aliyun.com/repository/jcenter' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/groups/public' &#125; &#125; dependencies &#123; classpath 'com.android.tools.build:gradle:3.2.1' &#125;&#125;allprojects &#123; repositories &#123; //google() //jcenter() maven &#123; url 'https://maven.aliyun.com/repository/google' &#125; maven &#123; url 'https://maven.aliyun.com/repository/jcenter' &#125; maven &#123; url 'http://maven.aliyun.com/nexus/content/groups/public' &#125; &#125;&#125;","path":"2020/07/14/466733536/","date":"07-14","excerpt":"通常由于不可描述的网络原因，在使用 Flutter 初次构建安卓应用时会异常缓慢 IDE 卡死在Initializing gradle...是经常会发生的事 目前除了使用代理之外，就只能使用阿里云的国内镜像来让应用构建加速了","tags":[{"name":"Flutter","slug":"Flutter","permalink":"https://yihuishou.github.io/tags/Flutter/"}]},{"title":"JavaScript 中 Splice 函数与数组塌陷","text":"在写JS代码时，我们常常使用 splice 函数来删除数组中的元素，因为 splice 函数会直接对数组进行修改，从而不需再自己写一个算法来移动数组中的其他元素填补到被删除的位置。splice 功能十分强大，除了可以删除数组的元素之外，还可以删除的同时添加新的元素到删除的位置等等用法。在 for 循环中使用 splice 时。 在对数组进行操作的时候，会使数组的长度产生变化，同时操作的数组那个项的下一个索引会被跳过，从而造成数组的某项会被跳过，这种叫做数组塌陷现象。 例如： 循环判断数组中的每一项的值，如果等于4就删除 遍历到第一个4，索引值i是3，执行删除操作，此时数组的长度就从原来的15变成了14，索引值还是3. 在进行循环 i++，这时i 变成 4，但是原来没删除数组中的第二个4 索引值变成了3，这样再去执行 i = 4 的操作，这样就跳过了原来没删除数组中的第二个4，去删除原来没删除数组中的第三个4，从而造成了输出的结果会有几个4没有被删除，就形成了数组塌陷现象。解决办法： 就是在对数组某项进行操作之后，手动将索引值 i –,保持数组每一项都被遍历。 // 定义数组var arr = [1, 2, 3, 4, 4, 4, 4, 4, 4, 4, 5, 6, 7, 8, 9];// 遍历for (var i = 0; i &lt; arr.length; i++) &#123; // 判断 if (arr[i] === 4) &#123; arr.splice(i, 1); // 此时， 删除的那一项会与原数组下标产生差异， 后面的所有成员都会往前移动。 i--; // 有了这条代码 才可以保证与数组中的每一个成员的下标一一对应。 &#125;&#125;console.log(arr)","path":"2020/06/12/4125727764/","date":"06-12","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"在 Java 中缩写 Lambda 表达式","text":"关于lambda的简写： obj -&gt; somefunction(obj) 可以写成： obj::somefunction 形如：x -&gt; foo(x) 此简写只能式单行语句且调用一个自身的方法 简写的格式：类名::方法 简写可用于构造方法并自动支持多参数 例如： (name,age) -&gt;new People(name,age) 可以写成： People::new 新建数组： String[]::new","path":"2020/06/12/1586694155/","date":"06-12","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"博客文章规范","text":"使用hexo new &quot;xxx文章&quot;命令生成文章以避免标题特殊字符导致的各种问题 文章标题中的英文单词应前后添加空格加以区分 必须添加tags，使用首字母大写的标签，无法归类的使用随笔标签 文章附带图片使用独立文件夹，图片使用首字母大写命名或三位数命名 文章中的英文单词、命令、特殊强调使用加重强调样式且前后不加空格 文章正文单行添加空行用于分隔，段落间添加空行用于分隔 插入的图片前后应添加空行用于分隔 删除无图片的文章图片文件夹 ✨ 更新博客为默认更新提交消息 文章正文使用中文标点符号 代码块必须使用代码块标签样式，代码类型使用空格加首字母大写的标签 文章为讲述人的视角编写来提高阅读体验","path":"2020/06/04/2276828982/","date":"06-04","excerpt":"使用hexo new &quot;xxx文章&quot;命令生成文章以避免标题特殊字符导致的各种问题 文章标题中的英文单词应前后添加空格加以区分 必须添加tags，使用首字母大写的标签，无法归类的使用随笔标签 文章附带图片使用独立文件夹，图片使用首字母大写命名或三位数命名 文章中的英文单词、命令、特殊强调使用加重强调样式且前后不加空格 文章正文单行添加空行用于分隔，段落间添加空行用于分隔 插入的图片前后应添加空行用于分隔 删除无图片的文章图片文件夹 ✨ 更新博客为默认更新提交消息 文章正文使用中文标点符号 代码块必须使用代码块标签样式，代码类型使用空格加首字母大写的标签 文章为讲述人的视角编写来提高阅读体验","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Windows 电源模式大全","text":"GOD mode 新建文件夹 GodMode.{ED7BA470-8E54-465E-825C-99712043E01C} PowerShell（管理员模式）：Win+X 或者 Cmd 命令行 电源方案：powercfg -duplicatescheme 381b4222-f694-41f0-9685-ff5bb260df2e（平衡） 电源方案：powercfg -duplicatescheme 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c（高性能） 电源方案：powercfg -duplicatescheme a1841308-3541-4fab-bc81-f71556f20b4a（节电） 电源方案：powercfg -duplicatescheme e9a42b02-d5df-448d-aa00-03f14749eb61（卓越性能）","path":"2020/01/17/3654333771/","date":"01-17","excerpt":"","tags":[{"name":"Windows","slug":"Windows","permalink":"https://yihuishou.github.io/tags/Windows/"}]},{"title":"禁止 Opera 升级和搜索引擎更改","text":"在 Opera 浏览器中 的关于 找到配置文件夹所在地址 default_partner_content.json 中的 “version” 字段值 控制起始页默认搜索引擎 默认 28 为百度搜索，强制更新后为 Opera 当前的大版本号 被改为搜狗，所以修改版本号为 28 即可锁定搜索引擎 最后更改 default_partner_content.json 文件属性为禁止写入。 禁用升级 系统环境变量新增一条 名为OPERA_AUTOUPDATE_DISABLED的环境变量，值随意填写 即可产生浏览器禁用更新检查器的效果。 删除 Opera 当前版本安装目录下的 opera_autoupdate.exe 文件即可 AppData\\Roaming\\Opera Software\\Opera Stable\\themes Opera 背景主题位置，复制背景文件到该位置即可","path":"2020/01/15/1811952678/","date":"01-15","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Dart 的进制转换","text":"在使用Flutter时，偶尔会碰到需要使用蓝牙模块的地方 由于蓝牙协议通常使用16进制传输数据，所以对Dart的数值转换进行了一番研究。 普通十进制定义： int a = 10; 16进制定义： int a = 0x10； 10进制转16进制字符串： 参数为转换进制 a.toRadixString(16); 16进制转10进制： 不加可选参数为10进制转换 int.tryParse(“e4”, radix: 16); int.parse(“e4”, radix: 16); parse转换失败会抛出异常 tryParse则返回 null","path":"2019/12/14/3255864385/","date":"12-14","excerpt":"","tags":[{"name":"Dart","slug":"Dart","permalink":"https://yihuishou.github.io/tags/Dart/"}]},{"title":"关于 ShadowSocksR 端口转发","text":"关于ShadowsocksR端口转发默认情况下，我们在使用SSR Windows客户端时，会发现它只能自动代理HTTP流量，即80/443端口的流量，即使设置为全局代理模式也一样。 这对我们正常浏览网页及下载普通文件，基本没有影响。 但是电脑上一些常用的软件，如果走的是非HTTP协议的流量，又想让它通过SSR代理，那么就需要对SSR客户端进行一些额外设置了，比如端口转发。 以下相关内容，在SSR Windows客户端的基础上展开， SSR 端口转发的用途下面举两个常用的例子： Windows远程桌面连接走SSR代理比如手里有一台国外服务器，安装Windows系统，通过远程桌面连接进行管理。但是线路一般，连接很慢，操作很不流畅。这种情况就可以设置远程桌面走SSR代理，通过网络较好的SSR服务器进行中转，从而加快远程桌面连接速度，大幅减少卡顿。 Putty通过SSR中转连接Linux服务器如果你使用的是Linux系列的服务器，同样因为网络不佳造成Putty连接不畅，那么通过SSR端口转发也可以帮忙解决。 以上两例适用于拥有多台VPS服务器的用户，仅做示例，其它Windows软件也可以参考实行。理论上，SSR端口转发可以在不借助其它工具的情况下，代理电脑上任意软件的流量。 如何使远程桌面连接走SSR代理下面我们具体介绍一下，远程桌面连接的代理设置，其它软件可以参考，步骤是一样的。 原始环境：国外VPS安装Windows系统，网络状况较差，经常性连接失败，即使连接成功，操作也极其卡顿，无法正常使用。 改善效果：通过SSR转发远程桌面后，很快连接成功，操作流畅，与本地桌面操作区别不大。 具体方法： 1.打开SSR Windows客户端，右键点击任务栏小飞机，选择端口设置： 2.在端口设置窗口中，点击添加按钮。 注意：在点击添加之前，不要直接填写下图右侧内容，即使填写了也无法保存，没有效果。 3.下面就可以填写右侧内容了，如下图所示，填写完成后点击确定保存。 开关：打勾。类型：选择端口转发。服务器ID：选择之前设置好的SSR服务器。本地端口：随意设置一个，用做后期远程桌面连接，建议设置为较大端口号，比如53389，避免冲突。目标地址：填入Windows服务器IP地址。目标端口：3389，即远程桌面连接的默认端口。 4.现在SSR的端口转发已经设置完毕，接下来可以使用远程桌面连接远程服务器了。 注意：在使用远程桌面时，要填写本机地址+53389，即127.0.0.1:53389,这样才能通过SSR代理，如下图所示： 5.远程桌面连接成功后的界面如下图所示： 6.设置成功后，如果你不想通过SSR代理连接远程桌面，那么直接将远程桌面的IP地址，由127.0.0.1:53389改为服务器IP即可，无需其它设置。 关于SSR 端口设置另外两项功能SSR的端口设置功能中，除了端口转发外，还有两项：强制代理/规则代理。 这两项的设置比较简单粗暴，可以设置直接代理本地某个端口的流量，大家可以根据自身情况酌情使用。 提示：这个功能并不适用于前文所讲的远程桌面代理，因为远程桌面连接的是服务器3389端口，而连接时使用的本地端口并不固定。 在 Windows 下使用 SSR 客户端的时候经常会碰到启动 SSR 客户端弹出 1080 端口被占用的提示，超级的烦人，原因你懂的。明月最近也是频繁的碰到这个问题，并且是公司、家里电脑都碰上这个问题了，虽然只是每次电脑断电关机重启后会出现，一般等个几分钟后再次重启 SSR 客户端也就消失了，不过，很明显这很不科学，既然提示是被“占用”了，那么就要找到“占用”的罪魁祸首来！ 今天就给大家分享一下具体的办法，明月在家里的 Windows 7 系统电脑实测有效的。 就是这个提示框，使用 SSR 客户端的朋友们应该不陌生吧？ 解决的方法是： 1、SSR 的本地端口是 1080，首先要找到是哪个程序占用了该端口，window+R 组合键，调出命令窗口，输入命令：netstat -aon|findstr “1080”，回车，查看被占用端口对应的 PID，最后一位数字即 PID 2、打开任务管理器，切换到服务选项卡，在 PID 一列查看对应的进程是谁，然后结束掉，再重新启动 SSR 即可。 Git使用代理 如果使用的是 socks5(SSR) 例如代理地址为 127.0.0.1 端口 1080 命令： git config --global http.proxy socks5://127.0.0.1:1080 如果使用的是Http/Https 命令： git config --global https.proxy http://127.0.0.1:1080 git config --global https.proxy https://127.0.0.1:1080 取消代理 git config --global --unset http.proxy git config --global --unset https.proxy","path":"2019/10/09/1453987926/","date":"10-09","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"MDUI v1版本的迁移记录","text":"重新安装Hexo npm install hexo -g MDUI 主题需要的Hexo插件： node-prismjs 代码高亮 hexo-helper-qrcode 二维码 hexo-generator-searchdb 全局搜索 hexo-deployer-git git部署 npm install 或者 yarn install gyp verb check python checking for Python executable “python2” in the PATH Cannot download “https://github.com/sass/node-sass/releases/download/v4.5.3/win32-x64-51_binding.node&quot; set SASS_BINARY_PATH=F:\\ww\\tools\\node-sass\\win32-x64-46_binding.node set SASS_BINARY_PATH=C:\\Users\\Ladybird\\Documents\\Blog\\node_modules\\win32-x64-64_binding.node https://github.com/ZEROKISEKI/hexo-theme-gal –global –production windows-build-tools npm –registry https://registry.npm.taobao.org install –global –production windows-build-tools npm –registry https://registry.npm.taobao.org install hexo-renderer-sass –save npm –registry https://registry.npm.taobao.org install hexo-renderer-scss –save 安装node-sass的正确姿势 安装 node-sass 的时候总是会各种不成功，今天我琢磨了一会儿总算知道要怎么解决了。 首先要知道的是，安装 node-sass 时在 node scripts/install 阶段会从 github.com 上下载一个 .node 文件，大部分安装不成功的原因都源自这里，因为 github Releases 里的文件都托管在 s3.amazonaws.com 上面，而这个网址在国内总是网络不稳定，所以我们需要通过第三方服务器下载这个文件。（顺带一提，你可以看看这个好玩的 commit） 方法一：使用淘宝镜像直接运行下面的命令即可： SASS_BINARY_SITE=https://npm.taobao.org/mirrors/node-sass/ npm install node-sass我们可能更希望能直接使用 npm install 安装所有依赖，所以我的做法是在项目内添加一个 .npmrc 文件： phantomjs_cdnurl=http://cnpmjs.org/downloadssass_binary_site=https://npm.taobao.org/mirrors/node-sass/registry=https://registry.npm.taobao.org 这样使用 npm install 安装 node-sass 和 phantomjs 时都能自动从淘宝源上下载，但是在使用 npm publish 的时候要把 registry 这一行给注释掉，否则就会发布到淘宝源上去了。 方法二：使用梯子假设你的梯子在你本地机器上开启了一个第三方服务器 127.0.0.1:1080，那么只需按照下面的方法配置一下就能正常安装 node-sass 了 （如果你开启的是 PAC 模式而不是全局模式，那还需要将 s3.amazonaws.com 加入 PAC 列表）： npm config set proxy http://127.0.0.1:1080 npm i node-sass 下载完成后删除 http 代理 npm config delete proxy嗯，这样下来就能正常安装了。 下载地址：前往github 根据报错下载win32-x64-64_binding.node类文件； 配置环境变量在用户变量里配置SASS_BINARY_PATH变量，变量值填入下载文件路径。在系统变量PATH的变量值中添加下载文件路径。重新npm install如果还不成功说明环境变量未生效，重启电脑后再次npm install即可。","path":"2019/09/30/4240243490/","date":"09-30","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Telnet 与 SSH","text":"ssh与telnet的相同点： 1.两种协议都可以远程登录另一台主机 2.两种协议都属于基于TCP/IP的协议 ssh与telnet的不同点： 1.telnet是明文传送；ssh是加密传送，并且支持压缩。 2.telnet的默认端口号为23；ssh的默认端口号为22 3.ssh使用公钥对访问的服务器的用户验证身份，进一步提高的安全性；telnet没有使用公钥。 SSH 生成和使用方法 生成SSH密钥 命令行执行 ssh-keygen 等同于ssh-keygen -t rsa 命令 开始生成RSA密钥 ssh-keygen 后可配置一个参数作为提交的 comment comment 对身份验证本身没有任何影响 之后命令行会询问密钥文件的保存路径，回车使用默认保存路径 最后会询问加密用的私钥，回车使用空口令 如果配置的私钥则需要输入两次已验证私钥是否正确 通常会在默认保存路径下生成两个密钥文件 id_rsa 私钥文件和 id_rsa.pub 公钥文件 服务的配置公钥 id_rsa.pub 可用文本工具打开，将公钥明文复制到服务端即可 Github 中在 Setting –&gt; SSH and GPG keys –&gt; New SHH key 将公钥明文粘贴到输入面板中保存 之后Github会询问账户的登录密码，密码验证成功之后 SSH 登录就配置成功了 下一次登录即可直接使用SSH免密登录，如果配置了私钥则在首次登录时需要输入私钥 关于IDEA的密码管理 idea 默认会记录一些账户密码，如git的用户名和密码，该设置是Configure a password policy Configure a password policy(配置密码策略) 在“Settings” 对话框（Ctrl+Alt+S）中，选择“ Appearance and Behavior –&gt; System Settings –&gt; Passwords”。 设置IntelliJ IDEA如何处理Git远程存储库的密码: In native Keychain: 选择此选项以使用本机Keychain存储您的密码。此设置仅适用于MacOS和Linux。 In KeePass: 选择此选项以使用KeePass密码管理器来存储您的密码。使用KeePass密码管理器时，将使用主密码来访问存储个人密码的文件。 一旦IntelliJ IDEA记住您的密码，除非您需要访问密码数据库，否则它不会要求它们。 输入将c.kdbx在MasterPassword字段中用于访问该文件的密码。 您可以在“ 数据库”选项中更改c.kdbx文件的默认位置。 要导入c.kdbx文件，请单击“设置图标”并从下拉菜单中选择“import”，或单击“省略号图标”并指定包含密码的本地文件的路径。 如果要从数据库中删除现有密码，请选择“clear”。 Do not save, forget passwords after restart: 如果要在关闭IntelliJ IDEA后重置密码，请选择此选项。 Set passwords for Git remotes(设置Git远程仓库的密码) 每次与Git远程仓库交互时（例如，在pull， update或push操作期间），都需要授权。您可以配置IntelliJ IDEA 以记住您的密码，这样您就不必在每次需要授权时都指定凭据。身份验证的类型取决于您尝试访问的远程存储库使用的网络协议：HTTP或SSH。 如果您使用HTTP访问远程，当您需要身份验证时，会从GIt凭据助手中请求凭据。如果未找到Git凭证助手，则会向IDE返回提示。 如果已配置密码策略，IntelliJ IDEA将在密码数据库中查找凭据。如果密码数据库中没有，则会提示您输入登录名和密码。 如果您的远程使用SSH协议，则除了配置密码策略外，您还可以选择是使用native（本机）还是built-in（内置） SSH可执行文件。 在Settings –&gt; Preferences对话框（Ctrl+Alt+S）中，选择Version Control –&gt; Git。从SSH可执行文件下拉列表中，选择以下选项之一： Built-in: 所有授权都在IDE端执行。 如果使用登录名和密码进行身份验证，则会根据所选密码策略执行授权。 如果使用没有密码的SSH密钥进行身份验证，IntelliJ IDEA将访问~/.ssh/config文件并从那里获取密钥。 如果身份验证需要带密码的SSH密钥，会在GIt凭据助手中查找它，如果找不到Git凭证助手，它会向IDE返回提示。 如果已配置 密码策略，IntelliJ IDEA将在密码数据库中查找凭据。如果没有密码数据库，则会显示提示，您必须输入SSH密钥和密码。 Native: 所有授权都在Git端执行。将不显示任何提示，因此如果您使用不带密码的SSH，或者密码保存在凭证帮助程序中，或者有SSH代理，请选择此授权类型。","path":"2019/09/27/2553549325/","date":"09-27","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"自然码辅助码入门教程","text":"0、摘要 本教程仅针对双拼中自然码方案的辅助码。在学习辅助码之前，你应该已经能够熟练使用双拼输入法。使用辅助码需要您使用的输入法软件支持双拼且支持辅助码，我使用的是手心输入法mac版和ios版（手心输入法也支持win和安卓）使用辅助码与不使用辅助码不冲突，也就是说可以在想用辅助码的时候添加一个辅助码字母，不想用的时候就正常当作双拼没有辅助码的时候打字1、基本原理 汉语中同音字太多，用拼音打字重码率高，引入辅助码后，将汉字的偏旁部首发音的声母（比如：“像”的部首是“人”，“人”的声母是r）作为拼音之后的补充部分，所以输入”xdr”（xd是“像”的自然码双拼）就能自动筛选出符合声母是r的偏旁的字，“像”这个字也就自然出现在了候选词的第一个（前几个）。 自然码的三大笔画则是 a 、 d 、 p。 其中 a 代表了一切 横 、 竖 、 折（折就是笔画里的横折、竖折、横撇等）；其中 d 代表了一切 点 （也包括捺，你懂的）；其中 p 代表了一切 撇。 2、部件拆分原理 2.1 独体字 一般是部首汉字，如：“金木水火土辶皿马皮日月目衣耳”等。独体字全部看成部首，不能进一步拆分出部件，只能由笔画构成。 自然码中的笔画码： ①以横竖起笔的在a键上： “一丨亅レ乛フㄥ” ②以点起笔的在 d 键上：“丶冫氵”【d就是点的意思啦】 ③以撇起笔的在 p 键上：“丿彡”【p就是撇的意思啦】 举例：金【jnp，jn是金的自然码双拼，辅助码p是金的第一笔撇p】 2.2 有明显部首的汉字 如 “极、版、码、程、想、 福、袋、鳌、游、洪、递”，辅助码就是部首的声母。（注意：部首以新华字典上的为标准，不是以从上到下从左到右的顺序看部首的，比如“架”的部首是“木”） 举例：架【jwm，jw是架的自然码双拼，辅助码m是木的声母m】 说明：如果一个字有明显两个部首，比如“杏”的部首可以是“木”和“口”，所以随意哪个部首当作辅助码都行，也就是输入【xym】或【xyk】两者皆可。 2.3 不认识或不是整体字部件的汉字 如“录、芈、暨、 释、稽、躅、摭、谧、荔”，这类字的部首或部件可以用首笔画（尾部用末笔画）或能认识的汉字代替。 【比如 躅＝足＋虫 】 3、基础辅助形码表 【a】一 丨 亅 レ 乛 フ ㄥ 【b】 八 丷 卜 冖 宀 匕 比 白 贝 疒 鼻 【c】 艹 卄 廾  廿 屮 卝 寸 【d】丶 冫 氵 刀 刂 リ ㄍ ⺈ 丁 歹 癶 【e】 二 儿 阝 耳 卩  【f】 扌 丰 反 方 风 父 缶 巿 【g】 乚  ㄅ ㄋ 勹 弓 工 广 艮 戈 瓜 谷 革 骨 鬼 夬 罓 【h】 灬 火 禾 户 虍 黑 乊 厷 【i】 厂 川 巛 亍 车 虫 臣 辰 赤 齿 髟 豖 【j】 几 九 己 巾 斤 钅 金 见 臼  角 【k】 コ 凵 匚 冂 口 囗 丂 【l】 力 六 立 龙 耒 卤 鹿 【m】 木 门 毛 马 米 矛 母 皿 尨 麻 丏 【n】 女 牛 牜 ⺧ 鸟 【o】 日 曰 月 目 【p】 ノ 彡 片 皮 疋 ⺪ 攴 【q】 七 犭 犬 丌 欠 气 且 【r】 亻 人 入 肉 【s】 三 罒 巳 纟 糹 糸 厶  【t】 土 田 【u】 水 手  食 飠饣示 礻山 石 尸 十 士 矢 殳 舌 身 豕 鼠 【v】 隹 ⺮ 爫 爪 豸 止 至 舟 【w】 文 亠 攵 夂 夊 ㄨ 王 韦 瓦 【x】 彳 小  心 忄  血 彐 夕 习 西 辛 【y】 乙 又 已 讠言 幺 尤 尢 冘 衣 衤羊 牙 业 由 用 页 酉 鱼 雨 羽 聿 乑 乂 【z】 辶 廴 子 自 走 足 ⻊卆 4、需要特殊记忆的部件 “日、月、曰、目”辅助码为圆圆的【o】 “扌”辅助码为扶手的【f】 “ 彳”辅助码为行人的【x】 “一、丨、亅、乛”横竖折都是【a】 “亠”文字头【d】 “灬”火的变体【h】 “艮”根【g】 “肀”聿yu【y】 “耒”垒【l】——比如耕的双拼+辅助码是【ggl】 “爿”片【p】 “豕”适【u】 “髟”長chang的ch【i】 “隹”锥zhui的zh也就是【v】 “リ”刀的变体【d】 “”艹的变体【c】 “尢”尤的变体【y】 “丌”齐的变体【q】 “弋”弋读yi所以是【y】 “厶”私si的【s】 “ㄨ”叉x的【x】或者勿的【w】","path":"2019/07/11/1146712470/","date":"07-11","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Go 看这一篇就够了","text":"","path":"2019/06/17/3032697242/","date":"06-17","excerpt":"","tags":[{"name":"Go","slug":"Go","permalink":"https://yihuishou.github.io/tags/Go/"}]},{"title":"漫画字体魔改增强教程","text":"改造清单需要补全的日文符号 需要补全的繁体拟声映射 主要改造的正文字体 主要改造的背景旁白字体 主要改造的拟声字体 字体分类及重命名","path":"2019/06/17/3378556125/","date":"06-17","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"逃离弱鸡业务循环","text":"一般在工作两三年的Java开发者身上广泛存在一种情况，我们叫它“弱鸡循环”： while(做弱鸡业务)&#123; 薪资低； 难跳槽； 幸福感弱； 成就感弱； 技术提升慢；&#125; 而造成上面那样的弱鸡业务，也往往因为没有测试？ 其实很多公司（甚至包括阿里这样的公司）的典型开发流程： 一堆人吭哧吭哧写完代码，发布到某个环境上，找一堆人来点点点，没问题，发布上线。 我在阿里呆了两年时间，一个测试也没有写过。 对于这种典型的情况，一个放之四海而皆准的方向是，尝试对你们的Web应用添加自动化测试。 终极目标说起来很简单：你们的应用上线之前，应该跑一个命令，不需要任何手工测试就可以放心上线。 先说好处： 方向明确。很多人谈到工作之外的“学习”或感到十分茫然，因为他们不知道要做什么。 刷题？又难又坚持不下去。 看书？不知道看什么，看完了做什么。 而我上面说的这件事，目标非常明确，虽然看上去很难，但是却是十分可行的。 关键是，它可以分解成很多的小步骤，循序渐进地完成。 贴近实践。刷算法题之类的“学习”方式在实际工作中用处不大，看上去非常像是……屠龙之技。 如果你不是为了进微软这样的公司，大可不必狂刷面试题。 可行性高。很多人想要在公司发起各种各样的技术革新，面临的最大问题是，老大不同意。 老大说，现在跑的这么稳定，换了你说的技术，出了问题怎么办？ 当然，你要是像我一样对某种新技术了如指掌（我指的是Gradle），那么你大可以狂妄地把担子揽过来。 进行自动化测试的好处是，你不需要对生产代码做任何变更，你不对别人的工作造成任何影响——一切都可以发生在本地。 一旦你完成了这项工作向别人展示，一个命令可以完成之前几个小时的手工测试的时候，相信我，不会会有人再愿意回到人工测试的时代。 人们拒绝新技术的唯一原因是因为他们还没有看到新技术带来的价值。 有助于职业发展。做完这件事情，你猜你的同事会不会高看你一眼？ 你猜你的老大会不会请你分享你的成就？你猜你能不能放到自己的简历里，在下次跳槽时大吹特吹？ 再说方法。我自己是Gradle的核心团队开发，因此对自动化构建非常推崇。 Gradle自己从自动化测试中受益无穷——每月的下载量在两百万次以上，但是核心团队只有不到十个人。 如果没有数万个自动化测试的保障，我们一定会疯掉。 如果你的公司符合以下条件，那么本文提到的方法百分百适合你。 一个庞大的Web application，连接了奇奇怪怪的数据库。 你的日常工作就是实现各种各样的需求，会熟练的： 在pom.xml里引入依赖 建立、注入各种各样奇奇怪怪的Cotroller/Service/Dao 写SQL取数据，进行各种处理，返回给前端 每次发布之后都在部门群里大吼一声：我们在测试服务器上部署了新版本，大家快去用鼠标点点点测试啊！ 现在，你要跳出弱鸡循环的第一步，你需要： 第一步，去看一下《Maven实战》，了解一下Maven的测试是怎么工作的。之所以让你去研究Maven，是因为你们这种系统，99%不会采用Gradle这种新技术的。第二步，写第一个测试，代码如下： public class MyTest &#123; @Test public void 跳出弱鸡循环() &#123; &#125;&#125; 是的，Java代码是可以用中文写的。 第三步，去搞一份你们线上数据库的表结构。各种数据库都有相应的命令dump表结构。有困难的的话，手写建表语句。 第四步，本地用Docker启动一个临时的数据库。 第五步，去研究一下flyway，用自动化方式把表结构灌到这个临时数据库里。 第六步，去了解一下你们的应用是怎么部署的，你们上线的应用不可能是通过在IDE里面点绿色三角来部署的。把部署的命令行要过来。 第七步，研究一下这个命令行，尝试在本地启动起来。碰到数据库没起来的问题，就把连接串改成刚刚那个Docker的临时数据库。 第八步，你平时怎么在网页上点点点测试的，把它翻译成Java。比如你平时会手工测试登录接口，那就用HttpClient写一段代码，模拟登录。 第九步，把上面这些整合起来： public class MyTest &#123; @Test public void 跳出弱鸡循环() &#123; 启动测试数据库(); 把表结构灌进去(); 本地启动应用(); 自动化方式测试接口(); &#125;&#125; 碰到任何问题的话，就一点一点地解决。 在这个过程中，你会发现自己达到了你最初的目的： 提高自己。必须说一句，这其实不是非常科学的集成测试，真正的集成测试应该把相关的步骤绑定到pre-integration-test/integration-test之类的phase。 但是……反正我写这么多，99%的人是不会坚持下去的，所以也无所谓了。 如果你真的做完了我说的这一切，私聊我，我告诉你应该怎么继续改进你的集成测试流程。 虽然这些步骤看上去很简单，但实际上每一步都可能要花掉你几个周末的时间，因此，请做好思想准备，坚持不下去也无所谓（毕竟99%的人是坚持不下去的）， 没关系，在弱鸡循环里呆着吧，反正，你不是一个人。","path":"2019/06/13/1754570926/","date":"06-13","excerpt":"一般在工作两三年的Java开发者身上广泛存在一种情况，我们叫它“弱鸡循环”： while(做弱鸡业务)&#123; 薪资低； 难跳槽； 幸福感弱； 成就感弱； 技术提升慢；&#125; 而造成上面那样的弱鸡业务，也往往因为没有测试？","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Dart 2.3 踩坑集锦","text":"错误： Setting VM flags failed: Unrecognized flags: checked 关闭项目编译中的 Checked mode 即可 Dart 中单例模式 class Manager &#123; // 工厂模式 factory Manager() =&gt;_getInstance(); static Manager get instance =&gt; _getInstance(); static Manager _instance; Manager._internal() &#123; // 初始化 &#125; static Manager _getInstance() &#123; if (_instance == null) &#123; _instance = new Manager._internal(); &#125; return _instance; &#125;&#125;// 无论如何初始化，取到的都是同一个对象Manager manager = new Manager();Manager manager2 = Manager.instance; Dart 2.3 新特性 展开运算符 ... 和JS中的展开符一样，可以展开Map 和 List List 集合可使用 For in 迭代 和 if 判断 需要注意的是该特性被当作表达式（所以三元表达式也可以），不用加花括号和分号 不能 return 和 使用多行语句（const 集合不支持） 箭头函数只做完表达式，不支持多行写法（花括号无用） 多行语句只能使用匿名函数 和JS一样 数学运算有精度问题 没有接口 统一定义为 抽象类 使用 implement 则作为接口，使用 extand 则作为抽象类 不能多继承，但可以使用 with 混入进行代替 with 的限制： 被混入的类必须式直接继承至 Object 不能有其他继承 私有变量为变量名前加_ 且必须在单独一个Dart文件中才会生效 方法中 [] 为可选参数 { tyep var} 为可选命名参数 var a=1000 为参数默认值 命名参数传入参数必须带参数名 var : value 字符串 ``` 可作为多行文本 Final 和 const 都可表示常量，但Final可延迟初始化 常量类型不能使用动态类型 没有初始化的变量都会被赋予默认值 null .. 级联操作符 相当于链式调用 ?. ??= 判断null 非空就赋值 执行","path":"2019/06/05/3668064671/","date":"06-05","excerpt":"","tags":[{"name":"Flutter","slug":"Flutter","permalink":"https://yihuishou.github.io/tags/Flutter/"}]},{"title":"Git 提交消息模板规范","text":"以下git提交建议的文字描述来自alibaba的开源项目egg.js，git-commit规范；符号部分来自github里部分项目的emoji表情提交建议。 一、文字规范 commit一共由五部分组成，具体内容如下。 type 提交 commit 的类型，包括以下几种 关键字 说明 示例 feat 新功能 [feat] 新功能 fix 修复问题 [fix] 修复问题 docs 修改文档 [docs] 修改文档 style 修改代码格式，不影响代码逻辑 [style] 修改代码格式 refactor 重构代码，理论上不影响现有功能 [refactor] 重构代码 perf 提升性能 [perf] 提升性能 chore 修改工具相关（包括但不限于文档、代码生成等） [chore] 修改工具 deps 升级依赖 [deps] 升级依赖 scope 修改文件的范围（包括但不限于 doc, middleware, core, config, plugin） subject 用一句话清楚的描述这次提交做了什么 body 补充 subject，适当增加原因、目的等相关因素，也可不写。 footer 当有非兼容修改(Breaking Change)时必须在这里描述清楚关联相关 issue，如 Closes #1, Closes #2, #3如果功能点有新增或修改的，还需要关联文档 doc二、emoji规范 注：以下emoji表情在git提交时已经完全支持，哪怕下面的表情显示不完整也不用慌，可以直接在git-submit里使用。 emoji emoji代码 commit说明 🎨 (调色板) :art: 改进代码结构/代码格式 ⚡️ (闪电) :zap: 提升性能 🐎 (赛马) :racehorse: 提升性能 🔥 (火焰) :fire: 移除代码或文件 🐛 (bug) :bug: 修复 bug 🚑 (急救车) :ambulance: 重要补丁 ✨ (火花) :sparkles: 引入新功能 📝 (铅笔) :pencil: 撰写文档 🚀 (火箭) :rocket: 部署功能 💄 (口红) :lipstick: 更新 UI 和样式文件 🎉 (庆祝) :tada: 初次提交 ✅ (白色复选框) :white_check_mark: 增加测试 🔒 (锁) :lock: 修复安全问题 🍎 (苹果) :apple: 修复 macOS 下的问题 🐧 (企鹅) :penguin: 修复 Linux 下的问题 🏁 (旗帜) :checked_flag: 修复 Windows 下的问题 🔖 (书签) :bookmark: 发行/版本标签 🚨 (警车灯) :rotating_light: 移除 linter 警告 🚧 (施工) :construction: 工作进行中 💚 (绿心) :green_heart: 修复 CI 构建问题 ⬇️ (下降箭头) :arrow_down: 降级依赖 ⬆️ (上升箭头) :arrow_up: 升级依赖 👷 (工人) :construction_worker: 添加 CI 构建系统 📈 (上升趋势图) :chart_with_upwards_trend: 添加分析或跟踪代码 🔨 (锤子) :hammer: 重大重构 ➖ (减号) :heavy_minus_sign: 减少一个依赖 🐳 (鲸鱼) :whale: 相关工作 ➕ (加号) :heavy_plus_sign: 增加一个依赖 🔧 (扳手) :wrench: 修改配置文件 🌐 (地球) :globe_with_meridians: 国际化与本地化 ✏️ (铅笔) :pencil2: 修复 typo","path":"2019/06/04/2575550749/","date":"06-04","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Jackson 序列化 Hibernate 对象问题","text":"大多数方案都是说在实体上加@JsonIgnoreProperties然后忽略掉hibernate的代理对象中用于懒加载的两个属性（handler和hibernateLazyInitializer），这种方案在实体不多的时候可行，但是对于强迫症的我总觉得这不是最好的方案，至少这真的是最次方案，毕竟这应该是一个全局问题，而不是用局部方案来解决。 后来谷歌和stf搜到的第二种方案是配置jackson的序列化策略，这算是全局配置了，通过往ObjectMapper里面设置SerializationFeature的FAIL_ON_EMPTY_BEANS,默认是true，也就是jackson找不到该属性序列化器的时候会抛出异常，也就导致序列化失败的原因，通过设置为false来规避序列化这种fail-fast机制（打个比方ヾ(￣▽￣)），序列化问题算是在全局上解决了，看起来算是最好方案了。 其实在第二种方案搜索的过程也看到说，自己为那两个hibernate代理属性写序列化器来忽略它们，其实这种应该才是最好的方案（关于这种方案，其实用起来不难，自己往spring ioc中注册一个自定义的objectMapper就可以了，不过懒….）。第二种方案在运用的过程中发现，虽然序列化如期成功了，但是会发现序列化后的json会出现handler和hibernateLazyInitializer，效果是这样的 “handler”: {}, “hibernateLazyInitializer”: {} 这种作为自从做了程序员强迫症从无到有，再到日益严重的我简直无法忍受。然后意外看到其实jackson有一个模块功能是针对hibernate做了这方面的工作，这对于java程序员这种伸手党简直福音- - 无脑到什么程度呢？加个依赖就好了…. hibernate5 hibernate4 &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-hibernate4&lt;/artifactId&gt; &lt;version&gt;2.9.8&lt;/version&gt;&lt;/dependency&gt; jackson有个Jackson2DatatypeHelper类会检查hibernate5组件是否存在classpath中，如果存在就会激活。老实说这种技术真的是很亮瞎狗眼。","path":"2019/05/29/472996778/","date":"05-29","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"SQL 中 in or 和 exist 区别","text":"in 和 or 区别如果in和or所在列有索引或者主键的话，or和in没啥差别，执行计划和执行时间都几乎一样。 如果in和or所在列没有 索引的话，性能差别就很大了。在没有索引的情况下，随着in或者or后面的数据量越多，in的效率不会有太大的下降，但是or会随着记录越多的话性能下降 非常厉害 因此在给in和or的效率下定义的时候，应该再加上一个条件，就是所在的列是否有索引或者是否是主键。如果有索引或者主键性能没啥差别，如果没有索引，性能差别不是一点点 in 和 existsin是把外表和内表作hash连接，而exists是对外表作loop循环，每次loop循环再对内表进行查询，一直以来认为exists比in效率高的说法是不准确的。如果查询的两个表大小相当，那么用in和exists差别不大；如果两个表中一个较小一个较大，则子查询表大的用exists，子查询表小的用in not in 和 not exists如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引 而not extsts 的子查询依然能用到表上的索引。 所以无论那个表大，用not exists都比not in要快。","path":"2019/05/28/895793596/","date":"05-28","excerpt":"","tags":[{"name":"SQL","slug":"SQL","permalink":"https://yihuishou.github.io/tags/SQL/"}]},{"title":"Gui 与 Cli 的抉择","text":"by Addone [天堂鱿鱼] 前言自Linux渐渐风行起来，有关图形界面（GUI，Graphical User Interface）和命令行界面（CLI，Command Line Interface）之争就一直闹个不停。看了众多评论之后，总有些郁闷之意想要发泄一下，虽然觉得有混水摸鱼的嫌疑，却还是不吐不快。 首先先声明一下本人的立场。我个人希望自己是站在一个比较中立的角度上看的。但实际应用上，我用图形界面的时间远远超过命令行界面，所以看问题难免会有一些偏颇，请读者见谅。 其次，本文的目的，不是对GUI和CLI进行比较从而得出何者更佳的结论，而是希望探讨一下为何关于两者的讨论会演变成一种对立的状况，以及试图触及一下两种界面方式所代表的截然不同的哲学观。本文热烈欢迎全文转载，恳请注明出处。 定义所谓GUI，我的定义是以图形作为工作元素并以鼠标、键盘协同作为主要输入工具的工作方式。GUI通常使用大量的图标来标识命令，并且通过组织按钮、工具栏、对话框等元素的方式来试图提高界面的直观性和易用性。通常来说，GUI由于使用了大量的图形元素，看起来会比较美观。 而CLI则自然是指主要以文本方式作为工作元素，并主要以键盘作为输入工具的工作方式。CLI采用直接输入命令和参数的方式直接向计算机发送各种指令，通过组织参数和命令的输入方法来试图提高工作效率。CLI中同样可以采用图形组件以使得界面更为美观，但这些图形组件并不像GUI中的那样具备实际的命令功能（否则就不该称为CLI了）。 谈一些奇怪的论点 一直很奇怪，为何很多人把GUI和“易用性”划上等号，而把CLI和“高效”划上等号。尽管从两者的出发点来说是没有错的，但如果说所有应用这些界面的软件都达到了其期望目标，那无异于一个泡沫般的梦想。 让我们来看看这个软件。这是一个著名的GUI软件的默认界面。说起GUI易用性，大概很多人都能猜到我会选择这个软件作为反面教材。 图1：不那么易用的GUI 很显然，这种将按钮隐藏起来的设计是为了使得界面更加美观和简洁。但这种设计实际上大大降低了软件的易用性和效率。我相信没有什么人愿意通过先找到那个用来显示按钮的按钮，点一下，再找到剪切、复制或粘贴按钮，以此来实现剪贴功能。事实上，大多数人会使用快捷键的方式。 像Office这类功能非常复杂的软件，设计一个良好的GUI界面会非常费神，其设计难度不亚于一个集成开发环境（IDE，Intergrated Developing Environment）。但复杂性不应该是界面设计糟糕的借口。如上例，事实上用户根本无法选择哪个按钮应该隐藏，哪个不该。把剪切、复制、粘贴、格式刷这样常用的按钮隐藏起来的唯一作用，就是敦促用户通过快捷键而非按钮去使用这些功能。不过既然如此，又何必把这些功能做成按钮呢？直接拿掉不是更简洁么？ 同样，并非所有的CLI软件都是高效的。以下是一个著名的CLI软件的一种典型用法： 不怎么高效的CLI ffmpeg.exe -i &quot;D:\\Video\\Fearless\\Fearless.avi&quot;-target film-dvd -s 720x352-padtop 64 -padbottom 64 -maxrate 7350000-b 3700000 -sc_threshold 1000000000-trellis -cgop -g 12 -bf 2 -qblur 0.3 -qcomp 0.7-me full -dc 10 -mbd 2-aspect 16:9 -pass 2 -passlogfile &quot;D:\\Video\\ffmpegencode&quot;-an -f mpeg2video &quot;D:\\Fearless.m2v&quot; 如果用户是要使用完全相同的参数进行大量的批量转换，以上命令也还勉强算得上“高效”。因为事实上，如果是需要经常使用的话，用户通常并不会选择每次都输入这堆参数，而会使用脚本的方式把以上的命令“包装”起来，以便于将来的调用。但实际情形则常常更为复杂，用户实际上很少使用完全同样的选项进行转换，而进行“微调”则会成为一件很麻烦的事情，于是就会出现把脚本“包装”起来以提供更灵活的微调功能的脚本，如此周而复始，层层包裹。 对于这类软件来说，由于所提供的功能选项非常丰富，设计参数列表和设计GUI同样是一件很麻烦的事情。CLI实质上是通过简化操作步骤和提供批量处理选项，来提高进行重复工作时的操作效率的。如果这个软件使用的机会并不多，而且每次使用时的选项都不完全一致，那么不仅不易用，而且也很难“高效”起来。 两者的特点尽管如此，在大多数情况下，GUI确实比CLI更易于使用，而CLI确实要比GUI更高效，因为两者的设计目标就是如此。 GUI由于采用了大量的图形元素，界面会更显得具有艺术性，富有人性化。相较于枯燥的文本来说，精致且合理的图形大大增强了界面的易用性。 图2: 漂亮的GUI GUI所提供的像单选框、多选框这样的简洁明了的图形控件使得软件操作起来更为直观。 图3: 伟大的设计——GUI控件 相较于GUI而言，CLI通常就不具备什么美观程度了。为了提高性能，CLI通常采用纯文本方式工作。 图4: 一片漆黑的经典CLI界面 当然，也有例外的。 图5: 现代Linux上的常见CLI界面 为了提高工作效率，CLI通常都能够以很自然的方式支持批量操作。例如删除当前目录下的所有obj文件： rm *.obj 这种精确的指令可以保证得到严格执行，不会像采用GUI方式一样，说不定一个不小心会漏掉了一两个文件。 由于使用了文本方式直接输入命令，描述起来也比GUI方式轻松得多。例如前面所示命令行的操作，如果需要以GUI方式描述出来的话，少不了一大堆截图，否则很难让广大的菜鸟从浩如烟海的选项中找到自己真正所需要的东西。 最后要提一下快捷键。快捷键取材于CLI，实质上是一种直接向系统发送指令的操作方式，但由于依赖于GUI，我把它归为GUI的工作元素，并视为GUI为提高工作效率而向CLI所作的折衷，下文会详细说明这一点。 CLI的哲学CLI可以说是人机界面的远祖，哪怕是远古时期的纸带式计算机，也同样需要使用“命令行”方式工作（当然载体不同）。可以说命令行是最符合计算机工作方式的操作方式。 CLI的身上，带有编程的“影子”。各种选项以命令参数的方式传递给系统，我们所需要做的唯一事情就是查阅手册并选择适当的参数，然后用键盘一股脑儿敲进去，然后就是回车并等待执行结果。如前所述，这种操作方式具有很便利的可重复性，我们可以把这条命令保存为一个脚本以供将来直接调用，也可以粘贴到网络上，任何人都能直接复制并粘贴到自己的电脑上执行并得到同样的结果。 由于主要使用文本作为界面，CLI软件对计算机的要求也低得多，在同等配置的机器上也要比GUI软件的性能好得多。也正因此，CLI软件得以在广大的服务器系统上大行其道，在这些系统上，性能是最重要的。同时，由于具备了比GUI软件好得多的可伸缩性，CLI的适用范围也远比GUI广泛，在很多嵌入式平台上，我们甚至只能看到CLI的身影。 但毕竟人不是计算机，符合计算机的工作方式的同时也就意味着不那么人性化。为了用好一个CLI软件，用户不得不反反复复地查阅参数手册，有时还需要做各种参数组合的测试。而且如前所述，对于一些参数复杂的CLI软件，用起来是颇为令人头痛的，甚至有时根本就无法发挥CLI本身应有的“高效”。 另外，对于CLI软件来说，执行结果往往并不是那么清晰的。用户常常不得不面对满屏滚动的反馈信息体验黑客帝国一般的快感，或者是仿效真正的黑客一般从浩瀚的log海洋中寻觅那条丝毫不起眼的提示信息。 有人把CLI软件的工作方式称为“WYTIWYG”（What You Think Is What You Get，所想即所得）。这种方式的特点在于，虽然没有直观地反应出执行结果，但却能保证执行结果可以和你的意图一致。从某种程度上来说，这种说法是正确的，因为用户的意图总是以命令＋参数的方式精确地传递给系统，最后虽然不能直观地看到执行结果，却总能发现系统已经出色并严格地完成了工作。但从某种意义上来说，这种说法是不准确的，因为当面对着长长的参数手册时，用户往往已经搞不清自己的意图到底是什么了。 GUI的哲学GUI是为了使操作直观而生，最初被苹果公司应用在其操作系统上。后来苹果公司更是大胆率先采用鼠标作为输入设备，从而进一步使得电脑操作更为直观和易用。不过在那个年代受限于硬件的机能，更由于苹果一贯的高价策略，GUI长期被视为一种不必要的“奢侈品”，直到微软的“平民系统”Windows出现，在大量抄袭了苹果系统的图形元素后，Windows成功地在低端市场蔓延开来，GUI才终于得以大行其道。从这点上来说，微软公司还是起到了很积极的作用，对计算机的平民化和易用化作出了不小的贡献。 GUI的设计目标就是为了摆脱CLI的弊病，把软件的输入和输出都以更为人性化的形式来展现，从而使得软件更为易用和直观。从这种意义上来说，GUI的出现，可以看作是一种“进步”。通过提供一组图形“控件”，用户得以以更为自然的方式与计算机进行互动。通过简洁明了的图标，用户可以对软件的功能一目了然。通过使用新的输入设备——鼠标，用户可以以更符合人类习惯的方式“Point &amp; Click”，舒服地向计算机传递各种指令。不难想象，GUI的出现对于计算机的发展来说，不啻于一场伟大的革命。 GUI软件可以通过使用大量的图形元素和图形特效，从根本上改变软件的表现形式，“美观”和“人性化”渐渐成为软件界面设计的讨论主题。随着计算机处理能力的发展，我们甚至能够以3D的形式来呈现和操作软件。大量GUI软件的出现大大降低了学习和使用计算机的门槛，赏心悦目的操作界面吸引了各行各业的人投入其中。如果说CLI适应了各种各样的计算机，GUI则适应了各种各样的人。可以说，要是没有GUI，也就没有今天如此繁盛的计算机产业。GUI的出现顺应了人们的需求，也是历史的必然。 然而无论多么精美的界面，电脑程序就是电脑程序，其本质上却还是需要通过“命令”传递给计算机才能发挥作用的。由于中间需要进行“人的习惯”到“计算机的习惯”的转换，GUI软件不可能做到如CLI软件一般的高效和精确。可以说，GUI避免了CLI的弊端，但CLI的优点却恰恰成为了GUI的缺点。 由于大量图形元素的使用，GUI软件带动了计算机硬件的发展，人们对良好界面的追求推动了计算机处理能力的飞速发展。但这同时也说明GUI软件对计算机硬件的依赖性很强，在需要将GUI软件移植到其他平台时，这种依赖性的弊端就会凸现出来。而且即使是在同一平台上，GUI软件所耗费的资源要比相同功能的CLI软件高得多，但所能达到的性能则要低得多。尽管GUI提供了良好的易用性，极大地填补了人机对话的鸿沟，但在另一方面看来，实际上增加了软件开发的成本，缩小了软件的适用范围，同时降低了软件的工作性能。 由于能够以非常灵活的方式进行设计，GUI软件的表现形式也是千差万别。这本来是件好事情，但由于存在太多的GUI设计方式，开发人员在设计复杂的GUI软件时往往会陷入一种无所适从的困境。为了设计出真正易用好用的GUI软件，开发商往往不得不求助于艺术家和心理学家，甚至不惜采用“仿真”的方式来设计软件界面，这大大增加了软件开发的成本。尽管因此带动了计算机图形学和人机界面设计学的发展，但更多的“无良”开发商基于成本的考虑，选择了滥竽充数得过且过，无视用户的操作习惯和软件的易用性，甚至创造出一些难以使用的“GUI”，企图用更符合自身利益的界面设计来“改善”用户本身自然的“习惯”和“体验”，如上面所提到的那个著名的GUI软件。以操作系统开发商为例，可以说，如今最能坚守易用性阵地的当属苹果公司。尽管其产品同样存在一些瑕疵，但直到今天，苹果公司仍然坚持发展人机界面设计学，其创造的GUI软件大都是艺术性和易用性结合的典范。而在微软Windows系统横行的国内，在其所推行的“廉价GUI”的理念影响下，能以谨慎的态度学习和应用哪怕是“图标设计学”的人都已经几乎绝迹了。这在实际上导致了部分用户对GUI的反感和抵触。 图6：“仿真”式的GUI软件 图7：不同操作系统对“图标一致性”的不同理解 (注：复合式图标设计的一个基本原则是，图标的基本部分能够清楚地表明项目的大类。图中所列出的图标均为文档项目，但Windows的图标基本上没有遵循这个原则。KDE的图标基本遵循，但使用的不同色彩容易引起混淆。而Mac本身的图标系统就直接支持复合图标，因此这些图标的叠加工作实际上是直接由系统完成的。) 和CLI相对的，GUI的哲学是“WYSIWYG”（What You See Is What You Get，所见即所得），用户以自己所习惯的方式向系统传递指令，并可以立刻在屏幕上以最自然的方式看到执行结果，系统可以保证展示出来的东西和实际处理（如打印、渲染）后的结果基本保持一致。不过这事实上仅仅是GUI的一个设计目标，很多软件是根本达不到令人满意的效果的。而且对于用户来说，如何能把心目中的蓝图展现在计算机上，即使是在GUI高度发达的今天，也还同样是个问题。 协同工作在如今的大多数软件产品中，纯GUI并没有所期望的那么“易用”，而纯CLI系统也没有所想象的那么“高效”。作为一名程序员，我在从Windows平台向Linux平台转换的过程中，发现了一个很有趣的现象。 Linux在继承了Unix的血统的同时，也继承了其庞大的CLI软件基础（这种说法很不准确，姑且这么说吧），这跟早期Linux主要应用在服务器市场上有关。随着Linux系统被越来越多地应用到桌面市场上，对Linux下GUI软件的呼声也越来越高，也由此而引发了一系列关于Linux系统的争议，例如“Linux不是Windows”、“Linux根本不适合用作桌面系统”、“现在的Linux已经不再是Linux了”、“Linux就应该做自己的服务器，不该到桌面市场瞎掺和”。很多人都忘记了Linux仅仅是一个系统核心而已，这不仅能说明为何Linux核心会如此优秀，也能说明为何Linux会具有惊人的伸缩性。Linux核心既能够和Unix移植过来的大量CLI软件一起组成一个稳固的服务器系统，自然也能够搭载各种GUI软件从而组成一个漂亮的桌面系统，这两者并不矛盾。 有些跑题了，但从上面的描述可以看出，Linux进入桌面领域的时间不长，其基础则主要是建立在过去的大量CLI软件上的。为了在增强Linux的易用性的同时保留原先的CLI优势，Linux下的许多GUI软件采用了GUI前端＋CLI后端的方式，也就是编写一个用于与原CLI软件进行互动的GUI软件，两者协同工作。这种工作方式和我们平常所说的“前台＋后台”方式并不相同，其CLI部分是一个独立的软件，而GUI部分则仅仅是该软件的一个“Shell”（外壳）而已。GUI部分无法独立工作，而且开发目的仅仅是为了使该软件更易用，而并没有增加任何功能。 这种引人注目的方式具有很多优点，并且在最近得到了越来越广泛的利用。这种方式结合了GUI和CLI的优点，在使得软件的易用性得到大大增强的同时，其跨平台能力以及性能和效率并没有受到显著削弱。由于同一个后端程序可以搭配不同的各种前端，从而能够以较低的开发成本实现较好的跨平台效果。由于前后端的分开，核心开发人员可以专注于系统性能，而无需受软件表现形式和输入方式的影响；而界面开发人员也可以无需关注核心的实现，只需着力于改善界面的易用性和美观程度即可。这类系统的耦合度通常较低，用户甚至可以选择完全使用CLI来工作而无需理会GUI，这也大大降低了系统的维护成本。 图8: 漂亮的前端和强大的后端：Texshop＋Texlive 这是GUI和CLI协同工作的一个好例子，但它也同样存在缺陷。最显而易见的问题在于，对于很多对跨平台没有特别要求的纯GUI软件，为了提高效率而分离并开发一个独立后端显得完全没有必要。于是，一些开发商把CLI的一些理念“借”到了GUI软件中，最常见且有效的莫过于快捷键了。快捷键本身实际上是一种直接使用键盘向系统发送命令的方式，只不过采用按键组合的方式来代替了传统的字符串命令，用户只需记忆各种按键组合即可轻松调用。这种方式既符合GUI的哲学，又引入了CLI的高效，实在是一大创举，自诞生伊始就被广泛采用。如今，一个成熟完善的GUI软件已经根本离不开设计合理的快捷键了。 图9：无孔不入的快捷键 尽管快捷键在一定程度上提高了GUI的效率，但对于复杂的应用来说还是很不足够，一种“类CLI”方式呼之欲出。微软Office中Word的域命令方式虽然为Word的易用性蒙上了阴影，却也为Word带来了更灵活的工作方式和更强大的功能，我把这种方式称之为“嵌入GUI中的CLI”。Autodesk公司的AutoCAD则走得更远，索性大胆地应用了GUI和CLI联合构建的“复合界面”，用户需要联合使用菜单、按钮、命令工作，以学习难度的增大为代价，带来的是软件功能的强大和Autodesk公司的富有。 图10：无所不能的复合界面 总结如今我们可以看到广大的GUI拥趸在Windows下使用“Win＋R”来输入命令以快速调用程序，也可以看到坚定的CLI信徒在Linux下使用FB（Frame Buffer）来为自己的终端界面增光添彩。GUI和CLI不是敌对的，灵活运用两者的特点才能开发出更符合用户需求的人机界面。所以，我真的很不明白，为何有这么多人陷入在“GUI还是CLI”这样的争论中无法自拔，甚至还出现了很多宣称“自己喜欢哪个就选哪个好了，吵什么吵”的和事佬。 其实，对于用户来说，直观、易用且高效的操作方式才是受欢迎的，开发者又何必拘泥于一种固定的操作方式呢？而且，正如很多人所指出的一样，高效、直观，其实有时仅仅取决于用户的习惯而已。如其争论“GUI好还是CLI好”这样的话题，倒还不如多花点时间来研究个更好用的操作界面吧。","path":"2019/05/28/2119795723/","date":"05-28","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"JavaScript 中的分号战争","text":"转自知乎 By贺师俊 当初鉴于本答案过长而可能导致部分“分号党”无法catch到我的主要论点，原本打算重新修订本答案。但是因时间精力因素未予重写，且从本答案的支持来看，为分号正本清源的目的已经达到，所以不再修订本答案。这里仅总结下“分号党”推崇的“总是写分号”风格的最主要缺陷： 人总是有可能忘记写分号。ASI导致无法区分是无意中忘记还是有意不写（代码折行）。 “总是写分号”并不能完全解决ASI缺陷（如return后换行会自动插入分号）。 “}”后是否要加分号需要回溯到对应“{”之前进行语义判断（是否是函数表达式），成本远高于前置分号判断。只要对行首字符进行token判断：是否是[ ( + - / 五个符号之一） 【以下为原答案】 首先，加还是不加，这是一个书写风格问题。而书写风格通常有一些外在的考量，比如团队所建立的规则或习惯。@玉伯 的答案就是基于此。我对此基本赞同，不过这其实有点避重就轻，呵呵。另外，即使团队有这样的规则，也未必要通过强制在写代码的时候就要这样写，而可以通过工具达成。比如在源码管理工具上挂上钩子，对提交的源代码自动整理格式。 其次，很多人提到代码压缩问题。我觉得这是非常扯淡的理由。如果2012年的今天一个JS压缩器还不能正确处理分号，这只能说明这个JS压缩器没有达到基本的质量要求，根本不值得信任。 网友提到的jslint也是一个工具的反面例子。工具是帮助人的，而不应该是强迫人的。不明白这一点，你就不会理解为什么在已经有jslint很多年的情况下，还会出现jshint。 jshint对于不写分号会报warn，但可以通过asi选项关闭（在文件头加上/* jshint asi:true */即可）。 在asi选项说明里，jshint的文档是这样写的： There is a lot of FUD (fear, uncertainty and doubt) spread about &gt; &gt; semicolon spreaded by quite a few people in the community. The common myths are that semicolons are required all the time (they are not) and that they are unreliable. JavaScript has rules about semicolons which are followed by all browsers so it is up to you to decide whether you should or should not use semicolons in your code. 翻译如下（【】里是我添加的说明）： 关于分号有大量的FUD，且是由社区里的一小撮人【你知道是指谁】散布的。一个常见的流言是必须写分号，不写分号不可靠【流言的意思是不写分号会导致代码行为不确定】。实际上JS有明确的分号规则，并且所有浏览器【居然】都忠实遵守了规则。所以是否应该在你的代码里使用分号，完全可以由你自己决定【而不是由一小撮流言散布者或二逼工具强加于你】。 所以对于可不可以不加分号这个问题，社区是有结论的。 然后所谓“应该不应该”，就只是利弊分析，而不是非黑即白。其中也必定有一些如“可维护性”、“可理解性”甚至“代码美感”之类的貌似“贱人贱智”的问题。不过我相信有经验的程序员还是会在大多数问题上找到共识的。 这个世界上有许多语言。大量语言是不用分号作为EOS（End of Statement）的。有些偏执狂认为不用分号的语言都是垃圾，对此我没啥好说的。 有些语言也是可选分号，比如python。python是可以加分号作为语句结束的。当然绝大多数python程序员是不会加分号的（除了在一行里写多个语句）。所以python和js一样是可选分号！并且python的习惯是不写分号（仅在极少数情况下写）！ 也有不少人会指摘python的语法太特殊，比如缩进啥的……不能算是c-style的。不过即使是C风格的语言，也有不写分号的，比如groovy。groovy和js一样是可选分号！并且groovy的习惯是不写分号（仅在极少数情况下写）！ 所以至少从同样两个是可选分号的语言来看，不写分号在实践上是可行的。毕竟，既然被设计为可选，那么合理的推断是：语言的设计初衷是倾向于鼓励不写分号。 实际上，不少人（包括我）认为，c-style的分号本来就是多余的。为什么这么说？因为明确的EOS只是给编译器的提示而已。如果漏了分号，编译器会报错。既然它都报错了，显然它知道这里应该有EOS。既然它知道，那么干嘛还要我写？ 给编译器以hint，这在几十年前是一个平衡编译器和用户成本的设计。某些语言（如Fortran、Basic等）选择用换行来作为EOS，这样每行只能一个语句，并且一个语句折行必须用特殊的接续符号。某些语言（如C）则选择了通过分号来达成，这样每行可以多个语句，并且一个语句也可以分布在多行。平心而论，我更喜欢前一种策略。不过现实是c-style的语法流传更广，至少当前的工业主流语言都是c-style的。 在c-style语言中，如果既要允许自由折行，又要避免额外的EOS（分号），编译器会较为复杂，光靠看token是不能确定语句是否结束的（即换行处有可能是语句结束，也有可能不是）——尽管在实践中只需要很少的规则，人就能一目了然的看清语句是否结束，但是parser要处理一切的极端情况，例如在换行前插入注释到底怎么算。而C的设计是遵循所谓worse is better的哲学，非常强调实现简单，一个明确的EOS对于编译器来说绝对是简单的。当初如果有人找K&amp;R去要求应该由编译器判断这里该不该是语句结束，我打包票肯定被K&amp;R扁死。有趣的是，lisp那一帮人更极端，如果你抱怨括号实在太密密麻麻的了，一定有人语重心长的告诉你S表达式才是王道。 其实像C++编译器也已经复杂到超乎想象，按理说可选分号真是小事一桩，但它因为要保持对C的完全兼容，所以还是必须写分号。 python和groovy的parser则都是有名的复杂。这并不完全由允许分号可选造成，但是可选的分号其实是整个语法设计哲学的一环。如Groovy的哲学是PHIM——Parse how I mean。 话说python的语法设计真的非常有意思。它也有问题，比如tab和空格混合，计算机之子@程劭非 曾经惊叹，居然有语言能通过改变注释（注释中可定义tabsize）就改变了语义和行为，真是极品。 当然后来者会吸取教训，比如coffeescript和jade之类的，也都是依赖缩进，但是都不允许tab和空格混用。 所以tab/sp这是python的坑。Guido Van Rossum现在就后悔了。从某种程度上说，JavaScript的分号就有点类似python的tab/sp问题。 正如混合tab/sp是出自GVR的良好初衷（让你们想用啥就用啥），可选分号也是出自BE的良好初衷（随便你写不写）。也如同tab/sp一样，良好的初衷并不代表就没有隐患。之所以python、groovy就没有可选分号的争议，而js就有争议，其实正说明js存在一些问题。 其实Groovy历史上也是有关于可选分号争议的，参见：Groovy在EOS问题上的痛苦权衡 。不幸的的是，与Groovy早期经过社区激烈的讨论才得到稳定语法不同，JS是一门早熟的语言，一些早期的设计失误没有机会被修复。自动分号插入算法就是其中之一。总体上，自动分号插入算法还算正常，但是在一些小地方留下了不易发觉的坑。比如return语句。 return{ a:1} 在return后会自动插入分号，导致完全违背期望的结果。 这一古怪行为往往被解释为在JS中应采用一行内跟随大括号的书写风格（即Java的风格，或者说是K&amp;R的C的原初风格，而不是C#风格），其实追根述源，问题还是出在分号上。 不要插分号的地方被插了分号，这挺坑爹了，但更更坑爹的是想要插的结果没插。这就是括号的问题。如果下一行的开始是 ( 、 [ 上一行的结尾不会被加上; 。 如：a = b(function(){…})() 会被解释为a = b(function(){…})() 其实如果我们真想表达上述代码，通常会这样写：a = b(function(){ … })() 再如：a = b[1,2,3].forEach(function(e){ console.log(e)}) 实际效果等价于a = b[3].forEach(function(e){ console.log(e) }) 坑爹的是，搞不好这代码说不定还能运行！你要事后通过调试发现这些错误是相当滴痛苦啊。 当然这也不能全赖BE。在JS的早期，还没有数组迭代方法 Array.prototype.forEach/map/filter…等，也没有今天常见的(function(){…})()惯用法，所以这个问题其实很不明显。但是到了今天，这些坑爹的问题就都冒出来了。 实际上，+/-也有问题，但是我们几乎不会在实践中遇到。因为你根本不可能会写行首以 + / - 开始的语句，除了 ++i 之类的语句（但是其实我们都会写成 i++ ）。 不过这些问题的解决方案其实也很简单。只要在 [、 ( 、 + 、- 、\\之前加;就可以了：a = b ;(function(){ … })() a = b ;[1,2,3].forEach(function(e){ console.log(e) }) 有些同学觉得这样很丑。没问题，你可以用void替代;。 也有不少人觉得这是一种“不一致”，需要记住额外的法则。 我承认采取这样一种方法你必须记住一些特例。但是几乎所有的语言都有一些历史原因导致的坑，并且JS也不止这一个坑。更关键的是即使你采用了总是写;的方法，仍然是有关于EOS的坑，因为造成问题的asi特性仍然存在。比如之前提到的return后面会自动插分号。 总是写分号，相比不写分号但是edge case要在行首加分号，看上去要更“简单”，但这只是描述简单，实际做起来未必更简单。 比如你必须要记得，function表达式后面也要写;！ 如：function a() { …}[1,2,3].forEach(…) 这代码是没问题的，但是你改成var a = function () { … } [1,2,3].forEach(…) 就有问题了！这坑爹！ 对于“始终加分号派”来说，结果就会变成函数后面也一定要加分号。（你分得清函数声明和函数表达式吗？坑爹啊，不如都加！）但是为什么函数就加而 if … {} 或 for (…) {…} 结构里的大括号后面就不加分号呢？这不是也不一致嘛。 而且，同样是一条特殊规则，行首加分号的规则比函数表达式后面加分号的规则其实要简单！ var a = function () { … } [1,2,3].forEach(…) 还是以上面代码为例。 行首是否要加分号，我只要看本行的第一个字符就可以了。因为对于object[prop]这样的意图，其实没有程序员会写出object[prop]这样的代码。如果他要折行，一定是写成object[ prop]所以行首第一个字符如果是括号，毋庸置疑的，这一定是一个新语句的开始。 反过来，你如果要判断 } 后面是否要加;，你得向上回溯，看清楚整段代码是一个结构呢？还是一个函数？如果是函数的话，是函数声明呢？还是函数表达式！ 许多时候，你可能向上翻几页还没找到对应的 { ！或者已经忘记了是几层缩进了！ 人不是机器，总有可能忘记写分号。上面的分析说明，对于人来说，行首特例加分号的策略其实更简单易行。而总是加分号的策略听上去简单，执行起来却难！（除非你的策略最后变成了所有 } 之后都加分号——我真见过有人这么做的。） 对人是这样，下面再来看看对机器（引入工具）的情形。特别的，因为有不少人表示他遵循总是写分号的方式是因为他严重依赖jslint。所以我就拿jslint开刀。 对于总是加分号的策略，你希望工具能提示你哪里缺少分号。但是实际情况是，你必须尽量避免写出有歧义的跨行语句，因为工具很难判断是有意为之，还是忘记写;。 比如：a = b (function(){ … })(); 这代码在jslint的提示是：Expected ‘(‘ at column 5, not column 1. 请问你是应该真的按照它的提示把括号移动到b后面吗？？ 仔细考虑一下，你就知道这个问题不好回答。因为jslint给出的建议其实是基于“这是合法的代码，只是格式不妥”。虽然我们都知道这更可能是忘记写分号。 再来一个更坑爹的例子： /jslint white: true */var a,b,c,d,e,f,g,h,i,j,k,l,m,o,s;a=b+cd-e /f/g-h*i/j/f/g.exec(s).map(f); 这段代码在jslint里是不报错的！！！ 但是我们是可以看出来这代码很有可能是缺少分号。 这里可以看出，如果排除了whitespace的格式提示（这事儿还是挺常见的，毕竟许多人不喜欢被强制加那么多空格规则），jslint其实无法在我们最需要帮助的时候帮到我们！因为它无法判断这个地方到底是有意为之（不用;而跨行），还是忘记写;。 反过来说，如果采取行首特例加;的习惯，其实工具是很容易判断你是否忘记加了分号。如果加上一些对缩进信息的判断来排除极少数不良的折行习惯（出warn即可），工具甚至能自动把所有这类分号都加上。 两种策略： 我总是写分号，让工具告诉我哪里我忘记写了（但是有时候可能还报不出来，或报了个其他信息） 我总是不写分号，让工具自动把（由于语言设计缺陷所要求的）必须的分号加上去 哪种更好？ 总结： 我所推荐的不写分号的方式，其实不仅是不写分号，而是同时采用更严格的跨行策略，即只允许在当前行处于未完成状态时跨行（就像你在jsshell中输入代码一样）。这条规则其实并不需要特别强制，因为绝大多数程序员一直就是这样在执行。诚然，存在少数人习惯写这样有歧义的折行代码： a = b + c + d + e + f + g 但是这个习惯是很容易纠正。并且工具根据缩进等信息是完全能检测到的。 说到这里，也许有些同志认为这只能说明jslint太挫，不能证明到处写;的风格不好。因为工具也可以同时加上其他限制嘛。不过你仔细想想，可以发现这是一个悖论。如果jslint够智能，引入了其他与分号无关的代码风格要求，比如空格和缩进，还有折行风格，确实也可以更精确的找到所有漏掉分号的地方。但是那无非再次证明了一点：编译器（代码分析器）完全可以知道哪里应该有EOS。既然所有的分号其实可以由机器自行加上，那么我们自己还要手写所有分号的意义到底在哪里？！","path":"2019/05/28/2418838881/","date":"05-28","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"Markdown 语法简要","text":"标题一级标题# 一级标题 二级标题## 二级标题 三级标题### 三级标题 四级标题#### 四级标题 五级标题##### 五级标题 六级标题###### 六级标题 列表无序列表 + - * 效果相同 1 2 3 - 1- 2- 3 有序列表 1 2 3 1. 12. 23. 3 引用 这是一条引用信息 &gt; 这是一条引用信息 分割线 + - * 效果相同 --- 代码块` 代码 ` 代码 粗体与斜体粗体 **粗体** 斜体 *斜体* 图片与链接插入链接百度链接 [百度链接](http://www.baidu.com) Markdown 插入图片![图片描述](图片地址) hexo 常用命令新建文章hexo new &quot;文章名称&quot; 使用双引号可以避免特殊字符问题 新建页面hexo new page &quot;页面名称&quot; 生成静态页面至public目录hexo generate 开启预览访问端口（默认端口4000，’ctrl + c’关闭server）hexo server 将目录部署到GitHubhexo deploy 需要插件 查看帮助hexo help 查看Hexo的版本hexo version","path":"2019/05/28/2937147501/","date":"05-28","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"位运算的常用技巧","text":"1、找出一个没有重复的数 给你一组整型数据，这些数据中，其中有一个数只出现了一次，其他的数都出现了两次，让你来找出一个数 。这道题可能很多人会用一个哈希表来存储，每次存储的时候，记录 某个数出现的次数，最后再遍历哈希表，看看哪个数只出现了一次。这种方法的时间复杂度为 O(n)，空间复杂度也为 O(n)了。 然而我想告诉你的是，采用位运算来做，绝对高逼格！ 我们刚才说过，两个相同的数异或的结果是 0，一个数和 0 异或的结果是它本身，所以我们把这一组整型全部异或一下，例如这组数据是：1， 2， 3， 4， 5， 1， 2， 3， 4。其中 5 只出现了一次，其他都出现了两次，把他们全部异或一下，结果如下： 由于异或支持交换律和结合律，所以: 1^2^3^4^5^1^2^3^4 = （1^1)^(2^2)^(3^3)^(4^4)^5= 0^0^0^0^5 = 5。 也就是说，那些出现了两次的数异或之后会变成0，那个出现一次的数，和 0 异或之后就等于它本身。就问这个解法牛不牛逼？所以代码如下 int find(int[] arr)&#123; int tmp = arr[0]; for(int i = 1;i &lt; arr.length; i++)&#123; tmp = tmp ^ arr[i]; &#125; return tmp;&#125; 时间复杂度为 O(n)，空间复杂度为 O(1)，而且看起来很牛逼。 这里说明一下，这个方式适合一个数出现了奇数次，其他数都出现了偶数次2、m的n次方 如果让你求解 2 的 n 次方，并且不能使用系统自带的 pow 函数，你会怎么做呢？这还不简单，连续让 n 个 m 相乘就行了，代码如下： pow(int n)&#123; int tmp = 1; for(int i = 1; i &lt;= n; i++) &#123; tmp = tmp * m; &#125; return tmp;&#125; 不过你要是这样做的话，我只能呵呵，时间复杂度为 O(n) 了，怕是小学生都会！如果让你用位运算来做，你会怎么做呢？ 我举个例子吧，例如 n = 13，则 n 的二进制表示为 1101, 那么 m 的 13 次方可以拆解为: m^1101 = m^0001 * m^0100 * m^1000。 我们可以通过 &amp; 1和 &gt;&gt;1 来逐位读取 1101，为1时将该位代表的乘数累乘到最终结果。直接看代码吧，反而容易理解： int pow(int n){ int sum = 1; int tmp = m; while(n != 0){ if(n &amp; 1 == 1){ sum *= tmp; } tmp *= tmp; n = n &gt;&gt; 1; } return sum;}时间复杂度近为 O(logn)，而且看起来很牛逼。 3、交换两个数 交换两个数相信很多人天天写过，我也相信你每次都会使用一个额外来变量来辅助交换，例如，我们要交换 x 与 y 值，传统代码如下： int tmp = x;x = y;y = tmp;这样写有问题吗？没问题，通俗易懂，万一哪天有人要为难你，不允许你使用额外的辅助变量来完成交换呢？你还别说，有人面试确实被问过，这个时候，位运算装逼大法就来了。代码如下： x = x ^ y // （1）y = x ^ y // （2）x = x ^ y // （3）我靠，牛逼！三个都是 x ^ y，就莫名交换成功了。在此我解释下吧，我们知道，两个相同的数异或之后结果会等于 0，即 n ^ n = 0。并且任何数与 0 异或等于它本身，即 n ^ 0 = n。所以，解释如下： 把（1）中的 x 带入 （2）中的 x，有 y = x^y = (x^y)^y = x^(y^y) = x^0 = x。 x 的值成功赋给了 y。 对于（3）,推导如下： x = x^y = (x^y)^x = (x^x)^y = 0^y = y。 这里解释一下，异或运算支持运算的交换律和结合律哦。怎么样？有木觉得很多牛逼？ 我在我的公众号：苦逼的码农，该公众号主要专注于写算法、计算机基础以及Java相关文章，也总结了很多算法技巧，欢迎大家的关注。 说到算法技巧，必须再给大家再讲一波好用的算法技巧，不信，你继续往下看 巧用数组下标 数组的下标是一个隐含的很有用的数组，特别是在统计一些数字，或者判断一些整型数是否出现过的时候。例如，给你一串字母，让你判断这些字母出现的次数时，我们就可以把这些字母作为下标，在遍历的时候，如果字母a遍历到，则arr[a]就可以加1了，即 arr[a]++; 通过这种巧用下标的方法，我们不需要逐个字母去判断。 我再举个例子： 问题：给你n个无序的int整型数组arr，并且这些整数的取值范围都在0-20之间，要你在 O(n) 的时间复杂度中把这 n 个数按照从小到大的顺序打印出来。 对于这道题，如果你是先把这 n 个数先排序，再打印，是不可能O(n)的时间打印出来的。但是数值范围在 0-20。我们就可以巧用数组下标了。把对应的数值作为数组下标，如果这个数出现过，则对应的数组加1。 代码如下： public void f(int arr[]) { int[] temp = new int[21]; for (int i = 0; i &lt; arr.length; i++) { temp[arr[i]]++; } //顺序打印 for (int i = 0; i &lt; 21; i++) { for (int j = 0; j &lt; temp[i]; j++) { System.out.println(i); } } }利用数组下标的应用还有很多，大家以后在遇到某些题的时候可以考虑是否可以巧用数组下标来优化。 巧用取余 有时候我们在遍历数组的时候，会进行越界判断，如果下标差不多要越界了，我们就把它置为0重新遍历。特别是在一些环形的数组中，例如用数组实现的队列。往往会写出这样的代码： (int i if (pos &lt; N) &#123; //没有越界 // 使用数组arr[pos] else &#123; pos = 0;//置为0再使用数组 //使用arr[pos] &#125; pos++;&#125; 实际上我们可以通过取余的方法来简化代码 (int i //使用数组arr[pos] (我们假设刚开始的时候pos &lt; N) pos = (pos + 1) % N;&#125; 巧用双指针 对于双指针，在做关于单链表的题是特别有用，比如“判断单链表是否有环”、“如何一次遍历就找到链表中间位置节点”、“单链表中倒数第 k 个节点”等问题。对于这种问题，我们就可以使用双指针了，会方便很多。我顺便说下这三个问题怎么用双指针解决吧。 例如对于第一个问题 我们就可以设置一个慢指针和一个快指针来遍历这个链表。慢指针一次移动一个节点，而快指针一次移动两个节点，如果该链表没有环，则快指针会先遍历完这个表，如果有环，则快指针会在第二次遍历时和慢指针相遇。 对于第二个问题 一样是设置一个快指针和慢指针。慢的一次移动一个节点，而快的两个。在遍历链表的时候，当快指针遍历完成时，慢指针刚好达到中点。 对于第三个问题 设置两个指针，其中一个指针先移动k个节点。之后两个指针以相同速度移动。当那个先移动的指针遍历完成的时候，第二个指针正好处于倒数第k个节点。 你看，采用双指针方便多了吧。所以以后在处理与链表相关的一些问题的时候，可以考虑双指针哦。 设置哨兵位 在链表的相关问题中，我们经常会设置一个头指针，而且这个头指针是不存任何有效数据的，只是为了操作方便，这个头指针我们就可以称之为哨兵位了。 例如我们要删除头第一个节点是时候，如果没有设置一个哨兵位，那么在操作上，它会与删除第二个节点的操作有所不同。但是我们设置了哨兵，那么删除第一个节点和删除第二个节点那么在操作上就一样了，不用做额外的判断。当然，插入节点的时候也一样。 有时候我们在操作数组的时候，也是可以设置一个哨兵的，把arr[0]作为哨兵。例如，要判断两个相邻的元素是否相等时，设置了哨兵就不怕越界等问题了，可以直接arr[i] == arr[i-1]?了。不用怕i = 0时出现越界。 当然我这只是举一个例子，具体的应用还有很多，例如插入排序，环形链表等。 5、找出不大于N的最大的2的幂指数 传统的做法就是让 1 不断着乘以 2，代码如下： int findN(int N){ int sum = 1; while(true){ if(sum * 2 &gt; N){ return sum; } sum = sum * 2; }}这样做的话，时间复杂度是 O(logn)，那如果改成位运算，该怎么做呢？如果要弄成位运算的方式，很多时候我们把某个数拆成二进制，然后看看有哪些发现。这里我举个例子吧。 例如 N = 19，那么转换成二进制就是 00010011（这里为了方便，我采用8位的二进制来表示）。那么我们要找的数就是，把二进制中最左边的 1 保留，后面的 1 全部变为 0。即我们的目标数是 00010000。那么如何获得这个数呢？相应解法如下： 1、找到最左边的 1，然后把它右边的所有 0 变成 1 2、把得到的数值加 1，可以得到 00100000即 00011111 + 1 = 00100000。 3、把 得到的 00100000 向右移动一位，即可得到 00010000，即 00100000 &gt;&gt; 1 = 00010000。 那么问题来了，第一步中把最左边 1 中后面的 0 转化为 1 该怎么弄呢？我先给出代码再解释吧。下面这段代码就可以把最左边 1 中后面的 0 全部转化为 1， n |= n &gt;&gt; 1;n |= n &gt;&gt; 2;n |= n &gt;&gt; 4;就是通过把 n 右移并且做或运算即可得到。我解释下吧，我们假设最左边的 1 处于二进制位中的第 k 位(从左往右数),那么把 n 右移一位之后，那么得到的结果中第 k+1 位也必定为 1,然后把 n 与右移后的结果做或运算，那么得到的结果中第 k 和 第 k + 1 位必定是 1;同样的道理，再次把 n 右移两位，那么得到的结果中第 k+2和第 k+3 位必定是 1,然后再次做或运算，那么就能得到第 k, k+1, k+2, k+3 都是 1，如此往复下去…. 最终的代码如下 int findN(int n){ n |= n &gt;&gt; 1; n |= n &gt;&gt; 2; n |= n &gt;&gt; 4; n |= n &gt;&gt; 8 ; n |= n &gt;&gt; 16;// 整型一般是 32 位，上面我是假设 8 位。 return (n + 1) &gt;&gt; 1;}这种做法的时间复杂度是 O(log(logn))，重点是，高逼格。 6、找出两个没有重复的数 对于第一题【找出没有重复的数】 给你一组整型数据，这些数据中，其中有一个数只出现了一次，其他的数都出现了两次，让你来找出一个数 。有人问如果有2个数出现了一次，其他数都出现了一次，那还能用位运算来找出这两个数吗？ 答是必须的，假如这两个出现一次的 数 分别为 A, B，则所有 数 异或后的结果为 A^B，这时我们遇到的问题是无法确定 A，B的值。 由于 A 和 B 是不一样的值，所以 A^B 的结果不为 0，也就是说，这个异或值的二进制中某一位为1。显然，A 和 B 中有且仅有一个数的相同位上也为 1。 这个时候，我们可以把所有 数 分为两类，一类在这个位上为 1，另一类为 0，那么对于这两类，一类会含有 A，另一类会含有 B。于是，我们可以分别计算这两类 数 的异或值，即可得到 A 和 B 的值。 举个例子吧：1、假如那两个没有重复的数分别是 a, b。那么把所有数的异或之后，最终所得到的值为 a^b。我们令 result = a^b.2、由于 a 和 b 的值不相等，所以 a^b 的值不为0，所以 result 的二进制位中一定存在某一个位为1（例如result = 5的二进制表达为00…00101，则第一位和第三位都是1）。我们假设第k位为1.3、显然，由于 result 的第 k 位为1，则a和b的第k位一定是一个为1，一个为0。假设a的第k位为0，b为1.4、我们把数组的所有元素进行分类，分成A, B两类，让A类的元素第k位有0，B类元素的第k类为1。5、那么a存在于A类中，b存在于B类中，那么这个就简单了，问题变成了和文章的第一题一样，从A类中找出一个出现一次的元素，B类中找出一个出现一次的元素了。 判断一个正整数数 N 是否为 2 的幂次方。 如果一个数是 2 的幂次方，意味着 N 的二进制表示中，只有一个位 是1，其他都是0。我举个例子，例如 2^0 = 0…..0001 2^1 = 0…..0010 2^2 = 0….0100 2^3 = 0..01000 ….. 所以呢，我们只需要判断N中的二进制表示法中是否只存在一个 1 就可以了。不过我们可以用上面第5题中的做法找出不大于N的最大的2的幂指数 M，然后判断找处理的那个数M是否和N相等。这种做法，比一个一个着去统计N的二进制位中是否只有一个1快多了。 所以呢，可以写出如下的代码 boolean judge(int n){ n |= n &gt;&gt; 1; n |= n &gt;&gt; 2; n |= n &gt;&gt; 4; n |= n &gt;&gt; 8; n |= n &gt;&gt; 16;// 我这里假设是32位的正整数 return (n + 1) &gt;&gt; 1 == n }然后，还有更加牛逼的解法，代码如下： boolean judege(int n){ return n &amp; (n - 1) == 0;//}卧槽，这也太牛逼了吧，一行代码解决，一行代码解决。这里我解释一下， n &amp; (n - 1) 这个运算，会把 n 的二进制位表示法中最左边的 1 变成 0。所以呢，经过这个运算之后，如果 n &amp; ( n - 1) 的结果是 0,说明 n 中只有一个 1。牛逼啊！ ACM中常使用二进制数1n位的0/1状态来表示一个由1n组成的集合，也就是第k位为1则代表数k在集合中，于是为了提高效率就有了各种花式枚举集合的方法： 1) 要求集合中不能有两个相邻的元素 if ((mask &gt;&gt; 1) &amp; mask) continue; 2) 在限定必须不取某些元素的前提下枚举子集 // mask的第x位为0表示x必须不在子集中(原集合中不含这个元素)： for (int mask1 = mask; mask1 &gt;= 0; mask1 = (mask1 - 1) &amp; mask) 3) 在限定必须取某些元素的前提下枚举子集 // mask的第x位为1表示x必须在子集中： for (int mask1 = mask; mask1 &lt; (1 &lt;&lt; m); mask1 = (mask1 + 1) | mask) 4) 找出二进制中恰好含有 k个1的所有数 for (int mask = 0; mask &lt; 1 &lt;&lt; n; ) { int tmp = mask &amp; -mask; mask = (mask + tmp) | (((mask ^ (mask + tmp)) &gt;&gt; 2) / tmp); }","path":"2019/05/28/672772678/","date":"05-28","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"常用 Chrome 扩展","text":"以下是我收集的比较好用的Chrome扩展程序安装文件 网页广告拦截 链接 浏览器脚本增强 链接 网页设计辅助 链接 和谐网站登陆器 链接 网页视频探测 链接 链接 Vue开发辅助工具 链接","path":"2019/05/28/2206723729/","date":"05-28","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Four pillars for US hegemony","text":"Four pillars for US hegemonyBy 金灿荣 上面翻译过来就是美国称霸世界的四根支柱，源自B站上金灿荣教授在《百年未有之大变局》中对美国称霸世界的分析 下面是金教授对美国四根支柱的分析： 美国现在是世界唯一霸主。他们的霸权建立在四根支柱上，分别是： 第一个就是高科技。 第二是强大的美军。 第三是美元霸权。 第四是好莱坞象征的话语权。 大家知道美国控制世界的诀窍： 第一就是全世界引进人才搞高科技。 美国的产业虽然放弃了很多，他留下了产业绝对是利润丰厚的。 于是美军拿到的装备就是最好的，而且财政基础特别好。 美国去年的军费开支7169亿美元，等于第2名到第15名的总和。 基本上就是美军打别人，不是别人打他。别人打他的唯一的情况就是，人家不想活了变恐怖分子了。想活得正常人都不会去打他。除非就是沙特，老子不活了。 于是一个后果是不是国际资本都信任他，他就有美元霸权。 有了美元霸权，美国的精英层就实现了人生的第一大理想：把你的钱变我的钱了。 然后他的资本就特别便宜，然后他开始正循环： 投资高等教育、投资科研，然后投资好莱坞，好莱坞影片就是好看，然后你在欣赏好莱坞的过程中，是不是就接受他的价值观，然后美国精英层实现了人生第二大理想：把我的想法变成你的想法。 分析起来实际上美国制霸的本质是通过正向循环配合复利效应来使自身不断发展壮大。 那么对于我们自身来说，如果我们所学得的知识，所掌握的技术，从不同项目中积累的经验 不能形成闭环或者说循环的话，显然是很不利的。","path":"2019/05/28/1395599601/","date":"05-28","excerpt":"Four pillars for US hegemonyBy 金灿荣 上面翻译过来就是美国称霸世界的四根支柱，源自B站上金灿荣教授在《百年未有之大变局》中对美国称霸世界的分析 下面是金教授对美国四根支柱的分析： 美国现在是世界唯一霸主。他们的霸权建立在四根支柱上，分别是： 第一个就是高科技。 第二是强大的美军。 第三是美元霸权。 第四是好莱坞象征的话语权。 大家知道美国控制世界的诀窍： 第一就是全世界引进人才搞高科技。 美国的产业虽然放弃了很多，他留下了产业绝对是利润丰厚的。 于是美军拿到的装备就是最好的，而且财政基础特别好。 美国去年的军费开支7169亿美元，等于第2名到第15名的总和。 基本上就是美军打别人，不是别人打他。别人打他的唯一的情况就是，人家不想活了变恐怖分子了。想活得正常人都不会去打他。除非就是沙特，老子不活了。 于是一个后果是不是国际资本都信任他，他就有美元霸权。 有了美元霸权，美国的精英层就实现了人生的第一大理想：把你的钱变我的钱了。 然后他的资本就特别便宜，然后他开始正循环： 投资高等教育、投资科研，然后投资好莱坞，好莱坞影片就是好看，然后你在欣赏好莱坞的过程中，是不是就接受他的价值观，然后美国精英层实现了人生第二大理想：把我的想法变成你的想法。","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"消灭 Tomcat中的 淇℃伅","text":"解决方法：将Tomcat安装目录下的conf文件夹下的logging.properties打开将java.util.logging.ConsoleHandler.encoding = UTF-8 这句话改为java.util.logging.ConsoleHandler.encoding = GBK 保存，重启Tomcat即可 对于 8.5 两个日志窗口的乱码 需要讲异步的窗口编码也改成 GBK","path":"2019/05/16/4275925800/","date":"05-16","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"用 JavaScript 收集用户浏览数据","text":"同步 AJAX数据发回服务器的常见做法是，将收集好的用户数据，放在unload事件里面，用 AJAX 请求发回服务器。但是，异步 AJAX 在unload事件里面不一定能成功，因为网页已经处于卸载中，浏览器可能发送，也可能不发送。所以，要改成同步 AJAX 请求。 window.addEventListener('unload', function (event) &#123; let xhr = new XMLHttpRequest(); xhr.open('post', '/log', false); xhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded'); xhr.send('foo=bar');&#125;); 上面代码中，xhr.open()方法的第三个参数是false，表示同步请求。这种方法最大的问题在于，浏览器逐步将不允许在主线程上面，使用同步 AJAX。所以，上面代码实际上不能用。 异步 AJAX异步 AJAX 其实是能用的。前提是unload事件里面，必须有一些很耗时的同步操作。这样就能留出足够的时间，保证异步 AJAX 能够发送成功。 function log() &#123; let xhr = new XMLHttpRequest(); xhr.open('post', '/log', true); xhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded'); xhr.send('foo=bar');&#125;window.addEventListener('unload', function(event) &#123; log(); // a time-consuming operation for (let i = 1; i &lt; 10000; i++) &#123; for (let m = 1; m &lt; 10000; m++) &#123; continue; &#125; &#125;&#125;); 上面代码中，强制执行了一次双重循环，拖长了unload事件的执行时间，导致异步 AJAX 能够发送成功。 追踪用户点击setTimeout也能拖延页面卸载，保证异步请求发送成功。下面是一个例子，追踪用户点击。 // HTML 代码如下// &lt;a id=\"target\" href=\"https://baidu.com\"&gt;click&lt;/a&gt;const clickTime = 350;const theLink = document.getElementById('target');function log() &#123; let xhr = new XMLHttpRequest(); xhr.open('post', '/log', true); xhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded'); xhr.send('foo=bar');&#125;theLink.addEventListener('click', function (event) &#123; event.preventDefault(); log(); setTimeout(function () &#123; window.location.href = theLink.getAttribute('href'); &#125;, clickTime);&#125;); 上面代码使用setTimeout，拖延了350毫秒，才让页面跳转，因此使得异步 AJAX 有时间发出。 反弹追踪追踪用户点击，还可以使用反弹追踪（bounce tracking）。所谓”反弹追踪”，就是网页跳转时，先跳到一个或多个中间网址，以便收集信息，然后再跳转到原来的目标网址。 // HTML 代码如下// &lt;a id=\"target\" href=\"https://baidu.com\"&gt;click&lt;/a&gt;const theLink = document.getElementById('target');theLink.addEventListener('click', function (event) &#123; event.preventDefault(); window.location.href = '/jump?url=' + encodeURIComponent(theLink.getAttribute('href'));&#125;); 上面代码中，用户点击的时候，会强制跳到一个中间网址，将信息携带过去，处理完毕以后，再跳到原始的目标网址。谷歌和百度现在都是这样做，点击搜索结果时，会反弹多次，才跳到目标网址。五、Beacon API上面这些做法，都会延缓网页卸载，严重影响用户体验。为了解决网页卸载时，异步请求无法成功的问题，浏览器特别实现了一个 Beacon API，允许异步请求脱离当前主线程，放到浏览器进程里面发出，这样可以保证一定能发出。 window.addEventListener(‘unload’, function (event) { navigator.sendBeacon(‘/log’, ‘foo=bar’);});上面代码中，navigator.sendBeacon()方法可以保证，异步请求一定会发出。第一个参数是请求的网址，第二个参数是发送的数据。注意，Beacon API 发出的是 POST 请求。 ping 属性HTML 的标签有一个ping属性，只要用户点击，就会向该属性指定的网址，发出一个 POST 请求。 &lt;a href=\"https://baidu.com\" ping=\"/log?foo=bar\"&gt; click&lt;/a&gt; 上面代码中，用户点击跳转时，会向/log这个网址发一个 POST 请求。ping属性无法指定数据体，似乎只能通过 URL 的查询字符串携带信息。","path":"2019/05/14/1042058289/","date":"05-14","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"复利原理","text":"用于计算复利的增长趋势： 是不是感觉熟悉又陌生？ 没错，我们高中课本里的一个数学概念，相信你也一定学习过，还用它计算过许多应用题，甚至有些同学现在还能背得出这公式…. 可自从你毕业后，它好想就从此和你没什么关系了。 偶尔间，听到有人说它能让你财富自由？ 你翻出了课本，看着这个公式，两眼呆滞… 除了能想到去买个理财产品「利滚利」之外，并不知道该如何使用… P=现值？ 是指投资的本金吗？我现在钱很少啊，复利至少得先有钱投资吧… i=增长比例？ 我怎么知道增长比例会是多少，我买股票亏钱的多… 买理财产品？收益又低，还经常遇到风险，不敢买啊~ n=执行次数？ 一说复利，就让我等30年，那请你告诉我，我这10年怎么办？ F=终值？ 完全没头绪，还是放弃吧….. 明晃晃的一个公式写在那里，每个字母也都能看的懂，可为什么就是用不了？ 然后，你合上书，想想还是算了吧，复利公式从此又将束之高阁，这个「奇迹」就此变成了你的「遗迹」… 难道「复利」真的只能作为一个用在投资上的数学模型吗？ 如果真是这样，你确实太小瞧查理了… 那我们该如何使用复利？ 我们之所以不会使用复利，通常情况下就是被那个复杂的数学公式给困住了。 保罗·洛克哈特，在他的一本著作《一个数学家的叹息》中说：数学的本质是表达的艺术。 什么意思？ 数学应该是一个思考工具，表达工具，而不是计算工具。 我们一看到这个数学公式，就会想到计算，然后在这个不完美的世界中，寻找各种条件参数往公式里塞，但是发现竟然塞不进去，你就蒙圈了，然后就不知道这个公式该如何使用了，然后，就没有然后了…. 数学公式，是一种理想情况下的完美表达，可现实世界常常是不完美的。当你眼里只有公式的时候，你的思维就会被死死的限制在这个等式的两端，出不来…. 那我们应该如何使用这个复利公式呢？ 首先，就是不要将视线局限在公式的细节里「每一个字母代表什么意思，我应该如何去套用….」你要理解公式背后的思维方式，弄明白它到底是想表达一种什么逻辑关系？其次，你接着想一想，如果你现在面对一个小孩子，你会怎么描述这个公式呢？这个大白话的描述，很可能就是这个公式背后的那个思考方式。最后，把「具体的公式」抽象成为「思考方式」之后，就能将这个思维方式应用到其他地方了。听起来是不是很简单？ 这里暂停2分钟，再看一眼这个复利公式，你试着自己想一想，这个复利公式是想表达是什么逻辑关系？ … … 想到了吗？ 复利其实就是：当你做了事情A，就会导致结果B，而结果B又会加强A，如此不断循环，循环次数越多，A就越强大。其实就那么简单的一个逻辑。 基于这个逻辑，就能产生不断自我增强的复利效应。比如： 网站是复利增长： 流量越多，搜索权重越高；搜索权重越高，流量越多；如此往复…. 淘宝店是复利增长： 销量越高，排名越高；排名越高，销量越高；如此往复…. 电商平台是复利增长： 买家越多，商家就越多；商家越多，就能吸引越多的用户过来买东西；如此往复… 这样解释，是不是就特别简单了？ 那接下来你该怎么办？ 如何把这个模型应用到你的商业模式、个人成长、财富增值上来呢？ 接下来，我就一步步教你，如何设计一个拥有复利效应的模式出来。 设计复利效应的步骤： 第一步：找到必然关系 设计复利效应的第一步，一定要找到一个「支点」。 什么是支点？就是我做了A，是否能得到结果B？ 就像是「鸡生蛋，蛋生鸡」是否有这个必然的因果关系？ 所有的复利效应都是建立在这样的一个支点上的，如果这个支点不成立，复利效应就会轰然倒塌。 支点怎么找？ 答案是：看书！ 除非特殊情况下，一般不要去重新发明轮子。什么意思？ 就是不要自己去摸索着写个因果关系，然后用自己的时间和金钱来验证它是否正确。你的顿悟，很可能只是别人的基本功，你要学会站在巨人的肩膀上。 最高效的方式，就是去相关领域中，找到那些已经被验证过的结论，或者是一些基本常识，甚至是数学定律，来用作「支点」。 很多大佬喜欢讲「第一性原理」为什么？ 因为第一性原理就是那个必然为真的支点，从这个支点开始推演出的逻辑关系就必然为真。如果从这个点出发，设计出拥有复利效应的商业模式，就不会轰然倒塌。 比如你是做电商的，那必须熟记以下这个公式： 销售额=流量×转化率×客单价 这样你就知道，如果你想提高销售额，无非就是从流量，转化率，和客单价这几个维度入手去提高。 支点必须是公式吗？ 不一定，只要有必然的因果关系就可以，比如： 文章写的越好，转发量就越高； 价格越贵，销量就越低（凡勃仑效应除外）； 销量越高，排名就越高… 因果关系不一定要特别严格，连牛顿的物理定理都被推翻了，世界上没有100%绝对正确的因果关系，只要在大部分情况下，这个因果关系是成立的就行。 第二步：设计增强循环 就是B如何反过来增强A？ 第一种情况：他们之间天生就有增强循环比如「鸡生蛋，蛋生鸡」这是自然规律，彼此天然有复利效应。 再比如，我们常见的「利滚利」，你投资了一个理财产品，年化收益10%，你投入10万元，1年后获得1万元收益。然后把这1万元收益，再做为本金，就可以利滚利，产生复利效应了… 再比如：这两年非常火的网约车平台 打车的人越多，就会吸引越多的司机加入；更多的司机加入，打车的人就越容易打到车，也就能吸引更多的用户，如此往复，不断互相促进…. 这种天生有复利效应的模型，你只需要找到，并按这个逻辑落地执行出来就行。 第二种情况：需要补充要素的增强闭环天然有复利效应的模型并不是那么好找，大多数情况下是你找到了某个支点，做了动作A产生了结果B，但是B好像无法反过来增强A了，怎么办？ 比如在淘宝上，流量越多，销量越高；销量越高排名就越高，因此获得的流量就会越多。 可线下门店呢？没有平台给他排名，销量好并不能直接带来流量，怎么办？ 如何把销售额用来增强人流？ 这个时候，我们就需要在「销售额」和「门店人流」之间，增加一些环节，让他们之间连成一个「增强闭环」： 比如，销售额越多，意味着利润越多；利润多的话，是否可以把这些超额利润转化成新的分店，开在人流密集的地方呢？ 再用赚到的钱，开更多的门店….如此往复，在不考虑经营情况和市场变化的情况下，你开店的速度，理论上会越来越快，并产生复利效应。你就从一个单店变成了大型连锁店。 当然，你还可以设计其他的循环方式，比如你也可以把「超额利润」的部分折换成优惠券的形式，发放给老客户，两人同行8折优惠，通过优惠券带来新的人流。 第三步：重复与耐心为什么很多人找到了复利效应，比如说花了10万元买了年化收益10%的理财，但是没坚持2、3年就坚持不下去了？ 因为复利效应天然有个「缺陷」，就是在初期很漫长的一段时间段里，增效都非常低，低到你几乎感觉不到它在增长；当你已经走到50%的位置的时候，甚至怀疑它的存在，因为几乎感觉不到有变化啊！ 只有坚持走到某一个位置开始，可以称这个位置为「里程碑」，这个曲线才会急速上扬： 所以，你需要保持耐心，相信这条曲线一定会出现，相信复利的回报。然后不断重复做正确的事，做时间的朋友，静静等待那个里程碑的到来。 两个特殊的复利模型 现在你已经知道复利模型的基本设计步骤，接下来我会介绍两种特殊的复利模型： 第一种：加法运算→加幂运算什么意思？就是这件事情原来你是做加法的：F=10+1+1…..；现在变成幂次运算了：F=10(1.1)n 是不是想起文章开头讲的复利公式了？ 对的，这个就是标准的复利计算公式，可问题是，是什么导致它变成幂次运算的？ 我们讲2个例子来理解这个概念： 案例1：你的知识量是如何增长的？假如你不断的看书学习，那么请问，随着你读书的数量越来越多，你的知识量是按「算数」增长的，即每多读一本书「知识量+1」？ 还是按「指数」增长的，即每多读一本书「知识量增加1%」？ 答案是：都有可能，看你用哪种方式学习。 如果你把每一本书作为孤立的一本书来学习，那么他就是以加法的方式增长的。比如你学习了：复利增长、比例偏见、SWOT分析… 那应该怎么学才能产生复利效应，让知识指数增长呢？ 那你就要把新学到的知识，放到自己原有的知识储量中去，然后和其他知识产生关联。 比如你今天学习了「复利」这个新概念，如果只是作为一个孤立的点来学习的话，它就是一条公式，储存在你的脑中。 那么如何让它和你的原有知识产生关联呢？可以试着这样思考： 如何在设计产品时加入复利效应？ 如何在团队激励中加入复利效应？ 如何在商业模式里加入复利效应？ 复利效应和庞氏骗局是什么关系？ …… 可以在白纸上画草图，或者用脑图工具，或者直接写文字笔记，把你的想法记录下来，让这个复利概念，和你其他的各种知识做一次联结。（为什么我们每篇文章底部都会建议你做课后作业？就是想让你把新学到的知识和你的知识存量发生一次联结） 这样，这个新学到的知识，就不是孤立的存在，而是在你知识存量里「长」出来了一个新概念。 你的知识存量就像是一个偌大的网络图，每个知识点之间都有联结，而每新增一个知识，就像是在这个网络图中增加一个新节点，这个节点又和其他节点相连，联结的数量越多，这个网络的信息含量增加的也就越多，那么你的知识量就会按复利的方式指数增长。 案例2：乐高积木再说说乐高积木，乐高是全球最大的玩具公司，至今估值已达到2500亿元。 是什么缔造了这样的一个玩具帝国？ 是什么让孩子们对他的玩具爱不释手？ 他和其他玩具厂家又有什么区别呢？ 他们有一种标志性的玩具产品：是各种一面有凸粒，一面有可嵌入凸粒的凹槽的塑料积木。 目前乐高总共生产了不同颜色、不同形状的这种积木共有 9000多种，但是你猜由着9000多种不同积木可以组合成多少种玩法呢？ 官方给出的数据是：超过9.15亿种拼法，是积木数量的10万倍。 为什么会这样？ 因为他每创新出1款新积木，并不是多了1款新积木，而是所有旧积木，多了一种新玩法，每一款新积木，都可以和原来所有的积木发生关系，这就产生了复利效应！ 不仅是玩法的复利效应，也是销量的复利效应，因为拥有的套装越多，意味着你有更多的玩法和更多的创意，你就会越买越多，任何一款你都会想带回家，和原来的组合起来玩玩看… 第二种：量变→质变就是原来这个模型是没有复利效应的，但是由于其中某个环节的数值增长到一定程度之后，这个模型便拥有了复利效应。 比如说微信公众号文章的传播，他的逻辑是这样的： 一篇文章从公众号发出，有一部分人打开了文章，成为了第一批「直接阅读者」 直接阅读者中，有一部分人觉得文章不错，便分享到了朋友圈（分享的人数 = 直接阅读人数 × 分享率） 发到朋友圈的文章，又会带来新的浏览量… 而新带来的读者中，又会有一部分人将文章转发到朋友圈，又带来一批新的阅读量…. 因此，从逻辑上看，不断的有人分享到朋友圈，不断的带来新的阅读量，看似是一个「复利效应」的循环，但在这个环节中，有一个关键的指标：分享率 分享率的大小，决定了这个循环能循环多少次。 假设，公众号带来的直接阅读量=500，一个人转发到朋友圈带来的平均阅读量=7。那么我们就可以计算，在不同分享率下，能分别带来的总阅读量是多少： 在分享率=5%的情况下，总共循环了3次，共计带来745的阅读量； 在分享率10%的情况下，总共循环了9次，共计带来了1263的阅读量； 也就是说，分享率决定了循环次数，分享率越高，传播次数就越多，但整体上看，每次循环带来的新阅读量是越来越少的。因此，他并不是具有复利效应的模型。 那有没有一种情况，当阅读量提高到某一数值之后，每次循环带来的新流量变得越来越多了呢？ 经过计算，我们得出这个数值=14.5% 当分享率≥14.5%的时候，每一次循环带来的新流量就比之前一轮带来的流量更多，因此会带来更多的人分享到朋友圈…如此往复，不断增强，从理论上来说，这篇文章的阅读量就可以无限增长… 到了这个分享率之后，你就会听到“pong”的一声，朋友圈被刷屏了….","path":"2019/04/30/2948278912/","date":"04-30","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"复利与天朝","text":"生活在天朝的我们虽然看着GDP一个劲的猛涨，但是手里的钞票倒是却越来越不禁用了。 这是为什么呢？ 先让我们来看这样的一个故事。 30年前，一位农村的老大爷，努力奋斗了几年后攒下了1000块钱，这在当时可是一笔巨款，大爷舍不得花，全存在了银行里。 但在30年后，大爷去银行取出存款后却傻了眼，原来的1000块现在变成了2000多块。 虽然说存款数额上涨了，但是现在的2000块钱能买啥，能跟30年前的1000元相提并论吗？ 这样的故事还有很多，在此不一一列举，我们不禁要问，为什么复利模式在中国走不通？ 爱因斯坦曾经说过：复利堪称世界第八大奇迹，它的威力甚至超过了原子弹。 而著名的价值投资者巴菲特也证明了复利的威力，据传其年收益率是20%，在55间资产增长近万倍。 但是，在中国，似乎没有听说过哪个人是靠复利发了家的。 这是为什么呢？难道西方的月亮比中国的圆吗？ 这就不得不说一下通货膨胀，有的人也听过这个名词，也知道物价涨了就是通货膨胀，但是对中国的通货膨胀具体情况可能不太了解。 今天就来为大家梳理一下。 上面这张图，是全球经济数据网上统计出的一张图表，表示的是我国从2010年以来的通货膨胀情况。 在2010-2012年间，通货膨胀率最高处于6%，而在2013年之后，差不多每年都处于2%左右。 看到这里你是不是觉得并没有什么大惊小怪的，只有2%而已嘛！ 这就是微妙之处所在了，为什么是2%这个数字，因为要和国际接轨，美联储每年给美国经济定的通胀率指标是多少？2%。 因为根据西方的智囊团研究，2%通胀率是个最好的数据，所以咱也要向老美看齐，通货膨胀率给老板看到是2%就有功无过了。 但是实际上呢，中国的实际通胀率远比这个要高，说出来可能会吓到你。 在过去十年间，我国广义货币M2平均每年增长率为16.32%。 同样是在这十年中，我国GDP平均每年的增长率为8.92%。 学过经济学的，应该都知道著名的费雪方程式，MV=PT。 根据这个方程式可以算出： 在过去的10年间，中国每年的实际通货膨胀率竟然达到了7.4%。 在这里想问问大家，在中国，除了暴雷的P2P,你去买哪个理财产品能跑得赢通胀？ 银保监会主席郭树清曾经说过:理财产品超过6%，要打个问号，超过8%很危险，超过10%就要做好损失全部本金的准备了。 那么通货膨胀率超过7%，怎么就没人提了呢？ 还是来看一下我们之前的一张表： 这张表说的是每年的收益率不同年限所能带来的资金增值倍数，其实把收益率换成通胀率也一样行得通。 按照7.4%的通胀率，在50年后，你就要面临资产缩水35倍的风险。就是说，你原先资产有35万，在50年后，就只相当于现在的1万了。 所以别再说老百姓们太过贪婪，竟然会去冒着血本无归的风险去投那些高收益的P2P平台。因为就算不投，过了几十年也跟握着一堆废纸没什么区别。 也别再说什么结婚女方要求有房是势利眼了，因为就过去几十年，房子是唯一跑赢通胀的东西，房子这东西就是能给人安全感。","path":"2019/04/30/2814458634/","date":"04-30","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"合理设计条件分支","text":"首先抛开剂量谈毒性都是耍流氓 在使用条件判断语句的地方，如果代码量小，需要判断的场景少的话， 那么没有比 if-else 更合适的语句，比如下面这样 if(object.getIndex() &gt; 0) &#123; //do something&#125; else &#123; //do other things&#125; 那在什么情况下 if-else 才会变差呢？ 以上面的代码为例子，当需要判断的情况逐渐增加的时候，上面的代码可能会变的难以维护。 在进阶高级开发的路上，应该逐步培养起这种前瞻意识， 即使在代码还在起步阶段，应该要能够看到将来代码发展的趋势， 比如上面的代码，当情况越来越多的时候，if-else可能会发展出许多个分支： 这是完全可能的，以我的经验来说就在不少项目上见过这样的代码。 而且代码执行块中的逻辑可能在几次迭代后变的非常复杂 使代码清晰，可以使用switch break/return 来代替 if-else 两种解决方案 抽象到方法 如何重构掉这段代码 对于这种代码我们重构的目标可以有两个深度，看自己强迫症的严重程度决定 · 继续用 if-else，只达到剥离执行代码块 · 用工厂模式去耦合 对于这两种其实不是非此即彼的关系，而是优化深度不同。第一种相对比较简单，可以重构成下面这样子 代码清爽了很多， 现在这段代码可以清楚的看出来都处理了哪些情况，条件判断的代码只关注了条件的不同， 而对于不同条件的具体处理逻辑我们剥离到了其他地方， 这样即使写到脑袋迷糊，也不至于说漏了哪个条件没判断。 抽象到类 （使用工厂模式和多态） 进一步优化 在上面的优化之后，如何再用工厂模式来继续重构呢？ 从上的代码看的出来，不同的条件下，执行的逻辑是不同的，那么可以把这种执行逻辑抽象出来，用多态的概念来定义不同的执行方式。 完成了这一步之后，就可以把代码块中不同条件下的方法抽到各个不同的具体类里面去了， 还可以进一步优化吗？可以的，甚至这里的条件判断都可以不要，我们可以定义一个工厂来把 new ExecutorWithTag()这件事给包了， 对工厂模式还有印象吗，上面这段代码在我之前的工厂模式一文里出现过，这里可以算是工厂模式的一个实际应用。 在经过这一轮重构之后，我们之前在一个类里面写的那堆代码已经抽离到多个不同的类里了， 现在在原来的类里的代码变成怎样了呢， 重构之后各个Executor和主类中的耦合已经降到很低了。","path":"2019/04/24/3043579305/","date":"04-24","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"杰克鸡的传送门","text":"杰克鸡系列系统传送门 使用方法： 复制补丁到 bin 目录下 对bin目录中的下面两个文件添加参数 idea64.exe.vmoptionsidea.exe.vmoptions -javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA 2017.1.5\\bin\\补丁文件.jar 启动杰克鸡，选择激活码激活模式 输入下面的激活信息 &#123;\"licenseId\":\"TestLicenseId\",\"licenseeName\":\"user\",\"assigneeName\":\"\",\"assigneeEmail\":\"TestLicense@gmail.com\",\"licenseRestriction\":\"Test License\",\"checkConcurrentUse\":false,\"products\":[&#123;\"code\":\"II\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"DM\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"AC\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"RS0\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"WS\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"DPN\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"RC\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"PS\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"DC\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"RM\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"CL\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"PC\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"DB\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"GO\",\"paidUpTo\":\"3099-12-31\"&#125;,&#123;\"code\":\"RD\",\"paidUpTo\":\"3099-12-31\"&#125;],\"hash\":\"2911276/0\",\"gracePeriodDays\":7,\"autoProlongated\":false&#125; 补丁版本 试用范围 4.2 最高 2018.3.x 2.10 最高 2018.2.x","path":"2019/04/23/3808206341/","date":"04-23","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Undertow 配置参数","text":"SpringBoot 替换默认的Tomcat &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- 从依赖信息里移除 Tomcat配置 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 添加 Undertow依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;&lt;/dependency&gt; ``` 配置参数io-threads = CPU核心数量 * 2worker-threads= io-threads * 8``` ymlserver: undertow: io-threads: 4 worker-threads: 32","path":"2019/04/23/3383294709/","date":"04-23","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"扫描登陆流程详解","text":"示例： ①：用户 A 访问微信网页版，微信服务器为这个会话生成一个全局唯一的 ID，上面的 URL 中 obsbQ-Dzag== 就是这个 ID，此时系统并不知道访问者是谁。 ②：用户A打开自己的手机微信并扫描这个二维码，并提示用户是否确认登录。 ③：手机上的微信是登录状态，用户点击确认登录后，手机上的微信客户端将微信账号和这个扫描得到的 ID 一起提交到服务器 ④：服务器将这个 ID 和用户 A 的微信号绑定在一起，并通知网页版微信，这个 ID 对应的微信号为用户 A，网页版微信加载用户 A 的微信信息，至此，扫码登录全部流程完成 扫码登录看起来神奇，主要是因为微信 APP 扫自家的码会做一些普通二维码软件不会做的额外的操作，那就是将当前已登录的微信和扫出来的 ID 提交到微信服务器，类似的应用还有扫码支付、扫码加公众号等功能","path":"2019/04/23/3728873280/","date":"04-23","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"使用 Docker 来部署应用","text":"Doker是啥轻量级虚拟化 包含了一个简易的Linux 文件系统 与传统的虚拟化最大的区别是更加轻量，没有了操作系统 只有相关应用环境和应用，主要实现了虚拟环境和应用隔离 三要素 仓库 仓库 保存并管理镜像 镜像 镜像 由Docke引擎实例化为 容器 容器 容器既是运行的应用 容器可以构建为镜像 Maven构建镜像docker的整个生命周期有三部分组成：镜像（image）+容器（container）+仓库（repository）； 如下图所示，容器是由镜像实例化而来，这和我们学习的面向对象的概念十分相似，我们可以把镜像看作类，把容器看作类实例化后的对象。 也可以说镜像是文件, 容器是进程。 容器是基于镜像创建的, 即容器中的进程依赖于镜像中的文件, 这里的文件包括进程运行所需要的可执行文件， 依赖软件， 库文件， 配置文件等等… docker 的镜像概念类似虚拟机的镜像。是一个只读的模板，一个独立的文件系统，包括运行容器所需的数据，可以用来创建新的容器。（ docker create ：为指定的镜像添加一个可读写层，构成一个新的容器；） 例如：一个镜像可以包含一个完整的ubuntu操作系统环境，里面仅安装了mysql或用户需要的其他应用程序。 docker镜像实际上是由一层一层的系统文件组成，这种层级的文件系统被称为UnionFS( Union file system 统一文件系统)，镜像可以基于dockerfile构建，dockerfile是一个描述文件，里面包含了若干条密令，每条命令都会对基础文件系统创建新的层次结构。 docker提供了一个很简单的机制来创建镜像或更新现有的镜像。用户甚至可以从其他人那里下载一个已经做好的镜像直接使用。（镜像是只读的，可以理解为静态文件） docker利用容器来运行应用：docker容器是由docker镜像创建的运行实例。docker容器类似虚拟机，可以执行包含启动，停止，删除等。每个容器间是相互隔离的。容器中会运行特定的运用，包含特定应用的代码及所需的依赖文件。可以把容器看作一个简易版的linux环境（包含root用户权限，进程空间，用户空间和网络空间等）和运行在其中的应用程序。 相对于镜像来说容器是动态的，容器在启动的时候创建了一层可写层次作为最上层。（ docker create ：为指定的镜像添加一个可读写层，构成一个新的容器；） docker仓库：如果使用了git和github就很容易理解docker的仓库概念。docker仓库概念和git类似。 docker仓库是用来包含镜像的位置，docker提供了一个注册服务器（register）来保存多个仓库，每个仓库又可以包含多个具备不同tag的镜像， docker运作中使用的默认仓库是docker hub公共仓库。 仓库支持的操作类似git，当用户创建了自己的镜像之后就可以使用push命令将它上传到共有或者私有的仓库。这样下次再另外一台机器上使用这个镜像的时候只需要从仓库里面pull下来就可以了。","path":"2019/04/22/1749531889/","date":"04-22","excerpt":"","tags":[{"name":"Docker","slug":"Docker","permalink":"https://yihuishou.github.io/tags/Docker/"}]},{"title":"Redis 的分布式锁 Redlock","text":"普通实现 说道Redis分布式锁大部分人都会想到：setnx+lua，或者知道set key value px milliseconds nx。后一种方式的核心实现命令如下： 获取锁（unique_value可以是UUID等）SET resource_name unique_value NX PX 30000 释放锁（lua脚本中，一定要比较value，防止误解锁）if redis.call(“get”,KEYS[1]) == ARGV[1] then return redis.call(“del”,KEYS[1])else return 0end 这种实现方式有3大要点（也是面试概率非常高的地方）： set命令要用set key value px milliseconds nx；value要具有唯一性；释放锁时要验证value值，不能误解锁；事实上这类琐最大的缺点就是它加锁时只作用在一个Redis节点上，即使Redis通过sentinel保证高可用，如果这个master节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况： 在Redis的master节点上拿到了锁；但是这个加锁的key还没有同步到slave节点；master故障，发生故障转移，slave节点升级为master节点；导致锁丢失。正因为如此，Redis作者antirez基于分布式环境下提出了一种更高级的分布式锁的实现方式：Redlock。笔者认为，Redlock也是Redis所有分布式锁实现方式中唯一能让面试官高潮的方式。 Redlock实现 antirez提出的redlock算法大概是这样的： 在Redis的分布式环境中，我们假设有N个Redis master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。 为了取到锁，客户端应该执行以下操作: 获取当前Unix时间，以毫秒为单位。依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。Redlock源码 redisson已经有对redlock算法封装，接下来对其用法进行简单介绍，并对核心源码进行分析（假设5个redis实例）。 POM依赖 &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt;&lt;/dependency&gt; 用法 首先，我们来看一下redission封装的redlock算法实现的分布式锁用法，非常简单，跟重入锁（ReentrantLock）有点类似： Config config = new Config();config.useSentinelServers().addSentinelAddress(\"127.0.0.1:6369\",\"127.0.0.1:6379\", \"127.0.0.1:6389\") .setMasterName(\"masterName\") .setPassword(\"password\").setDatabase(0);RedissonClient redissonClient = Redisson.create(config);// 还可以getFairLock(), getReadWriteLock()RLock redLock = redissonClient.getLock(\"REDLOCK_KEY\");boolean isLock;try &#123; isLock = redLock.tryLock(); // 500ms拿不到锁, 就认为获取锁失败。10000ms即10s是锁失效时间。 isLock = redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS); if (isLock) &#123; //TODO if get lock success, do something; &#125;&#125; catch (Exception e) &#123;&#125; finally &#123; // 无论如何, 最后都要解锁 redLock.unlock();&#125; 唯一ID 实现分布式锁的一个非常重要的点就是set的value要具有唯一性，redisson的value是怎样保证value的唯一性呢？答案是UUID+threadId。入口在redissonClient.getLock(“REDLOCK_KEY”)，源码在Redisson.java和RedissonLock.java中： protected final UUID id = UUID.randomUUID();String getLockName(long threadId) { return id + “:” + threadId;}获取锁 获取锁的代码为redLock.tryLock()或者redLock.tryLock(500, 10000, TimeUnit.MILLISECONDS)，两者的最终核心源码都是下面这段代码，只不过前者获取锁的默认租约时间（leaseTime）是LOCK_EXPIRATION_INTERVAL_SECONDS，即30s： &lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); // 获取锁时向5个redis实例发送的命令 return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, // 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间） \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间 \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + // 获取分布式锁的KEY的失效时间毫秒数 \"return redis.call('pttl', KEYS[1]);\", // 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2] Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));&#125; 获取锁的命令中， KEYS[1]就是Collections.singletonList(getName())，表示分布式锁的key，即REDLOCK_KEY；ARGV[1]就是internalLockLeaseTime，即锁的租约时间，默认30s；ARGV[2]就是getLockName(threadId)，是获取锁时set的唯一值，即UUID+threadId：释放锁 释放锁的代码为redLock.unlock()，核心源码如下： protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123; // 向5个redis实例都执行如下命令 return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, // 如果分布式锁KEY不存在，那么向channel发布一条消息 \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \" + \"end;\" + // 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回 \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" + \"return nil;\" + \"end; \" + // 如果就是当前线程占有分布式锁，那么将重入次数减1 \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" + // 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除 \"if (counter &gt; 0) then \" + \"redis.call('pexpire', KEYS[1], ARGV[2]); \" + \"return 0; \" + \"else \" + // 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息 \"redis.call('del', KEYS[1]); \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \"+ \"end; \" + \"return nil;\", // 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3] Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));&#125;","path":"2019/04/22/709887644/","date":"04-22","excerpt":"","tags":[{"name":"Redis","slug":"Redis","permalink":"https://yihuishou.github.io/tags/Redis/"}]},{"title":"数据库连接池到底设置为多大比较合适？","text":"数据库连接池的配置是开发者们常常搞出坑的地方，在配置数据库连接池时，有几个可以说是和直觉背道而驰的原则需要明确。 1万并发用户访问 想象你有一个网站，压力虽然还没到Facebook那个级别，但也有个1万上下的并发访问——也就是说差不多2万左右的TPS。那么这个网站的数据库连接池应该设置成多大呢？结果可能会让你惊讶，因为这个问题的正确问法是： “这个网站的数据库连接池应该设置成多小呢？” 初始的配置压测跑起来之后是这个样子的： 2048连接时的性能数据2048连接时的性能数据每个请求要在连接池队列里等待33ms，获得连接后执行SQL需要77ms 此时数据库的等待事件是这个熊样的： 各种buffer busy waits各种buffer busy waits各种buffer busy waits，数据库CPU在95%左右（这张图里没截到CPU） 接下来，把中间件连接池减到1024（并发什么的都不变），性能数据变成了这样： 连接池降到1024后连接池降到1024后获取链接等待时长没怎么变，但是执行SQL的耗时减少了。下面这张图，上半部分是wait，下半部分是吞吐量 wait和吞吐量能看到，中间件连接池从2048减半之后，吐吞量没变，但wait事件减少了一半。 接下来，把数据库连接池减到96，并发线程数仍然是9600不变。 96个连接时的性能数据96个连接时的性能数据队列平均等待1ms，执行SQL平均耗时2ms。 wait事件几乎没了，吞吐量上升。 没有调整任何其他东西，仅仅只是缩小了中间件层的数据库连接池，就把请求响应时间从100ms左右缩短到了3ms。 But why? 为什么nginx只用4个线程发挥出的性能就大大超越了100个进程的Apache HTTPD？回想一下计算机科学的基础知识，答案其实是很明显的。 即使是单核CPU的计算机也能“同时”运行数百个线程。但我们都[应该]知道这只不过是操作系统用时间分片玩的一个小把戏。一颗CPU核心同一时刻只能执行一个线程，然后操作系统切换上下文，核心开始执行另一个线程的代码，以此类推。给定一颗CPU核心，其顺序执行A和B永远比通过时间分片“同时”执行A和B要快，这是一条计算机科学的基本法则。一旦线程的数量超过了CPU核心的数量，再增加线程数系统就只会更慢，而不是更快。 这几乎就是真理了…… 有限的资源 上面的说法只能说是接近真理，但还并没有这么简单，有一些其他的因素需要加入。当我们寻找数据库的性能瓶颈时，总是可以将其归为三类：CPU、磁盘、网络。把内存加进来也没有错，但比起磁盘和网络，内存的带宽要高出好几个数量级，所以就先不加了。 如果我们无视磁盘和网络，那么结论就非常简单。在一个8核的服务器上，设定连接/线程数为8能够提供最优的性能，再增加连接数就会因上下文切换的损耗导致性能下降。数据库通常把数据存储在磁盘上，磁盘又通常是由一些旋转着的金属碟片和一个装在步进马达上的读写头组成的。读/写头同一时刻只能出现在一个地方，然后它必须“寻址”到另外一个位置来执行另一次读写操作。所以就有了寻址的耗时，此外还有旋回耗时，读写头需要等待碟片上的目标数据“旋转到位”才能进行操作。使用缓存当然是能够提升性能的，但上述原理仍然成立。 在这一时间段（即”I/O等待”）内，线程是在“阻塞”着等待磁盘，此时操作系统可以将那个空闲的CPU核心用于服务其他线程。所以，由于线程总是在I/O上阻塞，我们可以让线程/连接数比CPU核心多一些，这样能够在同样的时间内完成更多的工作。 那么应该多多少呢？这要取决于磁盘。较新型的SSD不需要寻址，也没有旋转的碟片。可别想当然地认为“SSD速度更快，所以我们应该增加线程数”，恰恰相反，无需寻址和没有旋回耗时意味着更少的阻塞，所以更少的线程[更接近于CPU核心数]会发挥出更高的性能。只有当阻塞创造了更多的执行机会时，更多的线程数才能发挥出更好的性能。 网络和磁盘类似。通过以太网接口读写数据时也会形成阻塞，10G带宽会比1G带宽的阻塞少一些，1G带宽又会比100M带宽的阻塞少一些。不过网络通常是放在第三位考虑的，有些人会在性能计算中忽略它们。 上图是PostgreSQL的benchmark数据，可以看到TPS增长率从50个连接数开始变缓。在上面Oracle的视频中，他们把连接数从2048降到了96，实际上96都太高了，除非服务器有16或32颗核心。 计算公式 下面的公式是由PostgreSQL提供的，不过我们认为可以广泛地应用于大多数数据库产品。你应该模拟预期的访问量，并从这一公式开始测试你的应用，寻找最合适的连接数值。 连接数 = ((核心数 * 2) + 有效磁盘数) 核心数不应包含超线程(hyper thread)，即使打开了hyperthreading也是。如果活跃数据全部被缓存了，那么有效磁盘数是0，随着缓存命中率的下降，有效磁盘数逐渐趋近于实际的磁盘数。这一公式作用于SSD时的效果如何尚未有分析。 按这个公式，你的4核i7数据库服务器的连接池大小应该为((4 * 2) + 1) = 9。取个整就算是是10吧。是不是觉得太小了？跑个性能测试试一下，我们保证它能轻松搞定3000用户以6000TPS的速率并发执行简单查询的场景。如果连接池大小超过10，你会看到响应时长开始增加，TPS开始下降。 笔者注：这一公式其实不仅适用于数据库连接池的计算，大部分涉及计算和I/O的程序，线程数的设置都可以参考这一公式。我之前在对一个使用Netty编写的消息收发服务进行压力测试时，最终测出的最佳线程数就刚好是CPU核心数的一倍。 公理：你需要一个小连接池，和一个充满了等待连接的线程的队列 如果你有10000个并发用户，设置一个10000的连接池基本等于失了智。1000仍然很恐怖。即是100也太多了。你需要一个10来个连接的小连接池，然后让剩下的业务线程都在队列里等待。连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。 我们经常见到一些小规模的web应用，应付着大约十来个的并发用户，却使用着一个100连接数的连接池。这会对你的数据库造成极其不必要的负担。 请注意 连接池的大小最终与系统特性相关。 比如一个混合了长事务和短事务的系统，通常是任何连接池都难以进行调优的。最好的办法是创建两个连接池，一个服务于长事务，一个服务于短事务。 再例如一个系统执行一个任务队列，只允许一定数量的任务同时执行，此时并发任务数应该去适应连接池连接数，而不是反过来。 连接池的几个设计要点： 最大连接数：不要打满，超过系统吞吐量的80%，就考虑水平扩展 初始连接数：一般设置为最大连接数，节约连接的创建时间 最大空闲时间：尽量设置长一些，避免反复创建 获取连接的超时时间：在系统容忍的响应时间内，尽量设计长一些","path":"2019/04/19/909643994/","date":"04-19","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"RPC 与 Restful","text":"撤没用的什么是真正的技术？说实话这个定义太大了我是不敢说的。 我只说现象：很多人、尤其是职场从业5年以下的，往往觉得多用熟了一个框架，就觉得掌握了一门新技术。 职场上这样的人很多。还有很多为了技术而技术的，例如我小弟天天嚷嚷上Spring cloud，实际上现实场景根本不需要这个东西。 至于到底真正的技术是什么？ 在我心里定义如下：被少数人能解决的能落地的技术场景结合扎实的数据结构和算法等基本功。 简而言之就是知识和实践相结合，并且被少数人掌握的。 什么是RPC 提到RPC（Remote Procedure Call），就躲不开提到分布式，这个促使RPC诞生的领域。 假设你有一个Calculator，以及它的实现类CalculatorImpl，那么单体应用时，要调用Calculator的add方法来执行一个加运算，你可以方法中直接使用，因为在同一个地址空间，或者说在同一块内存，这个称为本地函数调用。 现在，将系统改造为分布式应用，接口调用和实现分别在两个子系统内， 服务A里头并没有CalculatorImpl这个类，那它要怎样调用服务B的CalculatorImpl的add方法呢？可以模仿B/S架构的调用方式，在B服务暴露一个Restful接口，然后A服务通过调用这个Restful接口来间接调用CalculatorImpl的add方法。 这样，已经很接近RPC了，不过，像这种每次调用时，是不是都需要写一串发起http请求的代码呢？比如httpClient.sendRequest…之类的，能不能简单一下，像本地方法调用一样，去发起远程调用，让使用者感知不到远程调用的过程。 屏蔽的工作，可以使用代理模式解决，生成一个代理对象，而这个代理对象的内部，就是通过httpClient来实现RPC远程过程调用的。 这就是很多RPC框架要解决的问题和解决的思路，比如阿里的Dubbo。 总结一下，RPC要解决的两个问题： 解决分布式系统中，服务之间的调用问题。 远程调用时，要能够像本地调用一样方便，让调用者感知不到远程调用的逻辑。 RPC是一种技术的概念名词 RPC=Remote Produce Call 是一种技术的概念名词，HTTP是一种协议,RPC可以通过 HTTP 来实现,也可以通过Socket自己实现一套协议来实现.所以题目可以换一种理解,为何 RPC 还有除 HTTP 之外的实现法,有何必要，毕竟除了HTTP实现外,私有协议不具备通用性. RPC框架好处 http接口是在接口不多、系统与系统交互较少的情况下，解决信息孤岛初期常使用的一种通信手段； 优点就是简单、直接、开发方便。 如果是一个大型的网站，内部子系统较多、接口非常多的情况下，RPC框架的好处就显示出来了： 首先就是长链接，不必每次通信都要像http一样去3次握手什么的，减少了网络开销； 其次就是RPC框架一般都有注册中心，有丰富的监控管理；发布、下线接口、动态扩展等，对调用方来说是无感知、统一化的操作。 最后是安全性。 rpc是一种概念，http也是rpc实现的一种方式。 论复杂度，dubbo/hessian用起来是超级简单的。 至于为什么用dubbo/hessian，有几点： 一是调用简单，真正提供了类似于调用本地方法一样调用接口的功能 。 二是参数返回值简单明了 参数和返回值都是直接定义在jar包里的，不需要二次解析。 三是 轻量，没有多余的信息。 四是便于管理，基于dubbo的注册中心。 RPC能解耦服务 RPC:远程过程调用。RPC的核心并不在于使用什么协议。RPC的目的是让你在本地调用远程的方法，而对你来说这个调用是透明的，你并不知道这个调用的方法是部署哪里。 通过RPC能解耦服务，这才是使用RPC的真正目的。RPC的原理主要用到了动态代理模式，至于http协议，只是传输协议而已。简单的实现可以参考spring remoting，复杂的实现可以参考dubbo。 rpc=socket + 动态代理 服务器通讯原理就是一台socket服务器A,另一台socket客户端B,现在如果要通讯的话直接以流方式写入或读出。这样能实现通讯，但有个问题。如何知道更多信息？ 比如需要发送流大小，编码，Ip等。这样就有了协议，协议就是规范，就是发送的流中携带了很多的内容。那回到刚刚的问题。发送的内容就是文本类型，客户端就得序列化，那么常用的就有json，xml之类，如果想把内容变得更小，那就有二进制了。把文本变成二进制传递。 说到 rpc 与http接口，不要太复杂了。rpc 协议更简单内容更小，那么来说效率是要高一点 rpc 是什么？就是socket 加动态代理。 总结 学技术应该是知其然知其所以然，我们得明白什么场景，或者什么业务需要它，它能解决其他技术不能解决或者不方便解决的问题。 RPC是一个软件结构概念，是构建分布式应用的理论基础。就好比为啥你家可以用到发电厂发出来的电？是因为电是可以传输的。至于用铜线还是用铁丝还是其他种类的导线，也就是用http还是用其他协议的问题了。这个要看什么场景，对性能要求怎么样。 在java中的最基本的就是RMI技术，它是java原生的应用层分布式技术。我们可以肯定的是在传输性能方面，RMI的性能是优于HTTP的。 那为啥很少用到这个技术？那是因为用这个有很多局限性，首先它要保证传输的两端都要要用java实现，且两边需要有相同的对象类型和代理接口，不需要容器，但是加大了编程的难度，在应用内部的各个子系统之间还是会看到他的身影，比如EJB就是基于rmi技术的。 这就与目前的bs架构的软件大相径庭。用http必须要服务端位于http容器里面，这样减少了网络传输方面的开发，只需要关注业务开发即可。所以在架构一个软件的时候，不能一定根据需求选定技术。 RPC vs Restful 其实这两者并不是一个维度的概念，总得来说RPC涉及的维度更广。 如果硬要比较，那么可以从RPC风格的url和Restful风格的url上进行比较。 比如你提供一个查询订单的接口，用RPC风格，你可能会这样写： /queryOrder?orderId=123用Restful风格呢？ Get/order?orderId=123再精炼一点，甚至可以这样： Get/order/123RPC是面向过程，Restful是面向资源，并且使用了Http动词。从这个维度上看，Restful风格的url在表述的精简性、可读性上都要更好。 RPC vs RMI 严格来说这两者也不是一个维度的。 RMI是Java提供的一种访问远程对象的协议，是已经实现好了的，可以直接用了。 而RPC呢？人家只是一种编程模型，并没有规定你具体要怎样实现，你甚至都可以在你的RPC框架里面使用RMI来实现数据的传输，比如Dubbo：Dubbo - rmi协议 RPC没那么简单 要实现一个RPC不算难，难的是实现一个高性能高可靠的RPC框架。 比如，既然是分布式了，那么一个服务可能有多个实例，你在调用时，要如何获取这些实例的地址呢？ 这时候就需要一个服务注册中心，比如在Dubbo里头，就可以使用Zookeeper作为注册中心，在调用时，从Zookeeper获取服务的实例列表，再从中选择一个进行调用。 那么选哪个调用好呢？这时候就需要负载均衡了，于是你又得考虑如何实现复杂均衡，比如Dubbo就提供了好几种负载均衡策略。 这还没完，总不能每次调用时都去注册中心查询实例列表吧，这样效率多低呀，于是又有了缓存，有了缓存，就要考虑缓存的更新问题，blablabla…… 你以为就这样结束了，没呢，还有这些： 客户端总不能每次调用完都干等着服务端返回数据吧，于是就要支持异步调用；服务端的接口修改了，老的接口还有人在用，怎么办？总不能让他们都改了吧？这就需要版本控制了；服务端总不能每次接到请求都马上启动一个线程去处理吧？于是就需要线程池；服务端关闭时，还没处理完的请求怎么办？是直接结束呢，还是等全部请求处理完再关闭呢？……如此种种，都是一个优秀的RPC框架需要考虑的问题。 比较JSON-RPC比较符合直观，格式也相对宽松； REST最近正流行，有自己的一套设计规范。 REST面对的疑问跟当年刚开始流行面向对象时的情况是一样的。 它适合很多情况，但并不适合所有情况。 最差的结果就是盲目跟风，又对REST的概念和理念一知半解，最后搞出一个半吊子的怪胎，还自我标榜用了流行的RESTful API。 REST是一种设计风格，它的很多思维方式与RPC是完全冲突的。 RPC的思想是把本地函数映射到API，也就是说一个API对应的是一个function，我本地有一个getAllUsers，远程也能通过某种约定的协议来调用这个getAllUsers。至于这个协议是Socket、是HTTP还是别的什么并不重要； RPC中的主体都是动作，是个动词，表示我要做什么。 而REST则不然，它的URL主体是资源，是个名词。而且也仅支持HTTP协议，规定了使用HTTP Method表达本次要做的动作，类型一般也不超过那四五种。这些动作表达了对资源仅有的几种转化方式。 这种设计思路是反程序员直觉的，因为在本地业务代码中仍然是一个个的函数，是动作，但表现在接口形式上则完全是资源的形式。 就像面向对象的「万物皆对象」理论在习惯了纯粹面向过程开发的程序员眼里显得十分别扭一样：我的代码本来就是按顺序、循环、分支这么运行的啊，为啥非得在很明确的结构上封装一层一层的基类子类接口，还要故意给两个函数起同一个名字，调用时才选择用哪一个呢？ 使用「万物皆资源」的思想编写实际项目中的API接口时，最常见的问题就是「这玩意到底是个什么资源？………………算了，我就直接写吧，不管什么风格了」 比如，login和logout应该怎么REST化？比如，多条件复合搜索在GET里写不下怎么办？比如，大量资源的删除难道要写几千个DELETE？其实在理解了REST后，这些都不是什么无解的难题，只是思维方式要转换一下： login和logout其实只是对session资源的创建和删除；search本身就是个资源，使用POST创建，如果不需持久化，可以直接在Response中返回结果，如果需要（如翻页、长期缓存等），直接保存搜索结果并303跳转到资源地址就行了；id多到连url都写不下的请求，应该创建task，用GET返回task状态甚至执行进度；……等等等。 如果只是规定了一种规范，却不理解它表相下面的思维方式，实施中又按照自己的理解随意变动，那结果肯定是混乱不堪的。 当然，API怎么写是开发者的自由。但如果一个API在url里放一堆动词、资源设计混乱、各种乱用HTTP Method和Status Code，还自称RESTful API的话，那就像你养了一条狗，还管它叫猫一样。 这种混搭产物，不如叫它REFU吧。 （Remove Extension From Url：从url里去掉文件扩展名） 前面说了半天REST的理念和不懂REST造成的问题，但是，这并不代表REST比RPC更「高等」，更不是说不理解REST的人是落伍的。 所谓代码风格、接口形式、各种林林总总的格式规定，其实都是为了在团队内部形成共识、防止个人习惯差异引起的混乱。JSON-RPC当然也是有规范的，但相比REST实在宽松太多了。 如果一个开发团队规定必须在url里写action，所有请求都是POST，可以吗？当然也没问题，只是不要拿出去标榜自己写的是RESTful API就行。 规范最终还是为了开发者和软件产品服务的，如果它能带来便利、减少混乱，就值得用；反之，如果带来的麻烦比解决的还多，那就犯不上纯粹跟风追流行了。 RESTful API在很多实际项目中并不使用。因此真的做了项目，你可能会发现只能用HTTP+JSON来定义接口，无法严格遵守REST风格。 为什么说不实际呢？因为这个风格太理想化了，比方说： REST要求要将接口以资源的形式呈现。但实际上，很多时候都不太可能将一些业务逻辑看作资源。即使强制这么干了，也会非常非常别扭。登录就是登录，而不是“创建一个session”；播放音乐就是播放，而不是“创建一个播放状态“。我们之所以要定义接口，本身的动机是做一个抽象，把复杂性隐藏起来，而绝对不是把内部的实现细节给暴露出去。REST却反其道而行之，要求实现应该是“资源”并且这个实现细节要暴露在接口的形式上。 但一个好的接口设计就应该是简单、直观的，能够完全隐藏内部细节的，不管底层是不是资源，资源的组合还是别的什么架构。此外，让业务逻辑与接口表现一致，对系统的长期维护和演进都有极大的好处。REST只提供了增删改查的基本语义，其他的语义基本上不管。比如批量添加，批量删除，修改一个资源的一部分字段。区分“物理删除”和“标记删除”等等。复杂的查询更加不显示，对于像筛选这类的场景，REST明显就是个渣。这里要表扬一下GraphQL（但GraphQL有其他的问题，在此不展开）REST建议用HTTP的status code做错误码，以便于“统一”，实际上这非常难统一。各种业务的含义五花八门，抽象层次高低不齐，根本就无法满足需要。比如一个404到底是代表这个接口找不到，还是代表一个资源找不到。400表达请求有问题，但是我想提示用户“你登录手机号输入的格式不对“，还是“你登录手机号已经被占用了“。既然201表示“created”，为啥deleted和updated没有对应的status code，只能用200或者204（no content）？错误处理是web系统里最麻烦的，最需要细心细致的地方。REST风格在这里只能添乱。web请求参数可能散布在url path、querystring、body、header。服务器端处理对此完全没有什么章法。客户端和服务器端的研发之间还是要做约定。在url path上的变量会对很多其他的工作带来不良影响。比如监控，本来url可以作为一个接口的key统计次数/延迟，结果url里出了个变量，所以自动收集nginx的access log，自动做监控项目增加就没法弄了。再比如，想对接口做流量控制的计数，本来url可以做key，因为有变量，就得多费点事才行。现实中接口要处理的真正的问题，REST基本上也没怎么管。比如认证、授权、流控、数据缓存（http的etag还起了点作用）、超时控制、数据压缩……。REST有很多好的工具可以便利的生成对应的代码和文档，也容易形成规范。但问题是REST在实际的项目中并没有解决很多问题，也在很多时候不合用，因此产生的代码和文档也就没什么用，必须经过二次加工才能真的用起来。因此可以基于REST+你的业务场景定义一个你自己的规范。REST的本意是基于一个架构的假设（资源化），定义了一组风格，并基于这个风格形成约定、工具和支持。思路不错。但是因为他的架构假设就是有问题的，因此后续一系列东西都建立在了一个不稳固的基础之上。同时，REST并没有解决太多的实际问题。 是，的确，有些时候，用REST完成CRUD已经能完成任务了。此时，用REST没有什么不好的。但是，现实当中，真正的业务领域一般都会比资源的CRUD复杂的多。这时REST“基本上没解决太多实际问题”的缺点就会体现出来。我所见到的大多数情况，是会形成一种REST-like形式的接口，像REST却又不限于REST。 为了REST，我看到了太多的人在争执到底是POST还是PUT，到底用querystring还是body，到底用200还是201，到底一个单词应该用单数还是复数，到底一个请求参数应该放在url path的中间一段还是最后一段…… 真正要做的事情本身反而没人关心。而一旦把争论给一个“REST专家”看，他的回答八成是“其实你还是不懂REST”… 我觉得人生不能这么糟蹋，你觉得呢？ 附一个现实当中接口的开发的方式 你可以总是从REST开始，如果你要开发的东西能被自然而然的想成是一个资源。然后通过相关的工具自动生成一些代码，把这个原型和你的合作者讨论一下。这是我能想到的REST能做的一件很好的事情——快速实验。 然后如果你想认真的往下做，就可以彻底忘记REST这件事。开始自己定义业务接口，尽量不要在url里加变量。尽量只用GET和POST，减少一些沟通上的混乱。对于每个接口，好好定义可能发生的业务错误，并与PM一起协商怎么处理这些错误。认真的考虑认证、授权、流控等机制，当你开发的是和钱相关的业务尤其要留意。 最后，本文并不是说“绝对不要用REST”，而是：如果你在实际工作中用REST有了困惑，不知道某个情况下REST此时的最佳实践是什么时，不要追求“真正的REST会怎么做”，不要被REST限制住。 如果看过REST最初的那篇论文Architectural Styles and the Design of Network-based Software Architectures就会发现，当时想设计的目标是解决互联网级别的信息共享和互操作问题。而我们的大量开发者工作的主要目标是“为业务系统实现一个满足功能（比如登录，交易……）/非功能需求（比如认证，性能，可扩展性……）的接口“。并且设计接口时会区分“给第三方用的开放接口”、“给UI开发定制的接口“和“内部使用的接口”等。这些接口的设计目标都和REST当初制定的目标有差别。其中最接近的，是“开放接口”。因此可以看到有些开放接口用REST实现还是很不错的，比如github的接口，AWS S3的接口等。 但是其他两类接口与REST关注的点完全不一样。比如面向UI的接口的就要满足UI需要。此时资源不资源不太重要，而是尽量用少的roundtrip去返回这个界面需要的所有数据。接口是按照加载的优先级，而不是“资源”做切分。比如第一屏的显示要尽量一个接口先给出来，后续异步加载的数据可以用其他接口慢慢出。为UI提供的接口往往被划归为“大前端“的一部分。 而内部的接口，越接近DB的，越容易用表来mapping到“资源“，但是内部的接口需要考虑到数据整合的需要。比如底层的用户数据分为A、B、C三类，但这3个数据因为服务隔离不能直接在DB做join。需求要按照A的某个条件做排序分页，但要注入B和C的数据。这时就需要B和C提供batch读取和app注入的相关逻辑。此外还有复杂的查询条件，可动态改变的输出字段等要求。REST的“资源”概念在这里能帮上的忙有限。这也是GrpahQL尝试解决的问题。 再有一类问题是用接口实现分布式一致性的业务问题。比如下单+支付+扣库存+加积分问题。这时接口的形式并不重要，而能够支持实现SAGA或者TCC才是最关键的。而整个业务对外的感觉实际上是创建一个“事务”。早期一本叫做Resftul Web Services的书描述Restful接口做这个事情的方案是： 调用接口创建一个事务的资源拿着事务资源的id，调用步骤1接口，步骤2接口……拿着事务资源的id，调用事务的commit接口这种形式不仅臃肿，还把怎么做这件事的内部细节完全暴露到了调用方，造成了耦合。而我们一般常见的做法就是一个接口POST /doSomething，然后接口实现方内部维护事务，维护commit，rollback等细节。有的时候还需要添加一些异步回调。 简单总结下，写接口的目标各自不同。而REST的目标是“实现互联网级别的信息共享系统”，这个目标和大部分开发者要实现的目标完全不同，这就不难解释为何照搬REST去做另一个领域的事情可能会非常别扭。","path":"2019/04/18/2144847318/","date":"04-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Java 与闭包","text":"函数式编程就是一种抽象程度很高的编程范式。函数式编程的特点：函数可以赋给变量，所以，可作为参数传递，可作为返回值返回。 闭包是一类特殊的函数。如果一个函数定义在另一个函数的作用域中，并且函数中引用了外部函数的局部变量，那么这个函数就是一个闭包。 闭包就是能够读取其他函数内部变量的函数。例如在javascript中，只有函数内部的子函数才能读取局部变量，所以闭包可以理解成“定义在一个函数内部的函数“。在本质上，闭包是将函数内部和函数外部连接起来的桥梁。","path":"2019/04/17/1986098977/","date":"04-17","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"简单鸡尾酒制作","text":"记录了三种鸡尾酒，挺简单的 螺丝起子这是一种杯中洋溢着柳橙汁香味的鸡尾酒。在伊朗油田工作的美国工人以螺丝起子将伏特加及柳橙汁搅匀后饮用，故而取名为螺丝起子。这种酒素以勾引女子鸡尾酒闻名。如果将螺丝起子中的伏特加基酒换成琴酒，则变成橘子花鸡尾酒，美国禁酒法时期，这种鸡尾酒非常流行。螺丝起子的配方中如果多加一种叫加里安诺 (Galliano)的黄色甜味利口酒，就变成哈维.沃鲁班卡伏特加(HARVEY WALLBANGE)鸡尾酒。加里安诺的酒精度数是35%，原产地在意大利，是一种含有花草、药草及些许大茴香味的利口酒。 伏特加 ：橙汁/橘汁 = 1 ：3 苏打水版： 伏特加 ：橙汁/橘汁 ：苏打水 ：糖浆 = 1 ：3 ： 雪碧版： 伏特加 ：橙汁/橘汁 ：雪碧 = 1 ：3 ： 2 需要加冰块搅拌 蓝色夏威夷蓝色夏威夷（Blue Hawaii），这款鸡尾酒是以朗姆酒为基酒，配以蓝橙力娇酒、椰奶、菠萝汁等辅料制作而成的一款鸡尾酒。 [1]此款鸡尾酒是星座鸡尾酒中代表双鱼座（2月20日至3月20日）的一款鸡尾酒。 [1] 其中，蓝橙酒代表蓝色的海洋，塞满酒杯中的碎冰象征着泛起的浪花，而酒杯里散发的果汁甜味犹如夏威夷的微风细语。 蓝橙力娇酒 ：椰奶/椰子味朗姆酒 ：朗姆酒 ：菠萝汁 = 1 ：1 ：4 ：2 可加入雪碧提高甜度和颜色 下层是菠萝汁 上层是三种酒混合后加入 内加冰块 黑色俄罗斯咖啡糖浆/甘露咖啡酒/咖啡力娇酒 ： 伏特加 = 1：2 加冰块搅拌","path":"2019/04/15/4066886113/","date":"04-15","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"SpringSecurity 前后分离的选择","text":"SpringSecurity 前后分离的实现有几种不同的组合方式，在网上收集了各种各样的实现之后 总结一下两种实现方式 不同的验证结构 只使用 Securtiy ，通过添加自行实现的 JWT 过滤器到 Security 的过滤器链中。来实现鉴权， 通过重写各种逻辑 handeler 来实现更改默认的页面跳转为Json 数据响应。 使用 oauth2 的 Password 模式，通过 oauth2 来进行鉴权。由于可以直接使用本身的 handeler 可以不重写，但是由于自身处理的响应信息内容过少，还是需要重写。 注意：使用oauth2时 clien_id 和 grant_type 不可缺少，否则将会进入 Http Basic 模式 scope 虽然在当前模式没有什么意义，但是至少需要在客户端或服务端定义一个。在Jwt 签名中需要使用它。 oauth2注意的问题oauth2 实际上需要维护 客户端 和 用户 两个身份的信息，需要额外注意这一点。它比只使用 Securtiy 来说 多出了 客户端 的身份信息。需要注意维护这个身份相关的内容，在不提供第三方授权时，也可使用内存维护。 使用 oauth2 协议不需要配置 WebSecurity 只需要配置 oauth2 的两个认证服务器和资源服务器即可。 SpringSecurity-oauth2主要使用ouath2的password模式进行认证，依赖使用 spring-security-oauth2 扩展 spring-boot-starter-security 由于使用了oauth2 协议，所以除了可以使用密码模式以为，也可以使用其他三种模式，来授权第三方登陆。 但对于单体应用来说，使用 oauth2 协议 需要资源服务器和认证服务器配置在同一应用下，拦截器链很可能产生冲突。 不过 ouath2 提供了自带的Token 刷新，可以减少部分开发工作。配合 spring-security-oauth2-jose 可以使用 JWT 进行认证。 其中JOSE 是指 Javascript 对象签名和加密 它包含以下4个组件 JSON Web Token (JWT) JSON Web Signature (JWS) JSON Web Encryption (JWE) JSON Web Key (JWK) 需要注意的 oauth2 是三方信任的关系，保证了 用户-资源-客户端 的相互信任，所以有两条信任链，与基础的 用户-资源 信任方式不同。 它还有一个基于cloud的自动配置 spring-cloud-starter-oauth2 。 这里需要注意springBoot 的版本 由于 springBoot 1.5.x 使用的时 security 4 而 2.x.x 使用的是 security 5 相关配置和依赖项都有所不同，其中 springBoot 1.5.x 使用 spring-security-oauth2 和 spring-security-jwt 不能使用 2.x.x 的 spring-cloud-starter-oauth2 和 spring-security-oauth2-jose。 而且 2.x.x 的 httpbasic 配置方式也发生了改变，配置文件配置 basicHttp 不再生效，BasicHttp 验证页面变得好看了。 但严格来说，对于前后分离来讲，页面路由应由前端进行路由，后端只需提供数据。但 oauth2 授权码模式 会跳转到自己的登陆页面上，而不是返回数据。 提示前端来进行路由，这就需要重写SpringSecurity的各种处理器来实现发送数据，由于SpringSecurity早先是基于后端渲染级权限控制的。 所以它的一系列的登陆逻辑处理器都需要被重写。 SpringSecurity-jwt依赖 spring-security-jwt 两种方法都需要 spring-boot-starter-security。 完成依靠重写 SpringSecurity 的各种处理器来实现分离控制。不进行跳转。由于基本完全基于手工代码重写实现， 基本不会存在 oauth2 的多服务器拦截器链冲突问题，但相关的令牌生命周期和令牌刷新都需要自行实现。 oauth2 的相关问题首先是4种模式： 授权码 简化码 密码 客户端 授权码是最安全也最复杂的模式，对于第三方客户端来说，可以完全保护用户资源和用户信息。 简化码主要是在授权码基础上减少了一步由第三方客户端后台使用授权码换取资源访问许可令牌的环节， 从而令第三方直接获得资源访问令牌，无需使用授权码。 密码模式则是通过 用户名 密码 和 客户端ID 及客户端密码 发送到认证服务器，直接换取资源访问令牌。 客户端模式由认证服务器直接验证客户端身份信息，只需要客户端ID和客户端密码即可换取资源访问令牌。 对于刷新令牌，客户端和简化码模式不支持刷新。 令牌刷新问题主要有两种刷新方式： 浏览器主动刷新浏览器每次访问后端端口前先对存储在浏览器中的token解析，获取过期时间。然后与当前系统时间进行比较， 小于一定时间则调用服务器的令牌刷新端口获取新的访问令牌，最后用新的访问令牌去访问服务器资源。 不过由于浏览器需要更新令牌之后才能访问资源，所以在执行刷新令牌时浏览器访问延迟会提高。 服务器被动刷新浏览器每次访问后对令牌进行检查与存储在本地的令牌进行比较，如果令牌刷新则进行更新本地存储。 使用JWT则不应使用服务器被动刷新，因为JWT无状态特性不应在服务器上保存状态 一般来说，服务器对接口的访问每次都会进行验证，如果令牌过期但可以刷新那么就继续执行访问，返回时发送新的令牌。","path":"2019/04/04/1754077512/","date":"04-04","excerpt":"","tags":[{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://yihuishou.github.io/tags/SpringSecurity/"}]},{"title":"用于分析问题的 SMART 原则","text":"设立目标的SMART原则 设立目标，一定要遵循SMART原则，什么是SMART原则？ S：Specific，明确的，具体的比如刚才提到的目标「我的目标是要幸福」 这个目标本身没有错，只是办不到而已，因为幸福的定义不明确，所以不知道该做什么才能达成。那怎么办呢？ 你想要幸福，就一定要有所行动，因此，你可以把这个目标用清晰明确的行动指引来替代。 比如：我的目标是有一份稳定的工作，有一个爱自己的老公，每周能一起去看次电影，每年去旅行一次。 M：Measurable，可衡量的目标是否达成，需要可以被衡量，比如你说「我们的目标就是让客户满意」 那么怎么样才算满意呢？ 这个无法衡量。 你需要加上一组数据维度，比如说「用户好评分，在9.5分以上」，这样就能衡量是否达成了。 A： Achievable，（自力）可达到的你不能定一个不可实现的目标，比如前面说的唱歌的例子，那个目标是不错，但是从五音不全，到成为歌星，这个目标离你的现状太远，遥不可及，你几乎不可能在1年之内实现。 你可以先定一个可实现的小目标，比如参加唱歌培训班，并通过毕业考试。然后在K歌软件上上传翻唱录音，获得100个粉丝，100个点赞。 如果这个目标能达成，再定一个远一些的目标，就会比较靠谱。不然就会因为目标距离太远，而让自己始终处在焦虑的状态，也不知道下一步该如何改善… 这里要强调的一点是，目标的达成，一定是自己的力量可以控制的过程，而不能把目标达成与否寄托在他人或者你不可控的事情上。 比如，目标定为「下半年能够升职」，或者是「他能更喜欢我」，这些你不能控制，因为决定权在对方，你可以改成「连续两个月达到团队业绩第一名」、「提升自己对他的吸引力」… R：Rewarding，完成后有满足感的不能设定太远的目标，那我就设定一个「近一些的，容易实现的」目标可不可以呢？ 那你就需要衡量，当你完成这个目标的时候，是否能够满足你的存在感知层？ 太近、太容易的目标，即便完成，你也不会有愉悦感和满足感，那么这就不是一个好目标，会让你在过程中失去对它的渴求，也就没有了动力。 T：Time-bound，有时间限制的一定得有时间限制，不然任何目标都没有意义，比如「我的目标是赚100万」，那是准备多久达到呢？1个月？1年？10年？还是50年？ 不同的时间限制，会导致你思考的方式、制定的计划完全不同。如果没有时间限制，这个目标就会成为一句口号，起不到任何作用。 注意：区分目标和手段除了目标要遵循「SMART原则」外，你还得注意区分目标和手段… 我们使用方法A来达成目标B，但往往在过程中，却把A本身当成了目标，这是怎么回事？ 就比如读书这件事，你定了一个目标，一年要读50本书。 然后呢，具体要看什么书？ 历史？商业？还是文学？找不到方向… 年中的时候，发现才读了10本书，下半年就开始奋起直追。 到了年底，终于读完了50本书了，然后呢？ 好像也没学到什么，读完这50本书能干吗呢？ 还是一脸迷茫… 为什么会这样？ 那是因为，读书是手段，并不是目的。 你不应该问：“读书是为了什么？” 而是要问：“为了什么，我们需要读书？” 可能是为了要解决某个具体的问题；可能是为了要写一篇学术论文；也可能是为了要准备一场重要的演讲…这样的读书，才能有效果。 读书，是让你达成某个目标的手段， 但我们却常常把它当成了目标本身。 再比如，有两个人在图书馆争吵： 一个人要关窗，一个人要开窗，两个人争吵不休… 图书馆馆长走了过来，分别问他们，为什么要开关窗啊？ 其中一人说：我要开窗，是因为天气太热了，想要透透气，吹吹风；另一个人说：我要关窗，是因为外面噪音太大了，影响我专心看书；结果，馆长把窗户关上，拿来了电风扇，两个人的问题就都解决了。 关不关窗是手段，开/关窗后想要达到的结果才是目的。在不伤害其他人的情况下，别纠结手段，达到目的即可。 关于这一点，在谈判中也比较常见： 谈判中的双方，经常就某一价格问题，彼此僵持，一个要更便宜些，一个死活不降价，怎么办？ 那就是把手段当成了目的。 我们要降价，对方不肯降价，可能都是为了要达到彼此公司能有更高利润的目的。那么，你谈判的焦点，就应该放在如何帮助对方提高利润上，而不要局限于眼前这个产品的价格上。 比如，你们公司的网站流量很大，那么你就可以和对方说，价格我们给不了更多了，但是可以让你们公司的广告免费出现在我们的网站上，我们网站的流量非常高，这能让更多的用户了解你们，提高你们品牌的知名度。 这样，你能用低价购入对方的产品，对方也能通过你的网站提升自己的总收益，这是一个双赢的方案。 以上这些，就是因为目标的错误，而导致的问题。 所以，当你遇到一个问题的时候，第一步应该先检查一下的，你的目标是否符合SMART原则？你是否把手段本身当成了目标？ 目标不对，什么都不对！","path":"2019/04/03/1811262184/","date":"04-03","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"SpringDataJPA 效率优化","text":"延迟加载 与 N+1JPA 中默认 @ManyToMany 和 @OneToMany 使用延迟加载 其抓取方式为 Feth.select 会产生 N+1 条查询语句 这使得对数据库产生很大的压力 使用立即加载 则不会有 N+1 的问题，单多表关联时，即使仅仅查询某一个表中的数据 仍然会采用多表关联查询，也会对数据库产生压力 解决方案 使用 JPA 2.1 的 Name的 @NameEntityGraph @EntityGraph 来动态进行动态抓取 使用 JPQL 的 Fetch 语句 或者 单独使用 @EntityGraph ，对一层嵌套进行强制抓取 FetchType 与 @Fetch 比较： 两者都是设定关联对象的加载策略。前者是JPA标准的通用加载策略注解属性，后者是Hibernate自有加载策略注解属性。 FetchType可选值意义与区别如下： FetchType.LAZY: 懒加载，在访问关联对象的时候加载(即从数据库读入内存) FetchType.EAGER:立刻加载，在查询主对象的时候同时加载关联对象。 FetchMode可选值意义与区别如下： @Fetch(FetchMode.JOIN)： 始终立刻加载，使用外连(outer join)查询的同时加载关联对象，忽略FetchType.LAZY设定,只产生一条sql语句。 @Fetch(FetchMode.SELECT)： 默认懒加载(除非设定关联属性lazy=false)，当访问每一个关联对象时加载该对象，会累计产生N+1条sql语句，FetchType.LAZY设定时默认使用。 @Fetch(FetchMode.SUBSELECT)： 默认懒加载(除非设定关联属性lazy=false),在访问第一个关联对象时加载所有的关联对象。会累计产生两条sql语句。且FetchType设定有效。 Fetch在 Join 语句后添加 fetch 关键字，可强行抓取关联对象，生成的 sql 语句为 left outer join。 只对一层关联有效，不能在多层关联中使用。 示例： @Query(&quot;select d from Department d join fetch d.bossList where d.id=:id&quot;) 对于 @Query 查询来说，@Query 查询受 fetch 语句 和 FetchType.LAZY/EAGER 影响 不受 @Fetch 影响 @Query 的 FetchType.EAGER 查询固定使用 select 模式 会产生 N+1 问题 且 不受 @Fetch 影响 @EntityGraph使用该注解被声明 attributePaths 属性为关联实体属性，同样只支持一层抓取。 该属性支持一层级抓取多个关联实体属性 attributePaths = {“parm1”,”parm2”} 示例： @EntityGraph(attributePaths = &quot;bossList&quot;)@Query(&quot;select d from Department d where d.id=:id&quot;) EntityGraphType.LOAD 和 EntityGraphType.FETCH 为该注解可选属性，默认为 EntityGraphType.FETCH EntityGraphType.LOAD：在原有Entity的定义的基础上，定义还需要获取什么字段/关系 EntityGraphType.FETCH：完全放弃原有Entity的定义，定义仅需要获取什么字段/关系 EntityGraphType.LOAD：被加载的数据为name以及employees EntityGraphType.FETC：被加载的数据仅为employees @NamedEntityGraphs该注解声明在实体上，必须声明 name 属性，由接口方法中的 @EntityGraph 注解 value 属性调用，默认可省略 value 示例： @EntityGraph(&quot;department.all&quot;)@Query(&quot;select d from Department d where d.id=:id&quot;) @NamedEntityGraphs 为数组声明多个 @NamedEntityGraph 注解 @NamedEntityGraph 的 name 属性为调用名 attributeNodes 为定义的抓取的节点属性，包含多个@NamedAttributeNode @NamedAttributeNode 包含 value 和 subgraph 两个值，只有 value 时 可省略 value 为要抓取的关联实体属性 subgraph 则为要抓取的子实体名 对应为 @NamedSubgraph 的 name 属性值 subgraphs 包含多个 @NamedSubgraph 为抓取子实体关联节点 @NamedSubgraph 的 name 属性为子实体名 attributeNodes 则可定义嵌套抓取节点， 功能同 @NamedEntityGraph 的attributeNodes。可嵌套使用 下面的示例为抓取了 A 关联的实体属性 B 和 B 关联的实体属性 C 和 C 关联的实体属性 D 多层级抓取 需要使用 @IndexColumn 防止 cannot simultaneously fetch multiple bags 异常 @Entity@Table@NamedEntityGraphs(&#123; @NamedEntityGraph(name = \"A\", attributeNodes = &#123; @NamedAttributeNode(value = \"B\",subgraph = \"B.name\"), &#125;, subgraphs = &#123; @NamedSubgraph(name = \"B.name\", //一层延伸 attributeNodes = @NamedAttributeNode(value = \"C\", subgraph = \"C.name\")), @NamedSubgraph(name = \"C.name\", //两层延伸 attributeNodes = @NamedAttributeNode(value = \"D\")) &#125;) &#125;)Class A ()&#123; ...&#125;// 使用@EntityGraph(\"A\") 注意抓取超过一层的实体时，要求多实体一侧必须使用 Set 集合 当一个实体对象中包含多于一个非延迟加载策略时，比如 @OneToMany，@ManyToMany 或者 @ElementCollection 时，获取策略为(fetch = FetchType.EAGER) 当(fetch = FetchType.EAGER)多于一个时，持久框架抓取一方的对象时，同时又将多方的对象加载进容器中，多方又可能关联其它对象， Hibernate实现的JPA，默认最高抓取深度含本身级为四级(它有个属性配置是0-3), 若多方(第二级)存在重复值，则第三级中抓取的值就无法映射，就会出现 org.hibernate.loader.MultipleBagFetchException: cannot simultaneously fetch multiple bags 异常。 Hibernate 解决方案 @IndexColumn(name = “二级主键”) 或者次级主键 其实也可以使用 Set 集合来去重，并配合 @OrderIndex 来实现有序抓取。 但使用Set集合不能使用索引。优点是 该方法属于 JPA 规范内 使用 @IndexColumn 指定 唯一索引 属于超出 JPA 规范的方法 为 Hibernate 的专用方法。 推荐使用 @IndexColumn","path":"2019/03/25/1700353500/","date":"03-25","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"让 SpringBoot 以系统服务方式启动","text":"在linux下部署springboot项目是一件很简单的事，直接后台运行就行了，最多写个shell脚本开机自启就行了。我们最近做的项目需要在windows上部署，在windows上运行jar有一个问题，运行的时候会弹出一个cmd窗口，并且不能关闭，关闭的话程序就停止了。spring官方推荐使用winsw来将springboot项目作为服务运行。 winsw的使用比较简单。从github上下载：winsw下载，要下载的文件有两个：1.winsw.exe程序；2.xml配置文件。我下载的是最新版本的WinSW.NET4.exe和sample-minimal.xml。下载完成后，将下载的两个文件及springboot项目的jar包放在同一个文件夹中。 需要将winsw执行程序跟xml改成同样的名字，推荐使用项目名+Service的命名方式，比如：WinSW.NET4.exe改成myProjectService.exe，sample-minmal.xml改成myProjectService.xml。 bat 脚本头添加如下脚本可开启管理员模式启动 %1 mshta vbscript:CreateObject(\"Shell.Application\").ShellExecute(\"cmd.exe\",\"/c %~s0 ::\",\"\",\"runas\",1)(window.close)&amp;&amp;exit 配置完成后，命令行进入winsw所在的文件夹，执行“myProjectService.exe install”，其中myProjectService是你修改后的名称。 注意：命令提示符界面要用管理员权限进入，否则安装服务会失败，提示“WMI Operation failure: AccessDenied” 命令提示符界面输入命令“net start myProject”启动服务。 删除服务分为两步：1停止服务；2删除服务，都是在命令行界面实现。 输入“net stop myProject”停止运行服务。 输入“myProjectService.exe uninstall”删除服务。 现实生活中，我们使用windows系统的电脑的时候，可能会遇到这么一种情况：想把一些应用程序添加为开机启动项。对于有图形界面的应用程序，一般不存在问题。但是如果想运行命令行应用程序，就不是那么方便了。一种笨办法就是写个bat，放到启动文件夹里，就可以开机启动了。开机之后，你就会发现，这样会一直显示着一个CMD窗口，而且这个窗口不能关，关了程序就停了。 其实Windows系统自带后台程序管理的功能，也就是我们经常用到的服务。但是Windows的服务只有程序的开发者在写程序的时候引用到这个功能，我们才能利用服务来控制程序的启动和关闭。对于一般的命令行程序来说，没办法利用服务。 今天要介绍的WinSW，它就是一个可以将Windows上的任何一个程序注册为服务的工具。同样也可以进行卸载该服务。 配置文件编写完之后，将配置文件与WinSW.exe放在同一目录中。注意对应WinSW.exe的配置文件名称应该是WinSW.xml。此时，WinSW.exe、WinSW.xml以及你的应用程序应该都是在同一目录中。然后用管理员权限打开一个命令提示符窗口，cd进入到应用程序所在目录，可以通过输入下面的命令来进行控制应用程序对应的服务： winsw install 安装服务 winsw uninstall 卸载服务 winsw start 开启服务 winsw stop 停止服务 winsw restart 重新启动服务 winsw status 检查服务的当前状态 安装服务命令执行后，如果返回值为0，就表示服务已经安装成功。此时在windows服务的窗口，就能看到你刚才安装的服务了。 3、配置项说明 （1）id 指定在Windows系统内部使用的识别服务的ID。在系统中安装的所有服务中，这必须是唯一的，它应该完全由字母数字字符组成。 （2）name 服务的简短名称，它可以包含空格和其他字符。尽量简短，就像“id”一样，在系统的所有服务名称中，也要保持唯一。 （3）description 该服务可读描述。当选中该服务时，它将显示在Windows服务管理器中。 （4）executable 该元素指定要启动的可执行文件。它可以是绝对路径，也可以指定可执行文件的名称，然后从环境变量“PATH”中搜索（需要注意的是，服务经常在不同的用户账户中运行，因此它可能需要有不同于你设置在环境变量Path中的路径）。 （5）startmode 该元素指定Windows服务的启动模式。它可以是下列值之一：开机、系统、自动或手动。有关详细信息，请参阅MSDN【https://msdn.microsoft.com/en-us/library/aa384896%28v=vs.85%29.aspx】。默认值是“Automatic”。 （6）delayedAutoStart 这个布尔选项允许在定义“自动”启动模式时延时启动。关于延时启动模式，可参阅【https://blogs.technet.microsoft.com/askperf/2008/02/02/ws2008-startup-processes-and-delayed-automatic-start】。 请注意，延时启动模式在早于Windows 7和Windows Server 2008的操作系统中可能失效。在这种情况下，Windows服务安装可能会失败。 （7）depend 指定该服务所依赖的其他服务的id。当服务“X”依赖于服务“Y”时，“X”只能在“Y”运行后运行。可以使用多个元素来指定多个依赖项。 （8）logging 关于服务进程的日志以及错误信息，有单独的一个配置说明文档【WinSW Logging and Error Reporting】，咱们下次再详细说。 （9）argument 该元素指定要传递给可执行文件的参数。 如果有必要，Winsw会给每一个参数外加引号（“”），所以为了避免双重引号，尽量不要在参数中使用引号。 为了向后兼容，可以使用“arguments”来指定单个元素中的整个命令行。 （10）stopargument/stopexecutable 请求停止服务时，winsw通过调用终止进程的API函数来立即终结服务。然而，如果存在“stopargument”元素，winsw将通过使用”stopargument“作为参数，来启动“executable“元素（或者是”stopexecutable“元素）中配置的进程，来代替调用终止进程的API函数。期望通过这种方式来优雅的关闭服务进程。 然后，Winsw将等待两个进程自行退出，然后向Windows报告该服务已经终止。 当你使用“stopargument”元素时，你必须使用“startargument”元素代替“argument”元素。参见下面的完整示例： catalina.sh jpda run catalina.sh stop 注意，元素的名称是“startargument”，而不是“startarguments”。因此，要指定多个参数，你必须指定多个元素。 （11）stoptimeout 当服务被要求停止时，winsw首先尝试调用GenerateConsoleCtrlEvent 方法（类似于Ctrl+C），然后等待长达15秒的时间，让进程自行退出。 如果这样做了，进程关闭还是失败了（或者如果进程没有控制台）， 然后winsw会调用终止进程的API函数来立即终止服务。 这个可选元素允许您改变这个“15秒”的值，这样您就可以控制winsw等待服务进程自行关闭的时间。 如何指定时间期限，可参考下面的“onfailure”元素的设置： 10sec","path":"2019/03/22/2998191920/","date":"03-22","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"有状态 Bean 和无状态 Bean 与 Spring 多线程的秘密","text":"有状态Bean和无状态Bean有状态Bean ：有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象 ，可以保存数据，是非线程安全的。在不同方法调用间不保留任何状态。 无状态就是一次操作，不能保存数据。 无状态Bean ：无状态对象(Stateless Bean)，就是没有实例变量的对象 。不能保存数据，是不变类，是线程安全的。 无状态的Bean适合用不变模式，技术就是单例模式，这样可以共享实例，提高性能。 Spring中的BeanSpring 中默认为单例模式 singleton ，单例模式下的无状态Bean 是线程安全的，而 有状态Bean 则是线程非安全的。 如果要使用 有状态Bean 应将 Spring 更改为 prototype 原型模式。 SpingBoot 在组件上使用 @Scope(“prototype”) 注解 而如果是prototype的话，就不会出现资源共享的问题。（即不会出现线程安全的问题） 或者也可将 私有全局变量 更换为 方法的参数变量 或 方法的局部变量 也可以使用 ThreadLocal 的独立线程副本来保证线程安全。 从源头上来说，在Spring中不应使用有状态Bean。 使用 单例模式 singleton 的优势： 提高性能，不用每次创建Controller实例，减少了对象创建和垃圾收集的时间 没多例的必要由于只有一个Controller的实例，当多个线程同时调用它的时候，它的成员变量就不是线程安全的。当然在大多数情况下，我们根本不需要Controller考虑线程安全的问题，除非在类中声明了成员变量。因此Spring MVC的Contrller在编码时，尽量避免使用实例变量。如果一定要使用实例变量，则可以改用以下方式： Controller中声明 scope=”prototype”，即设置为多例模式 在Controller中使用ThreadLocal变量,如：private ThreadLocal count = new ThreadLocal(); 实体bean不是单例的，并没有交给spring来管理，每次我们都手动的New出来的【如EMakeType et = new EMakeType();】，所以即使是那些处理我们提交数据的业务处理类是被多线程共享的，但是他们处理的数据并不是共享的，数据时每一个线程都有自己的一份，所以在数据这个方面是不会出现线程同步方面的问题的。 对于实体bean一般通过方法参数的的形式传递（参数是局部变量），所以多线程之间不会有影响。 有的地方对于有状态的bean直接使用prototype原型模式来进行解决。 对于使用bean的地方可以通过new的方式来创建 Spring依赖注入static静态变量的方法 @Autowiredprivate static YourClass yourClass; 不能直接注入 需要将静态变量作为通用组件注入 spring 不允许/不支持把值注入到静态变量中，如： import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component public class GlobalValue &#123; @Value(\"$&#123;mongodb.db&#125;\") public static String DATABASE; &#125; 如果你获取GlobalValue.DATABASE，会得到nullGlobalValue.DATABASE = null那我们如何解决这个问题呢。好在spring支持set方法注入，我们可以利用非静态setter 方法注入静态变量。如： import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component public class GlobalValue &#123; public static String DATABASE; @Value(\"$&#123;mongodb.db&#125;\") public void setDatabase(String db) &#123; DATABASE = db; &#125; &#125; 什么情况下使用多线程?多线程的使用离不开“阻塞”这个概念，不过，我想先对这个概念加以扩充，首先先来回想一下阻塞概念原本的意思，简单的说，就是程序运行到某些函数或过程后等待某些事件发生而暂时停止CPU占用的情况；也就是说，是一种CPU闲等状态，不过有时我们使用多线程并不一定是保持闲等时的程序响应，例如在追求高性能的程序中，某条线程在进行高强度的运算，此时若对运算性能不满意，我们也许会再启动若干条运算线程（当然，是在CPU有运算余力的情况下），此时，高强度运算应该归为一种“忙等”状态。 说到这，多线程归根究底是为了解决”等”的问题，那我们这样定义一个阻塞过程：程序运行该过程所消耗的时间有可能在运行上下文间产生明显的卡顿；这里使用“可能”是因为有些情况下，诸如Socket通信，如果数据源源不断的进入，那么阻塞的时间可能非常小，但我们还是使用了一条线程（nio另说）来处理它，因为我们无法保证数据到来的持续性和有效性;”卡顿”带有主观臆想，也就是说是使用者（人或一些自动化程序）不可接受的。 接下来，对什么时候使用多线程做一个回答：编写程序过程中需要使用某些阻塞过程时，我们才使用多线程，或者更进一步讲，使用多线程的目的是对阻塞过程中的实际阻塞的抽象提取。前半句话应该很好理解，而后面的一句虽然不太好懂，不过它对一个程序应具有的合理线程数量进行了阐释（这点接下来解释）。 一句话总结： 在编写程序时，遇到了阻塞过程而不想使整个程序停止响应时，应使用多线程；一个程序的合理线程数量取决于对实际阻塞的抽象程度。","path":"2019/03/21/2631318642/","date":"03-21","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"SpringDataJPA 分页 排序与动态查询","text":"分页创建 Page page =PageRequest.of(“1”,”1”); page - 从零开始的索引页 size- 要返回的页面的大小 sort - 排序 修饰符和类型 方法和描述 你也可以创建没有排序的分页static PageRequest of(int page, int size) static PageRequest of(int page, int size, Sort.Direction direction, String… properties)更方便的是可以一行代码创建有排序方向和属性的分页static PageRequest of(int page, int size, Sort sort)比如我们想遍历整个数据表，就可以使用分页遍历，这样不至于一次把数据全部加载到内存。 修饰符和类型 方法和描述Pageable first() 请求第一页。Sort getSort() 返回排序参数。Pageable next() 请求下一个页面。PageRequest previous() 请求前一页。注意：在使用next()方法时，不要把pageable.next()直接作为参数传入方法，如repository.findAll(page.next())这样的写法会导致死循环。查看next()方法的源码发现这个方法只是帮我们new了一个新的Pageable对象，原来的pageable还是没啥变化。一直next()下去也只是在原地踏步。 public Pageable next() { return new PageRequest(getPageNumber() + 1, getPageSize(), getSort()); }正确的写法： repository.findAll(pageable = pageable.next()); Spring Data Jpa除了会通过命名规范帮助我们扩展Sql语句外，还会帮助我们处理类型为Pageable的参数，将pageable参数转换成为sql语句中的条件，同时，还会帮助我们处理类型为Page的返回值，当发现返回值类型为Page，Spring Data Jpa将会把数据的整体信息、当前数据的信息，分页的信息都放入到返回值中。这样，我们就能够方便的进行个性化的分页查询。 总页数 int getTotalPages()元素的总数 long getTotalElements()返回当前页的索引（是第几页） int getNumber()返回作为List的页面内容 List getContent()返回当前在这个页上的元素的数量 int getNumberOfElements()返回用于请求当前页的Pageable default Pageable getPageable()返回页的大小。 int getSize()返回页的排序参数。 Sort getSort()页面是否有内容。 boolean hasContent()是否有下一页。 boolean hasNext()是否有上一页 boolean hasPrevious()当前页是否是第一个 boolean isFirst()当前页是否是最后一个 boolean isLast()下一页的Pageable Pageable nextPageable()上一页的Pageable Pageable previousPageable() 排序通过一行代码就可以快速使用： Sort sort = new Sort(Sort.Direction.DESC, “id”);在Sort类中定义了一个枚举类型Direction，该枚举类型声明了两个常量ASC，DESC定义方向。该构造方法的第一个参数指明方向降序（DESC）或升序（ASC），第二个参数指明以id列的值为准进行排序。 你也可以创建一个多属性的Sort实例。 Sort(Sort.Direction direction, List properties)你也可以只传入属性而不声明方向： Sort(String… properties)不过官方已经弃用该方法，推荐使用 public static Sort by(String… properties)当你不声明方向时，默认方向为升序。 public static final Direction DEFAULT_DIRECTION = Direction.ASC;Sort的一些方法 修饰符和类型 方法和描述Sort and(Sort sort)返回由当前排序的排序顺序与给定的排序顺序组成的新排序。Sort ascending()返回具有当前设置但升序方向的新排序。static Sort by(List&lt;Sort.Order&gt; orders)为给定的Sort.Order创建一个新的排序。static Sort by(Sort.Direction direction, String… properties)创建一个新的排序。static Sort by(Sort.Order… orders)Creates a new Sort for the given Sort.Orders.static Sort by(String… properties)Creates a new Sort for the given properties.Sort descending()返回具有当前设置但顺序相反的新排序。boolean equals(Object obj)Sort.Order getOrderFor(String property)根据property获取Orderboolean isSorted()boolean isUnsorted()Iterator&lt;Sort.Order&gt; iterator()static Sort unsorted()返回一个根本没有排序设置的排序实例。Sort.OrderSort.Order是Sort的一个静态内部类，官方说明是：PropertyPath实现了排序的配对。方向和属性。它用于提供排序的输入 。 简单来讲，你可以定义一个Order，在需要时传入order构建Sord实例。 Order(Sort.Direction direction, String property)更独特的使用是加入自己的空处理提示的枚举： Order(Sort.Direction direction, String property, Sort.NullHandling nullHandlingHint)Sort.NullHandling是可用于排序表达式的空处理提示的枚举。对使用的数据存储的一种提示，用于在非空条目之后对具有空值的条目进行排序。 在需要Sort时，可通过Order创建： Sort(Sort.Order… orders)Sort.Order的一些方法 修饰符和类型 方法和描述static Sort.Order asc(String property)创建升序的Order实例static Sort.Order by(String property)创建默认方向的Order实例static Sort.Order desc(String property)创建降序的Order实例Sort.Direction getDirection()Sort.NullHandling getNullHandling()String getProperty()Sort.Order ignoreCase()开启不分大小写排序boolean isAscending()返回此属性的排序是否要升序。boolean isDescending()返回此属性的排序是否应该降序。boolean isIgnoreCase()返回该排序是否区分大小写。Sort.Order nullsFirst()返回 Sort.Order 使用 Sort.NullHandling.NULLS_FIRST 作为空处理提示。First：第一个Sort.Order nullsLast()返回 Sort.Order 使用Sort.NullHandling.NULLS_LAST 作为空处理提示。Last：最后一个Sort.Order nullsNative()返回 Sort.Order 使用Sort.NullHandling.NATIVE 作为空处理提示。NATIVE：原生的Sort.Order with(Sort.Direction direction)创建Order实例.Sort.Order with(Sort.NullHandling nullHandling)创建Order实例.Sort withProperties(String… properties)创建Order实例.Sort.Order withProperty(String property)创建Order实例. 动态查询Example example = Example.of(customer); of 支持两个参数 示例对象实例 和 对象参数匹配器 ExampleMatcher 默认的参数匹配器会忽略 null，使用的动态参数应设置在对象实例中。 Customer customer = new Customer(); customer.setParm1(“xxxxx”); Example example = Example.of(customer);","path":"2019/03/20/1671325781/","date":"03-20","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"SpringDataJPA 踩坑集锦","text":"状态JPA实现为Hibernate，具有三种状态： 瞬时态(Transient) 未于数据库进行关联状态 持久态(Persistent) 与数据库关联状态 脱管态(Detached) 脱离了Hibernate关联的状态 事务与缓存事务注解 @Transcation，定义在 service 层或者 dao 层。对于 更新和删除操作必须声明事务。 默认情况下，Spring Data JPA 实现的方法都是使用事务的。针对查询类型的方法，其等价于 @Transactional(readOnly=true)； 增删改类型的方法，等价于 @Transactional。可以看出，除了将查询的方法设为只读事务外，其他事务属性均采用默认值。 如果用户觉得有必要，可以在接口方法上使用 @Transactional 显式指定事务属性，该值覆盖 Spring Data JPA 提供的默认值。 同时，开发者也可以在业务层方法上使用 @Transactional 指定事务属性，这主要针对一个业务层方法多次调用持久层方法的情况。 持久层的事务会根据设置的事务传播行为来决定是挂起业务层事务还是加入业务层的事务。 缓存注解 @Cacheable 为 Hibernate 的二级缓存注解，需要开启并指定第三方缓存。 往往不如 spring 自身缓存管理好用，而且对于 hibernate 来说需要使用 @QueryHint 声明查询才行。 JPQL基础语句只有 select update delete 三种语句操作 update 和 delete 语句必须使用 @Modifying 注解 是否执行 insert 操作基于操作对象是否包含实体主键，如果实体具有有效的主键执行 update 否则执行 insert。 update 会更新有修改过的实体属性，并返回更新或插入后的实体对象。 注意：null 也被算做属性值之一，故更新时需要注意空值 @Modifying 注解开启自动清理缓存 @Modifying(clearAutomatically = true) 可有效清理 update 操作产生的脏数据。 save()方法与 update 语句的区别是 update 可在语句中指定更新字段，而 save() 方法则更新整个对象中所有发生过修改的字段， 尤其会导致 null 更新问题。使用save () 方法建议先查询对象 再修改对象的对应属性 最后执行 save()。 delete 返回 integer 或 int 数值，表示受影响的对象数量 select 则和 SQL 中的 select 差不多，需要注意查询时要使用首字母大写，表示对象 不能使用 * 进行查询所有属性，当不指定select 字段时，相当于 * 查询，例如： JPQL from User u where u.id = 1 等效于 select * from user u where u.id = 1 对象通常使用 as 指定别名用于在查询条件中使用，也可用于指定投影属性别名，大部分情况可省略。 对于表之间的关联关系必须在实体中声明，单纯使用关联语句并不生效。 JPQL语句中的关联关系共 inner join join left join 三种，没有 on 。也没有 right join。 join 默认为 inner join 关联方式为：join 主表别名.从表 从表别名（可省略，当使用从表字段作为查询条件时需指定）例如： 无从表查询条件 from User u join u.dept 有从表查询条件 from User u join u.dept p where p.id = :id 或者 select 和 update 所返回的结果对象，仍然为持久态对象。 当执行flush()方法时，对结果对象的修改会被同步到数据库中。 使用 spring 自带的 Bean 复制工具类 BeanUtitls 的 Copy 方法可脱离持久态。 对集合类应使用深拷贝才能脱离Hibernate的管理。 JPA 支持基础聚合函数以及排序 语句参数JPA 支持传递普通参数和对象参数，支持 ? 和 :参数别名 两种占位符。 ? 为参数顺序占位符，例如在语句中 ?1 表示第一个参数，一旦参数顺序发生变化会出现问题，故不推荐使用。 :参数别名 为参数别名占位符 参数注解前必须添加 @Param 注解。普通参数和对象参数都必须使用该注解 示例： @Query(\"from User u join u.dept p where p.id = :userid\")User queryUser(@Param (\"userid\") Long id); 对于对象参数，需要使用spring的SPEL表达式：:#{``#参数对象别名.参数对象属性} 示例： @Query(\"from User u join u.dept p where p.id = :#&#123;#ParamUser.userid&#125;\")User queryUser(@Param (\"ParamUser\") User user); 投影投影主要解决返回的实体属性过多或需要使用自定义属性的情景 投影不同于实体，没有Hibernate的状态，修改投影不会影响数据库。 投影可以在原生 SQL 和 JPQL 中使用。 接口投影普通接口，内声明属性的get方法。 接口投影支持嵌套投影，类投影不支持。 例如一个具有name属性的User对象： public interface User&#123; getName();&#125; 嵌套投影中获取嵌套投影中的get方法的属性名必须为实体中关联属性名 下面示例中的 getPermissionList 方法，PermissionList 是 User 中关联实体的属性： @Data@Entiypublic Class User&#123; private String name; @OneToMany private List&lt;Permission&gt; permissionList;&#125; 嵌套投影示例： public interface User&#123; getName(); List&lt;Permission&gt; getPermissionList();&#125; public interface Permission&#123; getPermission();&#125; 注意get必须小写 错误示例： getUserName(); getuserName(); 类投影（DTO）Bean类，必须提供包含全部属性的构造方法，可使用 Lombok 的 @Value 注解简化。 public class User &#123; private String name; public User(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 多表关联对应关系首先 @OneToMany 的含义 @当前实体To关联实体 所以 @OneToMany 关联实体应为集合，@ManyToOne 不能为属性 默认维护关系端都为 Many 一侧，由于实体只能维护自身表结构，所以 @OneToMany 在不指定 @JoinColumn 时 将使用额外的关系表来维护关系。 对于 @OneToOne 则由 mappedBy 指定关系方来确定，默认单向关系维护方在自身。 在使用延迟加载的实体上添加 @JsonIgnoreProperties(&quot;hibernateLazyInitializer&quot;) 格式化注解可消除 hibernate 生成的延迟加载标识 单向一对一@OneToOne 标注在关联属性对象上，表明一对一关联关系 主要参数： targetEntity 属性标时关联的实体类，默认为当前标注的实体。 cascade 属性表示与此实体一对一关联的实体的级联类型。级联类型指对当前实体进行操作时关联实体执行的操作策略。 其中，在定义关系时，经常会考虑是否要定义cascade属性的问题。 若不定义，则对关系表不会产生影响，默认没有定义； 未定义级联类型又操作了关联实体将会导致异常 五种级联类型： CasacdeType.PERSIST，级联新建 CascadeTypE.REMOVE，级联删除 CascadeType.REFRESH，级联刷新 CascadeType.MERGE，级联更新 CascadeType.ALL，表示选择上述四种。 fetch 属性表示该级联实体的加载方式，有 LAZY 和 EAGER 两种方式 FetchType.LAZY：延迟加载，关联实体不会立即从数据库中加载 默认为 FetchType.EAGER 延迟加载的实体一旦被调用将会立即加载，延迟加载会导致 N+1 问题 使用 BeanUtitls 的 copy 方法的第三个参数 可忽略指定属性，可防止延迟加载失效 FetchType.EAGER：立即加载，关联实体立即从数据库中加载 optional 属性表示关联的实体是否允许为 null，默认为true，表示可以为 null。 当 optional 为 false 时 关联实体一旦为 null 则整个查询结果为 null，生成的查询语句为 inner join 当 optional 为 true 时 即使关联实体为 null 仍能获取查询结果，只有关联属性为 null，生成的查询语句为 left join mappedBy 属性用于双向关联实体时，标注在不需要保存关联关系的实体中，值为保存实体关系的实体属性名，非表名。默认为空，不指定则关联的双方都会生成关联外键。 orphanRemoval 属性用于在关联实体中自动清理无效的从表实体，且只能使用在 one 一侧。 在关联关系中单向级联中，将主表实体中的从表实体设置为 null 并不能删除从表实体，仅仅是将维护关系字段设置为 null 当 orphanRemoval 为 ture 时，就可以自动删除关系字段为 null 的从表实体了 @JoinColumn 标注在关联属性对象上，标明维护关联关系表字段的相关设置 name 属性用来标记表中自动生成的关联字段的名称（通常为外键） 如果不设置，则默认为 关联表_关联表主键 referencedColumnName 属性用于标明从表的关联字段，默认使用从表的主键用来作外键。 foreignKey 属性用于外键建立策略例如： foreignKey = @ForeignKey(ConstraintMode.NO_CONSTRAINT) 表示不建立外键，该属性仅影响外键是否生成，不影响关系字段生成 ConstraintMode.CONSTRAINT，建立外键 ConstraintMode.NO_CONSTRAINT，不建立外键 ConstraintMode.PROVIDER_DEFAULT，默认配置 insertable 和 updatable 可插入可更新，默认为 true。两个属性同时设置为 false 一般用在 @ManyToOne 中避免字段重复映射 unique 唯一约束 默认为 false 默认不唯一 nullable 空值约束 默认ture 默认可为空 @JoinColumns 可传入多个 @JoinColumn ，和一个 foreignKey 指定复杂的维护关系，示例： @JoinColumns(value = { @JoinColumn(name = &quot;A&quot;),@JoinColumn(name = &quot;B&quot;) },foreignKey = @ForeignKey(ConstraintMode.NO_CONSTRAINT)) 双向一对一@OneToOne 大部分注解同一对一，注意需要指定关系维护实体，配置 mappedBy 指定关系维护方 在双向一对一中，延迟加载在不维护关系的实体一方不生效 解决办法为更换成 @OneToMany 影响最小 或者不声明 mappedBy 主从实体都维护关联关系，此缺点为级联操作时将影响两个表。 单向一对多@OneToMany 属性与@OneToOne相同 默认为延迟加载 需要标注在集合属性上且必须指定泛型类型 如果没有使用 @JoinColumn 的 name 属性指定本表维护关系的字段，JPA会生成额外的中间表来维护关系。 清空关联集合时应get集合实体的 clear() 方法，由于放入新的空集合不受Hibernate管理将导致异常 双向一对多@OneToMany 声明在多端，实体属性必须为集合 @ManyToOne 声明在一端，实体属性不可为集合，没有 mapperby 属性 @ManyToOne 中要使用 FetchType.LAZY，否则会导致性能降低。 属性与 @OneToOne 相同 需要指定关系维护实体，配置 mappedBy 指定关系维护方 多对多@JoinTable name 属性为连接两个表的表名称，若不指定,则使用默认的表名称 表1_表2 joinColumn 属性表示，在保存关系的表中，所保存关联关系的外键的字段，并配合 @JoinColumn 标记使用 inverseJoinColumn 属性与 joinColumn 类似，它保存的是保存关系的另外一个外键字段 atalog 和 schema 属性表示实体指定点目录名称或数据库名称 uniqueConstraints 属性表示该实体所关联的唯一约束条件，一个实体可以有多个唯一约束条件，默认没有约束 其他注意事项@Query 中识别 SQL IFNULL 的解决办法 使用 coalesce() 函数 @Embedded @Embeddable 注解的使用 无限递归错误在使用Json来序列化对象时，会产生无限递归（Infinite recursion）的错误。这里有2个解决方法： 在@ManyToOne下面使用 @JsonIgnore 。 在@OneToMany下面使用 @JsonManagedReference ,在 @ManyToOne 下面使用 @JsonBackReference。 @JsonBackReference 和 @JsonManagedReference： @JsonBackReference 标注的属性在序列化（serialization)时，会被忽略。 @JsonManagedReference 标注的属性则会被序列化。在序列化时，@JsonBackReference 的作用相当于@JsonIgnore， 此时可以没有@JsonManagedReference。但在反序列化（deserialization）时，如果没有@JsonManagedReference， 则不会自动注入@JsonBackReference标注的属性；如果有@JsonManagedReference，则会自动注入@JsonBackReference标注的属性。 @JsonIgnore：直接忽略某个属性，以断开无限递归，序列化或反序列化均忽略。当然如果标注在get、set方法中，则可以分开控制，序列化对应的是get方法，反序列化对应的是set方法。","path":"2019/03/13/1800538801/","date":"03-13","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"一次由 Mysql 驱动引发的 Bug","text":"首先MySQL驱动包现在有2个： com.mysql.jdbc.Driver 是 mysql-connector-java 5中的 com.mysql.cj.jdbc.Driver 是 mysql-connector-java 6中的 错误的引用驱动包不仅会得到一个警告，还会送一个时区异常错误 1、JDBC连接Mysql5 com.mysql.jdbc.Driver: driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false 2、JDBC连接Mysql6 com.mysql.cj.jdbc.Driver， 需要指定时区serverTimezone: driverClassName=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://localhost:3306/test?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false 在设定时区的时候，如果设定serverTimezone=UTC，会比中国时间早8个小时，如果在中国，可以选择Asia/Shanghai或者Asia/Hongkong。 如果未明确设置，MySQL 5.5.45+, 5.6.26+ 还有 5.7.6+版本默认要求建立SSL连接。","path":"2019/03/11/1584671401/","date":"03-11","excerpt":"","tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://yihuishou.github.io/tags/Mysql/"}]},{"title":"优雅地更新 Github 上 Fork 的项目","text":"一般来说，由于开源项目比较活跃。Fork过的项目总会很快落后于主仓库中的内容。 如何快速而优雅地更新Fork的项目，是一个很棘手的问题。 其实是一个很简单的流程，主要是将合并请求的仓库互换，就可以通过new pull request来更新Fork过的代码。 流程如下： 打开你Fork的项目 点击Pull request 点击new pull request。默认情况下，github会比较original/your fork，这时没有任何差异。 点击switching the base.这时github将反过来比较yourfork/original，这时你将看到original相对你fork时的所有代码提交 点击create a pull request for this comparison，这时将会反过来向你的Fork过来的仓库提交一个pull request 点击confirm the merge合并代码就可以快速更新到最新的代码了。","path":"2019/03/11/182889867/","date":"03-11","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Mybatis 的缺陷","text":"Mybatis 的优势是由于采用模板映射，可以更自由的控制SQL语句和映射，可以使用很多的临时解决方案。但也真因为 采用模板的自由化，导致数据库字段发生变更时会产生很大的问题。 Mybatis是阿里这种大公司的御用框架，于是理所当然的成了绝大多数公司的标准选择 （理由很简单＂大公司都在用，我们用，没毛病＂．．．），尤其是这些年，很多人放弃了数据库的范式，极端追求数据库表的＂扁平化＂， 大量使用扁平的表结构，去掉关联关系，大量使用冗余，很多所谓的架构师还理所当然的说在服务化的场景下这是绝对正确的； 很多人说java需要分层，什么view，facade，service，dao．．．这还不够， 于是最终瞄准了DAO层～他们说将SQL拿出来独立出一个mapper层，说这样更容易管理，在代码里拼装SQL是上个世纪的做法，是一种很low的行为； 反正．．个人无法苟同这种无脑的逻辑； 我曾经无数次劝说别人放弃Mybatis这个坑；实际上，Mybatis让我的代码变得很糟糕，还让我重复干了好多事情～ Mybatis是什么？毫不客气的说，这货只是一个＂SQL模板引擎＂，而不是一个完整的DAO解决方案；为什么我要使用DAO框架去处理一些东西？因为我懒啊，如果什么都需要我自己干我还需要它干嘛？？有人说Mybatis generator～Mybatis generator能解决你80％的问题吗？如果Mybatis generator能解决你80％的问题，甚至你说你根本不需要自己写SQL，使用生成的就好，那么．．nutz这种简单轻量的框架不是更好？？？相比直接使用JDBC API，Mybatis没有让事情变得更加单（你甚至可以自己写一个jdbc generator根据数据库去生成DAO代码，我相信这大多数人都能做到）你要写的依然需要自己写，甚至你需要来回维护多份东西（数据库DDL，数据库文档，SQL XML，你的Entity代码，你的dao(或者mapper)接口…）; 想想当年，直接用hibernate写entity建模，生成DDL和常规通用接口代码，jekins+自己写的数据库文档生成工具，自动根据entity注释和数据库元数据生成markdown文档．．．不要太惬意哦；为什么我还要花那么多时间搞一个半自动的东西？（我的习惯是直接用java代码建模，然后直接生成数据库（物理模型），我甚至不需要手动添加索引，觉得entity哪个字段看着顺眼会用于查询加个注解就完了，然后用自己写得小工具生产通用dao层和数据库文档．．．很多事情只需要做一次就行了，用过hibernate建模的估计都知道我在说什么～） 很多人拿Mybatis和hibernate比，说Mybatis怎么怎么好．．我只能说，呵呵了；这两者根本不是一个层面的东西好吧～ mybaties使用XML这种＂非人类的东西（众所周知XML这种东西设计目标就不是给人阅读的）＂作为模板语言，代码可读性可维护性多糟糕你自己打开Mybatis generator生成的东西或者别人写的mapper文件看看你就知道了，你还说好维护？呵呵了，我直接在java里拼接SQL可读性都比他好；XML中对大于＂＞＂＂＜＂这种特殊字符串还需要做转义处理，使得可读性变得更加糟糕； &lt;if test='id != null and id gt 28'&gt;&lt;/if&gt;//这种方式和拼接字符串本质又有啥区别吗????不明白比在java中拼接字符串高明在哪里~//对于Java中拼接,还能用Java的语法优势,我甚至不需要熟悉MYBaXXX的XML语法~&lt;select id=\"selectUseIf\" parameterType=\"com.DynamicTestModel\" resultMap=\"userMap\"&gt; select * from t_user where 1=1 &lt;if test='id != null'&gt; and id=#&#123;id&#125; &lt;/if&gt; &lt;/select&gt; 你们觉得这种代码比拼接字符串高明在哪里？更容易阅读吗？？？？ 无病呻吟的封装； 一个DAO方法往往有多个参数，有些简单的接口，比如： /** getUser by username @param username 用户名,不能为空或者emptyStr @param tenantId 租户ID,不能为空或者emptyStr @return 返回租户下username对应的的用户,如果不存在返回null / User getUser(String username,String tenantId);我一直强调封装是必须有语义的，语义不随接口变化而变化，他在系统中存在单一的语义，同时最好能够复用～ 比如上面这个 User，你一看名称就知道它代表一个用户，这也符合单一功能原则～这个User在其他接口；比如 List listUsers(int first,int max) ;也能重用~所以我觉得User是一个不错的封装～而下面的GetUserTo 就不是一个好的选择～ 这个接口语义很简单（也很明确，调用它的人一看就知道要干嘛）：根据username和租户id（做过多租户saas软件大概明白这是干嘛的）获得一个User对象～ 在mybaties中我们需要怎么办做呢？使用注解标记区分username和tenantId两个参数； User getUser(@param(“username”) String username,@param(“tenantId” String tenantId);//多了一个注解,看着也还能接受~或者，使用一个专门的TO或者map进行封装； User getUser(GetUserTo to);//个人觉得这不是好的封装他的语义是接口级别的;其他接口而已这个封装几乎没有任何用处User getUser(Map to);//上面的封装还能忍,无非多几个不能复用的,没有语义的,一次性的to对象,//调用者跳入GetUserTo依然还能通过属性上的注释看到接口参数约束,可这个Map真的我就无法忍受了再或者放弃干脆放弃命名参数，使用下标～#{0} 多几行代码是小事情，可，这样真的优雅吗？?因为这个坑，我需要放弃一个优雅的模型和接口，从上到下提供各种蛋疼的封装～ 题外话：实际上，出现这个问题的原因也不能怪mybaties～我们知道我们通过反射可以获得方法的名称，参数类型和返回类型等信息（编译器和连接器通过参数个数和类型区分重载方法，不需要参数名称，所以参数名称在编译后被丢弃了），甚至泛型信息等元数据，但我们无法获得一个接口的＂参数名称＂（至少早期的java版本是这样的），class文件中的参数名称是arg0 arg1；运行时候这些参数名称虚拟机也不会使用和保留; 那么？除了注解，有什么办法在运行时获得接口参数吗？ java6的时代（那时候自己在写一个框架，需要获得接口参数名称）我费劲心思找到了一个 paul-hammant/paranamer ；这个东西～ 实际上，（基本思想：你无法从class中获得这些元数据，那么你只能从源代码出发，在编译的时候获取这部分数据了～）你可以解析你的源代码，然后从源代码中抽离出方法的参数名称，生成一个参数名称映射文件，运行的时候读取这个额外生产的映射文件来获取参数名； 这种方式的好处是在于兼容性；而，问题是在于，每次改变接口你都需要重新生成一遍这个映射文件； 对于java8可以添加 -parameters 编译参数，让编译器保留参数名称信息；但这依然会带来很多问题，比如字节码变大，兼容性等； 以上两种方法都不是很好，所以mybaties只能选择用目前提供的三种比较恶心的方式去处理这个问题了～ 很难优雅的管理区分＂手写SQL XML＂和＂自动生成的SQL XML＂； 很多时候我们使用Mybatis generator生成通用的mapper，如果将自己的SQL也写在里面，重新生成的时候会覆盖掉我们的自定义的东西，或者需要重新合并，非常麻烦；所以对于特殊的需求我们去要用另一个XML文件，分开管理他们～这已经是目前能想到的最优雅的方式；可..真的优雅吗？反正我觉得挺别扭的～ 知乎用户：数据库和ORM如何优雅的添加字段？ 代码生成是＂编译时（实际上是编译前）＂而＂非运行时＂； 很多小公司往往：ａ，需求不明确；ｂ，开发时间紧，没过多的时间做完善的设计； 于是，代码写着写着需要添加一个字段两个字段是常有的事儿；于是你需要：ａ，修改数据库增加字段，生成修改SQL；２，运行generator重新生成一遍；３，手动修改自定义部分，往往有多处地方修改（自定义的TO．XML多出地方包括头上的映射信息，手写SQL里面的各种地方），一不小心就改错了或者漏了（我相信任何用过Mybatis的人都遇到过这个问题）～；４，你可能需要维护一份数据库文档，然后你得打开你的word文档，然后添加一个字段～ ．．．． 老这么折腾，你的时间是多没价值啊？ 我们知道hibernate，包括国产的nutz这种框架在运行时生成SQL的～将SQL的生成推迟到运行的时候； 这种＂延迟SQL生成＂的方式或许有有那么一点点的性能上代价（生成的SQL是有缓存的～而且你真的无法忍受吗？） 可带来的好处是很直观的～添加一个字段？我在entity中加个字段就OK了？ 我需要干别的吗？或许也需要写个文档啥的，出数据库文档你自己不能写个工具吗？或者ＰＤ？？ 调试问题／代码重构 拼接字符串这种丑陋的方式至少能调试的？？？可你告诉我？放在XML中的SQL怎么调试？？？？？？ 用java写的好处是java能在语法级别给出错误提示，当然还有ＩＤＥ强大的重构功能；XML？搜一下关键字然后一行一行改吧～ 手写的SQL未必比hibernate生成的SQL效率高～ 可能因为项目时间的关系，有的人写SQL就不怎么讲究了，比如select * 这种不会出现在hibernate生成的SQL里～ 缓存问题～ （这里说的是二级缓存，不是thread级别的缓存） hibernate缓存？我只需要简单配置一下 ?就像这样? &lt;!-- Secondary Cache --&gt;&lt;property name=\"hibernate.cache.use_second_level_cache\"&gt;true&lt;/property&gt;&lt;property name=\"hibernate.cache.use_query_cache\"&gt;true&lt;/property&gt;&lt;property name=\"hibernate.cache.provider_class\"&gt;org.hibernate.cache.EhCacheProvider&lt;/property&gt; 我就能简单开启二级缓缓存了～包括查询缓存（KEY是SQL），数据缓存(KEY是实体ID) 替换掉这个EhCacheProvider，你就可以用你喜欢的任何缓存，比如OSCache,Memcached,或者redis…了～（当然，用的不好还是会出问题的，尤其是那个查询缓存，慎重～） mybaties缓存？你自己慢慢写吧～ 事实上～mybaties这种不完备的非实体映射的ＤＡＯ框架限制了你大概只能＂显式＂的调用缓存接口～ 分表分库／审计／全文索引问题～ hibernate shards；hibernate Envers；hibernate search；．．． hibernate有一系列的解决方案帮你做这些事情； mybaties？？？你自己慢慢写吧～ 糟糕的实现； 曾经简单看了一下mybaties的代码～因为时间长了，代码质量好不好已经不太记得了； 不过：我记得当时为了数据加密需要实现自定义的拦截器，看了一下mybaties拦截器的实现～ 发现拦截方法只有update（还有其他几个），并没有insert和delete（他们都走update逻辑，代码实现也是调用同一个方法）～ 有人提出这是个bug，Mybatis并没有承认这是个bug～（不知道现在什么情况） 关联查询 Mybatis 连接多张表？还能自动生成了吗？好吧，我觉得这是噩梦～至少比DBUtils或者手写SQL来说要麻烦的多得多～ 于是你说，我们不需要关联表，面向服务的开发是不需要关联的，不需要任何外键约束的，关联表是不合理的…..balabla…. 好吧，你赢了～或者你的业务足够简单～ 满世界找文件～ 文件多了，很多东西分开或许是好事，或许不是，因为这意味着，你需要这一个东西你得满世界找，本来改一个地方，你现在需要改多出地方；很多东西是有代价的，分层，业务拆分，服务拆分．．．需要找一个平衡点，而非毫无底线，越细越好～好的方式一定是简单的，我们是从实际需求出发，而非从某个完美设计或者构想出发，技术是为人类服务的，而不是折腾人的，很多东西是没必要的，比如XML中写SQL这种东西，你说分开容易管理，我只能呵呵了～","path":"2019/03/08/4211700064/","date":"03-08","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"架构混乱之谜","text":"前言新技术层出不穷。过去十年时间里，我们经历了许多激动人心的新技术，包括那些新的框架、语言、平台、编程模型等等。这些新技术极大地改善了开发人员的工作环境，缩短了产品和项目的面世时间。然而作为在软件行业第一线工作多年的从业者，我们却不得不面对一个现实，那就是当初采用新技术的乐趣随着项目周期的增长而迅速减少。无论当初的选择多么光鲜，半年、一年之后，只要这个项目依然活跃，业务在扩张——越来越多的功能需要加入，一些公共的问题就会逐渐显露出来。构建过慢，完成新功能让你痛不欲生，团队成员无法很快融入，文档无法及时更新等等。 在长期运转的项目中，架构的腐化是怎么产生的？为什么常见的面向对象技术无法解决这类问题？如何延缓架构的腐化？ 本文将尝试解释这一切，并提出相应的解决方案。读者需要具备相当的开发经验——至少在同一个项目的开发上一年以上；公司负责架构演进、产品演进的角色会从本文找到灵感。 架构架构这个词在各种场合不断地以各种面目表现出来。从维基百科的词条看来，我们经常听到的有插件架构（Plugin），以数据库为中心的架构（Database Centric），模型-视图-控制器架构（MVC），面向服务的架构（SOA），三层模型(Three-Tier model)，模型驱动架构（MDA）等等等等。奇妙的是，这些词越大，实际的开发者就越痛苦。SOA很好——但在它提出的那个年代，带给开发者的只是面向厂商虚无缥缈的“公共数据类型”；MDA甚至都没有机会沦为新一轮令人笑话的CASE工具。 在继续阅读之前，读者不妨问自己一个问题：在长期的项目中，这些大词是否真的切实给你带来过好处？更为功利的问题是：你，作为战斗在一线的开发者，在长期项目中可曾有过美好的体验？ 技术的演变与挥之不去的痛 企业应用的发展似乎从十年前开始腾飞。从Microsoft ASP/LAMP(Linux、Apache、MySQL、PHP)年代开始，各种企业应用纷纷向浏览器迁移。经过十年的发展，目前阵营已经百花齐放。与过去不同，现在的技术不仅仅在编程语言方面，常见的编程套路、最佳实践、方法学、社区，都是各种技术独特拥有的。目前占据主流的阵营有： RailsJava EE平台。值得一提的是Java VM已经成为一种新的宿主平台，Scala、JRuby更为活跃并引人瞩目LAMP平台。Linux/MySQL/Apache并没有多少变化，PHP社区从Rails社区获得了不少养分，出现了许多更加优秀的开发框架Microsoft .NET平台Django没有理由对这些新技术不感到振奋。它们解决了许多它们出现之前的问题。在它们的网站上都宣称各种生产效率如何之高的广告语，类似于15分钟创建一个博客应用；2分钟快速教程等等。比起过去21天才能学会XXX，现在它们在上手难度上早已大幅度降低。 需要泼冷水的是，本文开篇提出的问题，在上述任何一种技术下，都如幽灵般挥之不去。采用Ruby on Rails的某高效团队在10人团队工作半年之后，构建时间从当初的2分钟变成2小时；我们之前采用Microsoft .NET 3.5 (C# 3.0)的一个项目，在产生2万行代码的时候，构建时间已经超过半小时；我们的一些客户，工作在10年的Java代码库上——他们竭尽全力，保持技术栈与时俱进：Spring、Hibernate、Struts等，面对的困境是他们需要同时打开72个项目才能在Eclipse中获得编译；由于编译打包时间过长，他们去掉了大部分的单元测试——带来巨大的质量风险。 如果你真的在一个长期的项目工作过，你应该清楚地了解到，这种痛苦，似乎不是任何一种框架能够根本性解决的。这些新时代的框架解决了大部分显而易见的问题，然而在一个长期项目中所面对的问题，它们无能为力。 一步一步：架构是如何腐化的无论架构师在任何时代以何种绚丽的方式描述架构，开发中的项目不会超出下图所示： 基本架构示意 一些基本的准则： 为了降低耦合，系统应当以恰当的方式进行分层。目前最经考验的分层是MVC+Service。为了提供基础的访问，一些基本的、平台级别的API应该被引入。用Spring之类的框架来做这件事情。用AOP进行横向切分业务层面共性的操作，例如日志、权限等。为了保证项目正常构建，你还需要数据库、持续集成服务器，以及对应的与环境无关的构建脚本和数据库迁移脚本。阶段1 满足这个条件的架构在初期是非常令人愉悦的。上一部分我们描述的框架都符合这种架构。这个阶段开发非常快：IDE打开很快，开发功能完成很快，团队这个时候往往规模较小，交流也没有问题。所有人都很高兴——因为用了新技术，因为这个架构是如此的简单、清晰、有效。 阶段2 好日子不算太长。 很快你的老板（或者客户，随便什么）有一揽子的想法要在这个团队实现。工作有条不紊的展开。更多的功能加入进来，更多的团队成员也加入了进来。新加入的功能也按照之前的架构方式开发着；新加入的团队成员也对清晰的架构表示欣喜，也一丝不苟的遵循着。用不了多久——也许是三个月，或者更短，你会发现代码库变成下面的样子： 正常开发之后 你也许很快会意识到这其中有什么问题。但你很难意识到这到底意味着什么。常见的动作往往围绕着重构——将纵向相关的抽取出来，形成一个新的项目；横向相关的抽取出来，形成一个名叫common或者base的项目。 无论你做什么类型的重构，一些变化在悄悄产生（也许只是快慢的不同）。构建过程不可避免的变长。从刚开始的一两分钟变成好几分钟，到十几分钟。通过重构构建脚本，去掉那些不需要的部分，构建时间会降到几分钟，你满意了，于是继续。 阶段3 更多的功能、更多的成员加入了。构建时间又变长了。随着加载代码的增多，IDE也慢了下来；交流也多了起来——不是所有人能够了解所有代码了。在某些时候，一个很有道德的程序员尝试重构一部分重复逻辑，发现牵涉的代码太多了，好多都是他看不懂的业务，于是他放弃了。更多的人这么做了，代码库越来越臃肿，最终没有一个人能够搞清楚系统具体是怎么工作的了。 系统在混乱的状态下继续缓慢地混乱——这个过程远比本文写作的时间要长很多，之间会有反复，但据我观察，在不超过1年的时间内，无论采用何种技术框架，应用何种架构，这个过程似乎是不可抗拒的宿命。 常见的解决方案我们并非是坐以待毙的。身边优秀的同事们在问题发现之前采取了各种解决方案。常见的解决方案如下： 升级工作环境没有什么比一台与时俱进的电脑更能激励开发人员了。最多每隔三年，升级一次开发人员的电脑——升级到当时最好的配置，能够大幅度的提升生产效率，激励开发人员。反过来，利用过时的电脑，在慢速的机器上进行开发，带来的不仅仅是客观上开发效率的降低，更大程度上带来的是开发人员心理上的懈怠。 升级的工作环境不仅仅是电脑，还包括工作的空间。良好的，促进沟通的空间（以及工作方式）能够促进问题的发现从而减少问题的产生。隔断不适合开发。 分阶段的构建一般而言，构建的顺序是：本地构建确保所有的功能运行正常，然后提交等待持续集成工作正常。本地构建超过5分钟的时候就变得难以忍受；大多数情况下你希望这个反馈时间越短越好。项目的初期往往会运行所有的步骤：编译所有代码，运行所有测试。随着项目周期的变长，代码的增多，时间会越来越长。在尝试若干次重构构建脚本再也没办法优化之后，“分阶段构建”成为绝大多数的选择。通过合理的拆分、分层，每次运行特定的步骤，例如只运行特定的测试、只构建必要的部分；然后提交，让持续集成服务器运行所有的步骤。这样开发者能够继续进行后续的工作。 分布式构建即便本地快了起来，采用分阶段构建的团队很快发现，CI服务器的构建时间也越来越让人不满意。每次提交半小时之后才能得到构建结果太不可接受了。各种各样的分布式技术被创建出来。除了常见的CI服务器本身提供的能力，许多团队也发明了自己的分布式技术，他们往往能够将代码分布到多台机器进行编译和运行测试。这种解决方案能够在比较长的一段时间内生效——当构建变慢的时候，只需要调整分布策略，让构建过程运行在更多的集群机器上，就可以显著的减少构建时间。 采用JRebel或者Spork一些新的工具能够显著地提速开发人员的工作。JRebel能够将需要编译的Java语言变成修改、保存立即生效，减少了大量的修改、保存、重新编译、部署的时间；Spork能够启动一个Server，将RSpec测试相关的代码缓存于其中，这样在运行RSpec测试的时候就不用重新进行加载，极大提升了效率。 到底是什么问题？上述的解决方案在特定的时间域内很好地解决了一部分问题。然而，在项目运转一年，两年或者更久，它们最终依然无法避免构建时间变长、开发变慢、代码变得混乱、架构晦涩难懂、新人难以上手等问题。到底问题的症结是什么？ 人们喜欢简洁。但这更多的看起来是一个谎言——没有多少团队能够自始至终保持简洁。人们喜欢简洁只是因为这个难以做到。并不是说人们不愿意如此。很多人都知道软件开发不比其他的劳动力密集型的行业——人越多，产量越大。《人月神话》中已经提到，项目增加更多的人，在提升工作产出的同时，也产生了混乱。短期内，这些混乱能够被团队通过各种形式消化；但从长期看来，随着团队人员的变动（新人加入，老人离开），以及人正常自然的遗忘曲线，代码库会逐渐失控，混乱无法被消化，而项目并不会停止，新功能不断的加入，架构就在一天天的过程中被腐蚀。 人的理解总有一个边界，而需求和功能不会——今天的功能总比昨天的多；这个版本的功能总比上个版本的多。而在长时间的开发中，忘记之前的代码是正常的；忘记某些约定也是正常的。形成某些小而不经意的错误是正常的，在巨大的代码库中，这些小错误被忽视也是正常的。这些不断积攒的小小的不一致、错误，随着时间的积累，最终变得难以控制。 很少有人注意到，规模的变大才是导致架构腐化的根源——因果关系在时空上的不连续，使得人们并不能从其中获得经验，只是一再重复这个悲剧的循环。 解决方案解决方案的终极目标是：在混乱发生之前，在我们的认知出现障碍之前，就将项目的规模控制在一定范围之内。这并不容易。大多数团队都有相当的交付压力。大多数的业务用户并没有意识到，往一个项目/产品毫无节制地增加需求只会导致产品的崩溃。看看Lotus Notes，你就知道产品最终会多么令人费解、难以使用。我们这里主要讨论的是技术方案。业务上你也需要始终对需求的增长保持警惕。 采用新技术这可能是最廉价的、最容易采用的方案。新技术的产生往往为了解决某些特定的问题，它们往往是经验的集合。学习，理解这些新技术能够极大程度减少过去为了完成某些技术目标而进行的必要的经验积累过程。就像武侠小说中经常有离奇遭遇的主人公突然获得某个世外高人多年的内力一样，这些新技术能够迅速帮助团队从某些特定的痛点中解脱出来。 已经有足够多的例子来证明这一观点。在Spring出现之前，开发者的基本上只能遵循J2EE模式文档中的各种实践，来构建自己的系统。有一些简单的框架能够帮助这一过程，但总体来说，在处理今天看起来很基础的如数据库连接，异常管理，系统分层等等方面，还有很多手工的工作要做。Spring出现之后，你不需要花费很多精力，很快就能得到一个系统分层良好、大部分设施已经准备就绪的基础。这为减少代码库容量以及解决可能出现的低级Bug提供了帮助。 Rails则是另外一个极端的例子。Rails带来的不仅仅是开发的便利，还带来了人们在Linux世界多年的部署经验。数据库Migration， Apache + FastCGI或者nginx+passenger，这些过去看起来复杂异常的技术在Rails中变得无足轻重——稍懂命令行的人即可进行部署。 任何一个组织都无法全部拥有这些新技术。因此作为软件从业者，需要不断地保持对技术社区的关注。闭门造车只能加速架构的腐化——特别是这些自己的发明在开源社区早已有成熟的方案的时候。在那些貌似光鲜的产品背后，实际上有着无数的失败的案例成功的经验在支撑。 我们曾经有一个项目。在意识到需求可能转向类似于key-value的文档数据库之后，团队大胆的尝试采用SQLServer 2008的XML能力，在SQL Server内部实现了类似于No-SQL的数据库。这是一个新的发明，创造者初期很兴奋，终于有机会做不同的事情了。然而随着项目的进行，越来越多的需求出现了：Migration的支持、监控、管理工具的支持、文档、性能等等。随着项目的进展，最终发现这些能力与时下流行的MongoDB是如此的相似 ——MongoDB已经解决了大多数的问题。这个时候，代码库已经有相当的规模了——而这部分的代码，让许多团队成员费解；在一年之后，大约只有2个人能够了解其实现过程。如果在早期采用MongoDB，团队本有机会摒弃大部分相关的工作。 值得一提的是，高傲的开发者往往对新技术不够耐心；或者说对新技术的能力或局限缺乏足够耐心去了解。每一个产品都有其针对的问题域，对于问题域之外，新技术往往没有成熟到能够应对的地步。开发者需要不断地阅读、思考、参与，来验证自己的问题域是否与其匹配。浅尝辄止不是好的态度，也阻碍了新技术在团队内的推广。 新技术的选型往往发生在项目/产品特定的时期，如开始阶段，某个特定的痛点时期。日常阶段，开发者仍然需要保持对代码库的关注。下一条，重构到物理隔离的组件则是对不断增大的代码库另一种解决方案。 重构到物理隔离的组件显而易见的趋势是，对于同一个产品而言，需求总是不断增多的。去年有100个功能，今年就有200个。去年有10万行代码，今年也许就有20万行。去年2G 内存的机器能够正常开发，今年似乎得加倍才行。去年有15个开发人员，今年就到30个了。去年构建一次最多15–20分钟，今年就得1个小时了，还得整个分布式的。 有人会注意到代码的设计问题，孜孜不倦地进行着重构；有人会注意到构建变慢的问题，不懈地改进着构建时间。然而很少有人注意到代码库的变大才是问题的根源。很多常规的策略往往是针对组织的：例如将代码库按照功能模块划分（例如ABC功能之类）或者按层次划分（例如持久层、表现层），但这些拆分之后的项目依然存在于开发人员的工作空间中。无论项目如何组织，开发者都需要打开所有的项目才能完成编译和运行过程。我曾经见到一个团队需要在Visual Studio中打开120个项目；我自己也经历过需要在Eclipse中打开72个项目才能完成编译。 解决方案是物理隔离这些组件。就像团队在使用Spring/Hibernate/Asp.NET MVC/ActiveRecord这些库的时候，不用将它们对应的源代码放到工作空间进行编译一样，团队也可以将稳定工作的代码单元整理出来形成对应的库，标记版本然后直接引用二进制文件。 在不同的技术平台上有着不同的方案。Java世界有历史悠久的Maven库，能够良好的将不同版本的 JAR以及他们的以来进行管理；.NET比较遗憾，这方面真正成熟的什么也没有——但参考Maven的实现，团队自己造一个也不是难事（可能比较困难的是与MSBuild的集成）；Ruby/Rails世界则有著名的gem/bundler系统。将自己整理出来的比较独立的模块不要放到rails/lib /中，整理出来，形成一个新的gem，对其进行依赖引用（团队内需要搭建自己的gems库）。 同时，代码库也需要进行大刀阔斧的整改。之前的代码结构可能如下，（这里以SVN为例，因为SVN有明确的trunk/branches/tags目录结构。git/hg类似） 原来的库结构 改进之后，将会如下图所示： 改进的库结构 每个模块都有属于自己的代码库，拥有自己的独立的升级和发布周期，甚至有自己的文档。 这一方案看起来很容易理解，但在实际操作过程中则困难重重。团队运转很长一段时间之后，很少有人去关心模块之间的依赖。一旦要拆分出来，去分析几十上百个现存项目之间的依赖相当费劲。最简单的处理办法是，检查代码库的提交记录，例如最近3个月之内某个模块就没有人提交过，那么这个模块基本上就可以拿出来形成二进制依赖了。 很多开源产品都是通过这个过程形成的，例如Spring（请参考阅读《J2EE设计开发编程指南》，Rod Johnson基本上阐述了整个Spring的设计思路来源）。一旦团队开始这样去思考，每隔一段时间重新审视代码库，你会发现核心代码库不可能失控，同时也获得了一组设计良好、工作稳定的组件。 将独立的模块放入独立的进程上面的解决方案核心原则只有一条：始终将核心代码库控制在团队可以理解的范围内。如果运转良好，能够很大程度上解决架构因为代码规模变大而腐化的问题。然而该解决方案只解决了在系统在静态层面的隔离。当隔离出的模块越来越多，系统也因此也需要越来越多的依赖来运行。这部分依赖在运行期分为两类：一类是类似于 Spring/Hibernate/Apache Commons之类的，系统运行的基础，运行期这些必须存在；另外一类是相对独立的业务功能，例如缓存的读取，电子商城的支付模块等。 第二类依赖则可以更进一步：将其放到独立的进程中。现在稍具规模的系统，登录、注销功能已经从应用中脱离而出，要么采用SSO的方案来进行登陆，要么则干脆代理给别的登陆系统。LiveJournal团队在开发过程中，发现缓存的读写实际上可以放到独立的进程中进行（而不是类似EhCache的方案，直接运行于所在的运行环境中），于是发明了现在鼎鼎有名的memcached. 我们之前进行的一个项目中，发现支付模块完全能够独立出来，于是将其进行隔离，形成了一个新的、没有界面的、永远在运行的系统，通过REST处理支付请求。在另外一个出版项目中，我们发现编辑编写报告的过程实际上与报告发行过程虽然存在类级别的重用，但在业务层面是独立的。最终我们将报告发行过程做成了一个常驻服务，系统其他的模块通过MQ消息与其进行交互。 这一解决方案应该不难理解。与解决方案1不同的是，这一方案更多的是要对系统进行面向业务层面的思考。由于系统将会以独立的进程来运行这一模块，在不同的进程中可能存在一定的代码重复。例如Spring同时存在两个不相关的项目中大家觉得没什么大不了的；但如果是自己的某个业务组件同时在同一个项目的两个进程中重复，许多人就有些洁癖不可接受了。（题外话：这种洁癖在OSGi环境中也存在）这里需要提醒的是：当处于不同的进程时，它们在物理上、运行时上已经彻底隔离了。必须以进程的观点去思考整个架构，而不是简单的物理结构。 从单进程模型到多进程模型的架构思维转变也不太容易——需要架构师有意识的加强这方面的练习。流行的.NET和Java世界倾向于把什么都放到一起。而 Linux世界Rails/Django则能更好的平衡优秀产品之间的进程协调。例如memcached的使用。另外，现在多核环境越来越多，与其费尽心思在编程语言层面上不如享受多核的好处，多进程能够简单并且显著地利用多核能力。 形成高度松散耦合的平台+应用现在将眼光看更远一些。想象一下我们在做一个类似于开心网、Facebook、人人网的系统。它们的共同特点是能够接入几乎无限的第三方应用，无论是买卖朋友这类简单的应用，还是绚丽无比的各种社交游戏。神奇的是，实现这一点并不需要第三方应用的开发者采用跟它们一样的技术平台，也不需要服务端提供无限的运算能力——大部分的架构由开发方来控制。 在企业应用中实现这个并不难。这其中的秘诀在于：当用户通过Facebook访问某个第三方应用的时候，Facebook实际上通过后台去访问了第三方应用，将当前用户的信息（以及好友信息）通过HTTP POST送到第三方应用指定的服务网址，然后将应用的HTML结果渲染到当前页面中。某种意义上说，这种技术本质上是一种服务器端的mashup. Facebook Facebook App架构 这种架构的优点在于极度的分布式。从外观上看起来一致的系统，实际由若干个耦合极低、技术架构完全不同的小应用组成。它们不需要被部署在同一台机器上，可以单独地开发、升级、优化。一个应用的瘫痪不影响整个系统的运行；每个应用的自行升级对整个系统也完全没有影响。 这并非是终极的解决方案，只在某些特定的条件下有效。当系统规模上非常庞大，例如由若干个子系统组成；界面基本一致；子系统之间关联较少。针对这个前提，可以考虑采用这种架构。抽象出极少的、真正有效公用的信息，在系统之间通过HTTP POST.。其他的系统完全可以独立开发、部署，甚至针对应用访问的情况进行特定的部署优化。如果不这么做，动辄上百万千万行的代码堆在一个系统中，随着时间的推移，开发者逐渐对代码失控，架构的腐化是迟早的事情。 例如，银行的财务系统，包括了十多个个子系统，包括薪资、资产、报表等等模块，每一部分功能都相对独立并且复杂。整个系统如果按照这种方式拆分，就能够实现单点优化而无需重新启动整个应用。针对每个应用，开发者能够在更小的代码内采用自己熟悉的技术方案，从而减少架构腐化的可能。 结语没有糟糕的架构，变化使之我访问过很多团队。在很多项目开始的时候，他们花很多时间在选择用何种技术体系，何种架构，乃至何种IDE。就像小孩子选择自己钟爱的玩具，我相信无论过程如何，团队最终都会欣然选择他们所选择的，并且坚信他们的选择没有错误。事实也确实如此。在项目的开始阶段很难有真正的架构挑战。困难的地方在于，随着时间的增长，人们会忘记；有很多的人加入，他们需要理解旧代码的同时完成新功能；每一次代码量的突破，都会引起架构的不适应；这些不适应包括：新功能引入变得困难，新人难以迅速上手；构建时间变长等等。这些能否引起团队的警觉，并且采取结构性的解决方案而不是临时性的。 关于文档很多人说敏捷不提倡文档。他们说文档很难写。他们说开发人员写不了文档。于是就没有文档。 奇怪的是我看到的情况却不是这样。程序写得优秀的人，写起文字来也很不错。ThoughtBlogs上绝大多数都是程序员，很多人的文字写得都很赞。 而项目中的文档往往少得可怜。新人来了总是一头雾水。令人奇怪的是，新人能够一天或者两天之内通过阅读RSpec或者JBehave迅速了解这些工具的使用，到了团队里面却没有了文档。 抛开项目持续运转并交付的特性不谈，我认为巨大的、不稳定的代码库是文档迅速失效的根源。如果我们能够按照上述的解决方案，将代码库缩小，那么独立出来的模块或者应用就有机会在更小的范围内具备更独特的价值。想象一下现在的Rails3/Spring框架，他们往往有超过20个第三方依赖，我们却没有觉得理解困难，最重要的原因是依赖隔离之后，这些模块有了独立的文档可以学习。 企业级项目也可以如此。 创建应用程序的生态环境，而非单一的项目 功能总是不断的、不断的加到同一个产品中。这毫不奇怪。然而通过我们前面的分析，我们应当重新思考这个常识。是创建一个日益庞大的、缓慢的、毫无生机的产品，还是将其有机分解，成为一个生机勃勃的具有不同依赖的生态系统？项目的各方人员（包括业务用户、架构师、开发者）应当从短视的眼光中走出来，着眼于创建可持续的应用程序生态系统。","path":"2019/03/08/3607390463/","date":"03-08","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"创业的初衷","text":"大约五年前，我和几个小伙伴开始了金数据创业之旅。金数据是一个很简单的在线表单工具，帮助用户收集和管理日常工作中的数据，提升工作效率。从第一天起，金数据提供按月按年的订阅式服务，直到今天。 五年以来，金数据在产品上不断演进，包括地理位置字段、商品字段、动态邮件和短信通知，扩展字段，规则跳转，不收佣金的在线支付，开放API等功能，让没有编程能力但头脑灵活的高级用户一下入坑。 然而，金数据本质上仍然是一个以数据为核心的表单工具。它没打算做一个餐饮解决方案，成为一个客户关系管理(CRM)系统；也对完整的电商解决方案没有兴趣；同样，对于在创业路上伸出的橄榄枝——成为某政府园区的解决方案，入驻某云的市场，成为某电信公司的合作伙伴表现冷淡；也极少获得风险投资。就是这样的一个创业团队，三年后被收购，现在仍然保持独立运营，人数不过二十多人。 今天想讲的创业，除了融资、增长、下一轮融资、更高速的增长、更多的钱、死掉或者上市卖掉之外，也许还有另外一条路。 当下的创业圈，太多专注过热的风口，太多希望尽可能早、尽可能快的干掉可能潜在的竞争对手，成为市场的独裁者。 2014年，金数据3周年纪念笔记本扉页 聊起创业，如今没有人考虑仅仅给这个世界留下一点点痕迹。他们考虑的是接管这个世界。仅仅参与这个游戏还不够，他们要成为这个游戏本身。他们要定义游戏。仅仅服务客户还不够，他们要俘虏客户，占领客户。看看如今的打车市场，伟大的生态企业，还有冉冉升起就已硝烟四起的新兴共享单车公司。 在这种前提下，创业的定义，被局限到「全力以赴，直到完全占领整个市场」。市场充满着对「独角兽」的狂热。从拿到投资的第一天开始，几个人，几十个人，几百个几千个几万个人，996，711，披星戴月，为成为这个传说中的生物而努力工作。 你可能在想，这与我何干？我的项目与众不同。我将会打败所有的竞争对手，成为唯一的独角兽。管他哪来的钱，只要给钱，叫爸爸都没问题。跟我有什么关系？ 是吗？近几年创业失败的却是尸横遍野。在消耗了大量金钱和社会资源之后，躺倒在灰色的墓地中。 这又能怪谁呢？从拿到天使轮融资的那一天开始，便进入了这个注定不能回头的管道。每当拿到一轮新的融资，创始人，投资人，员工对于成为独角兽的信念又强了几分。 然而，你不得不看到的是，从天使轮开始，每一轮的融资你为自己又增加了几位老板。有更多的人会指导你如何做生意，给你更多关于增长的建议。当然，你拿了钱之后，这些就不仅仅是「建议」了。这是欠了一笔债务，从今往后，你只能接受这种随之而来的「唠叨」了。 如果你希望在接下来五年，或者终其一生成为中国的Salesforce, 下一个滴滴，美团……等估值百亿的公司，这是合理的逻辑。然而，花点时间仔细思考那是否真的是你想要的。尤其重要的是，这些在定义层面的成功，是否真是你想要的成功？ 不要不假思索地接受那些人人都正接受的字面意义的成功。是的，他们的确出现在许多地方：巨额融资，IPO，与巨头达成战略合作，在富丽堂皇的地方开了发布会，被称为「独角兽」，等等。如同漆过的木头，你需要刮下这些炫彩的部分，才能看到底下的木头。然而，没有刷上这层油漆，你就不成功了吗？ 我想，真正的问题是，你为何而创业？拜访过许多创业者，我并不相信大部分的创业者是为了最终的上市，或者财务回报。好吧，他们看到了有人去敲钟当然很受鼓舞，但这并非唯一的激励理由。我也鼓励你认真地、深入的探索自己创业的动机。 对于我而言，当初开始做金数据的内在动力是这样的： 我想要赋予普通人IT的能力。我想要创造出足够通用、在简单和强大之间平衡得很好的工具，帮助普通人节省时间，提高效率，更聪明的工作。 我想要直接跟最终用户沟通。我想要自行控制产品的研发路线。我想要将产品卖给在意质量并且愿意为此付费的客户。我不希望产品被少数大客户绑定。 我想要这个产品便宜、人人可用。我想要直接通过出售产品而盈利，而非产品免费去出售数据、隐私或者广告之类什么的东西。我讨厌「羊毛出在猪身上，让狗付钱」的逻辑。我想要做一桩盈利的生意。 我希望能够站着挣钱，而不用进入无休止的询价、谈合同、做方案、实施的漫长过程。我只挣自己的那一份——就像卖给厨师的菜刀，价格不会因为他工作在米其林餐厅还是成都小吃而不同。 是的，这就是老生常谈的一套：老老实实做生意。简单、诚信的生意。我做好产品，你付钱买。我们甚至没有什么复杂的商业模式或者变现逻辑，因为这就是很简单的——所有人都能理解。 我看到许多的企业的起落。曾经创业大赛排名靠前的企业，几年期间消失不见。许多关系短暂而临时。各种炫目的头衔在不同的公司、不同人之间轮转。我不接受这些。我追求长久而有效的关系。有许多的客户从2013年开始付费，直到今天。我们早期合伙人，最长的一起工作将近10年，最短的，也有5年了。人生状态已经发生了许多改变，我们仍然在一起。我们早期构建的合作伙伴，几年过去，直到现在还在。 我追求财务的可靠性。从经济学来说，30%的几率挣到300万，和3%的几率挣到3000万，和0.3%的几率挣到3亿，是一样的。但是具体来说，你会做那种选择？ 事实上，虽然直觉上我们做了选择，在创业路上，30%的几率挣到300万的策略却总是让步于0.3%挣到3亿。我对「一将功成万骨枯」的增长没有兴趣。我想要整个组织和个人能够伴随业务有机成长。世界很大。我有很多兴趣爱好，有家庭需要照顾，有许多书要读。我很想看看Rails 5.1有什么新特性，自然语言识别看起来也很有趣。我希望周围的同事也能够平衡自己的工作、兴趣和生活，有趣的享受每一天。生命只有一次。你的二十岁或者三十岁，只有一次。尽心工作，但工作并不是全部。 这些原动力，构成了我想要创建金数据的原因，也从一开始就对「成功」有了不同的定义。我们没有接管整个世界的计划。没有干掉竞争对手的想法。没有征服客户的想法。显然，也没有任何融资消息，没有种子轮，A轮，B轮。 我们对于「赢」的定义，甚至不包括目前普遍意义上的赢。比如成为市场上的第一名，或者「垄断」整个市场。涂抹竞争对手，或者以最短的时间烧掉最多的钱……这都不是我们的方式。我们与这个世界，是有你有我的共生，不是非此即彼的屠戮。 听起来似乎很温和，没有颠覆任何东西。然而，我更倾向于解释为谦逊和务实。我们在产品上的创新依然在不断进行。我们在对市场的教育依然在投入。我们连续三年每年营收增长超过300%，而今年第一季度未结束，我们的ARR（年度循环收入）已经超过去年全年。我们最终的目标仍然是有机的，整体的，包含了让团队、市场、客户共赢和全面成功的世界。 我拜访了许多创业团队。成功的或者不成功的。那些突然成功的背后往往伴随着许多小的激励，独一无二的路线。许多并不为人所知。我越来越感觉到创业世界中，有一个共同构建的巨大阴谋。人们都是利己的——仅仅为自己考虑，尤其是那些在创业过程中仅仅投入财务支持的。他们合理化这一切投入，认为对「社会」有帮助。创始人的原始想法，已经不重要。 媒体已经被训练为融资报道机器。某公司获得数千万A轮融资！某公司获得B轮融资！鼓掌！哇，了不起！ 但最终，创业团队只是「借」来了这笔钱。在他们公司的高层决策会议室里，又添了几把老板椅。在资本的复合杠杆作用下，道德不重要，增长治百病。贪婪本身是一个强大的动机，当老板变多，它继续加速。数据变现？涨价？改行做更挣钱的生意？跟着热点做？没问题！ 当然并非所有这些的都不好。但他们显著地消耗了创业世界中的注意力，而将一元成功论凌驾于所有的成功范式之上。这种扭曲甚至影响到了那些正常做着盈利生意的经营者。他们本只想贷款稍微扩大一些规模，结果被要求十倍百倍的增长。 在奥运中最重要的事情不是取得胜利而是全力参与，就像生命中最重要的事情不是获胜而是奋斗；最关键的原则不是征服，而是战斗到底。 ——现代奥林匹克运动会之父 皮埃尔-德-顾拜旦，1936 如果说「战斗到底」显得过于激昂的话，我更倾向于说享受整个过程。仔细审视你的创业动机，如果稍有迟疑，就不要拿投资人的钱。做对人们真正有用的产品。能够给世界留下痕迹，对于许多人生，便已足够。 By 陈金洲","path":"2019/03/06/2191692417/","date":"03-06","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Java 中格式化数字的四种方式","text":"下面记录了几种Java中处理数字的方式，主要用于对金钱的处理。 DecimalFormatDecimalFormat(&quot;#.00&quot;) # 表示整数,小数点后有几个 0 就保留几位小数 double demoValue = 1463.286;DecimalFormat df = new DecimalFormat(\".00\");// 效果一样DecimalFormat df2 = new DecimalFormat(\"#.00\");System.out.println(df.format(demoValue));System.out.println(df2.format(demoValue)); String.format%.2f 2代表保留小数位数 double demoValue = 1463.286;System.out.println(String.format(\"%.2f\", demoValue)); BigDecimalsetScale(2, BigDecimal.ROUND_HALF_UP) 参数1：保留小数位数 参数2：处理方式，四舍五入 示例： double demoValue = 1463.286;BigDecimal bg = new BigDecimal(demoValue);、// 科学计数法double d3 = bg.setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue();// 不使用科学计数法String d4 = bg.setScale(2, BigDecimal.ROUND_HALF_UP).toPlainString();System.out.println(d3);System.out.println(d4); NumberFormatsetMaximumFractionDigits(2) 参数1：保留小数位数 示例： double demoValue = 1463.286;NumberFormat nf = NumberFormat.getNumberInstance();nf.setMaximumFractionDigits(2);System.out.println(nf.format(demoValue)); 需要留意的地方 对于 0 的处理最好用 String.format 会输出 0.00 ，BigDecimal 并选择输出原始数值也可以 对于大数字使用 BigDecimal 要注意直接输出的 double 值会表示为科学计数法 NumberFormat 对 0 直接输出 0 ，但会对千位加，处理 不推荐使用 DecimalFormat 它会输出 .00 整数部分被直接丢掉了 其实算法也可以处理，但是太Low了 1、 str.split(String regex); public String[] split (String regex) 2、 str.replaceAll(String regex, String replacement); str.replaceFirst(String regex,String replacement) public String replaceAll(String regex, String replacement) 3、 str.matches(String regex) public boolean matches(String regex) 下面可以用来去除空格，包括字符串中的空格和前后两端的空格 正则表达式 1、 表示空格 “ \\s”， “[ ]”， “[\\s]” 表示多个空格 “\\s+”， “[ ]+”， “[\\s]+” 2、 表示数字 “\\d”， “[\\d]”， “[0-9]” 表示多个数字，同理，在后面加上”+” 可以用来添加空格 %-15s 左对齐 后面加空格 总共15个字符长度 %15s 右对齐 前面加空格 总共15个字符长度","path":"2019/02/28/435757353/","date":"02-28","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"互联网金融产品的科普","text":"知乎的答案记录一下 中国「互联网金融」的迅速发展，是中国金融体制极其落后，以及中国极其落后的监管法律造成的产物。 换句话说，中国的「互联网金融」看起来“非常发达”远超欧美发达国家，是因为中国金融体制太落后了。 多谢邀请，这邀请放我邀请里已经1年多了。本来不想来答这题，上次说上面那句话，被一堆人怼的跟条狗一样，包括某些大V。但是我还是很想答这题，这个答案也写了很久了，今天修改了一下发出来。因为我希望只要有一个人能看明白这一答，就能多多少少避免钱宝3M之类带来的悲剧。也能给我国金融业朝正常轨道上发展多一些助力。 我把最重要的一句话放在第一句。如果你因为第一句话不看了，那可以直接关闭了。为了避免一群鼓吹“互联网金融”的傻X们再来喷，我这次把答案写的不管多外行都能看懂，省的一些人看不懂就喷。就当上了一堂金融课吧。 由于我必须把答案写的不管多外行都能看懂，所以答案比较长，可能会显得比较啰嗦，多多谅解。 ================================== 在最开始，我必须解释一下，同工业，农业不同，「金融业」“非常发达”不是什么好事，可能是一件能危害到国民根本利益的坏事。 这点必须首先明确，如果你认为金融越“发达”越好，那你就大错特错了。 首先，我要解释一下「金融商品」，否则一般人无法看懂后面所有的内容。 金融商品，是一类特殊的商品，和传统的实物商品（衣服鞋子电脑等），或者服务类商品（快递，按摩等）不同。 金融商品有两个非常典型的特征： 首先，传统商品，你买鞋子是为了穿，你买电脑是为了用，你去看电影是为了爽。但「金融商品」不同，任何人，买金融商品的目的是为了「以钱生钱」。你买定期存款是为了利息，买国债也是为了利息，你买股票是为了股息以及未来股价变动的差价，买保险是为了保险金。 这点，就决定了，评价金融商品“好坏”（这个“好坏”，后面会重点解释。），和一般产品不一样，鞋子好坏看质量做工外型，电脑好坏看材质配置性能寿命，电影好坏看评价。 但金融商品的好坏，在普通人眼里，只跟一个因素有关——收益率。 银行理财，一年8%收益率的，就是比5%的“好”。100万的车险，5000块钱保费的，就是比8000块钱保费的“好”。 这点没有疑问。如果A银行一年存款利率5%，B银行一年3%，那傻子都知道去A银行存钱，因为A银行的存款产品“好”。 这里就出现了一个金融产品第一个特征——以钱生钱。如果专业点说，叫「利殖性」。 「金融商品」的第二个特征，也是不同于一般商品的。 你买鞋子，一手交钱一手交货，好不好你能当场判断，你觉得值就买，不值就不买。你付钱，鞋子给你。 你买电脑，你看性能配置，品牌和使用寿命，觉得好不好，值不值这个价，你觉得值，付钱电脑搬回家。觉得不值，不买。 而「金融商品」有一个非常典型的特征，不论任何金融商品，你购买，和你获得商品的回报，中间存在一个时间差。 这个时间差，可长可短，可能是几分钟，也可能是几十年。比如赌博，你下注，到开注，就是几分钟的事情。你存定期，那就是一年一结算。你买保险，那可能就是到死了才能获得回报。 这就是金融商品的第二个特征——付款和获得回报不同步，存在时间差，我们简称「时间差」。专业点说，叫做「风险负担性」。 由于这个「时间差」，你付了钱，并不能当场看到“商品”，你去店里买电脑，当场就能看到电脑质量如何。但金融商品，你付了钱，必须到期，才知道这个“商品”到底质量如何。你借出去的钱，到期了才能拿回本息。你去赌钱，开盘了才知道赢没赢，你去买彩票，开奖了才知道中没中，你去存款，到期了，才能拿到利息，你去买保险，出事了才能拿到保险金。 那么第一讲就结束了。 「金融商品」具有两个特征， 1，以钱生钱。 2，时间差。 这两个特征，是金融商品的「充分必要条件」。 任何买卖只要符合这两个条件，就必然是「金融」，「金融商品」也必然符合这两个条件。 通过这点，我们就可以知道，存款，国债，借贷，股票，信托，保险，赌博，彩票。全部都是金融，其本质都是一样的。 OK，只要能理解「金融产品」，后面就非常好理解了。 接下来，我们讲金融行业。需要解释一个词「道德风险」。 我举个例子，债券股票和保险对于一般外行人比较难理解，我们就拿非常简单的彩票来举例子，来帮助理解，因为他们都是金融商品，本质是一样的。 例： 假如你设计了一款彩票，1-100,100个数字，选一个，下注，一注100块钱。一天后开奖。 那么请问奖金是多少你不赔也不赚？ 显然，一万块钱奖金，你是不赔也不赚的。 但是你想赚钱，你把奖金设置成1000，那么你每卖出去一万的彩票，你就能赚9000，没问题对吧？ 但是对于买彩票的人来说，他们就是想碰碰运气，100块以小博大，赚10倍，何乐而不为呢？于是他们就来买了，因为对于他们来说，概率是个很玄学的东西，大家都更相信运气，哪怕是长期看稳亏不赚的彩票，也有很多人买。毕竟我也不是长期买，万一一次就中了呢？ 于是第一次，1000个人来买你的彩票，你卖了10万的彩票，你赚了9万。 你看，金融业赚钱，就这么容易。 你的同行看不顺眼了，TMD凭什么你小子空手套白狼，躺着赚钱这么舒服？这钱不能就让你赚啊！于是你的同样也设计了一款彩票。一样1-100,100个数字选一个下注，一注100块，一天后开奖。 但是他的奖金是2000。 于是彩民们一看，一样的玩法，一样的价格，这家奖金高。 所以大家都去买你同行家的彩票了。 然后你一看，TMD还是这孙子会玩，我的钱你也敢来赚？那我能服吗？ 第二天你把奖金提升到3000，于是彩民们又都回来买你的了。 你同行不服，提升到4000。 你不服，提升到5000。 …… 最后，你们都把奖金提升到9999。每一万赚1块，毕竟不能再少了，再少都不赚钱了，于是你和你的同行都是9999的奖金，达成了默契，大家谁也别把谁逼死。 你们两个各平分了彩票市场50%的份额。 这就是金融业的市场竞争。通过让利给消费者，来获得更大的市场份额。不论什么金融业都有这样的竞争。在银行业，叫做「利率竞争」，在保险业叫做「保费竞争」，在证券业。叫做「手续费竞争」，在信托业叫做「托管费竞争」。 但这个时候，你怒从心中起，恶向胆边生。“TMD老子本来卖彩票赚的好好地，10块赚9块，还不是你这个傻逼来跟我竞争，搞得我1万才赚1块？” 于是这个时候，你把奖金提高到2万。反正你经营彩票多年，手头有很多钱，也能亏一阵子。 所有彩民一看，啊，这彩票奖金这么高？都来买你的，于是你又霸占了市场份额，而且由于很多人从你的彩票赚钱了，又有很多新的人来买你的彩票。 第一次你2万奖金，之前的1000人都来买你的彩票。你一次亏了10万。 第二次你还是2万奖金，之前的1000人又带了1000个人来买你的彩票。你一次亏了20万。 第三次，「你的彩票能赚钱」已经在江湖流传开来，大家都来买你的彩票。一次有50万人来买你的彩票，你卖了5000万的彩票。 但是这次，你直接卷钱跑了，没有再发奖金。于是你一次“赚”了5000万！ 一次性能赚5000万，毫无技术含量，这就是金融。 之后，你被警察抓了。但是这5000万，你已经转移到国外，追不回来了。没错，你坐牢了，但是你骗走了50万人一共5000万的积蓄，引发了巨大的社会群体事件，这50万人跑去政府门口抗议，要求把你放出来，让你继续做彩票。 但是你知道，这彩票做不下去，根本不赚钱，你之所以弄个2万的奖金，就是为了一次卷走这5000万。 你赚了5000万，但是社会损失了5000万的财富。 这就是金融的「道德风险」，那为什么金融会有道德风险呢？ 我们之前提到，金融的两个特征： 1，钱生钱。 2，时间差。 由于你的买卖是钱生钱的买卖，对于一般民众，「风险」这东西毕竟太高深，只要有得赚，就是“好产品”。赚的越多越“好”。 但是不同于你卖电脑，好不好是人家看了才知道。金融产品这个“好不好”，是你说了算。 这就涉及到第二个特征「时间差」，付钱在先，交货在后。这产品“好不好”，你事先告诉消费者。但是“商品质量”如何，事后交货才知道。 这就产生了严重的「信息不对称」，你告诉消费者，你的彩票是能赚钱的，消费者先把钱给你了，但是赚不赚钱，消费者事后才知道。这个时间差，你就可以做手脚，把钱卷走跑路。 这就涉及到一个非常严重的问题。 「金融的准入机制」，金融不是谁想干就能干，金融是个非常没有技术含量的东西。如果人人都能干，那么「道德风险」就会非常高，会对社会造成非常严重的危害。 所以社会，不论银行，保险公司，借贷公司，担保公司，信托银行，证券公司，必须有政府颁发的牌照才能开业，否则是严重的犯罪「非法设立金融机构罪」。如果你还因此损害到了公众利益，那么会非常严重，「集资诈骗罪」「非法吸收公众存款罪」都等着你…… 知道钱宝是怎么赚钱的吗？ 好，我们接下来再讲，我们有了准入机制。 那么政府允许的金融公司就能好好经营吗？ 我们知道，之前的彩票的例子非常简单，我们再举个例子，这次呢，我们用「银行」来举例，因为股票和保险确实比较难理解。 例： 你是一家银行。 很多人来你这里存款。 你给存款的人一年3%的利息。 于是有1000个人，一人放了1000万在你这里，你一年要给每个人支付30万的利息。 你就有了100亿。 但是你每年要给他们3亿利息，怎么办呢？ 那你就要用这100亿去赚钱，赚的比3亿多，多出来的都是自己的。 你用这100亿去放贷，找你借钱的人，你一年收他们6%的利息。 存钱3%，借钱6%。 那么请问你用这100亿一年能赚多少钱？很简单，3亿对吧？ OK。但是呢，人类社会，并不是所有人都讲信用的。你能把人彩民的钱卷款跑了，你借钱给别人，别人就一定会还吗？ 如果别人不还，就叫坏账，如果坏账率1%，也就是说，你借出去1亿，就有100万不还。也就是你借出去100亿，实际上你只能收回来99亿外带利息。 那你一年还能赚2亿。 你说，没关系，我控制一下坏账率，借钱之前评估一下别人没有能力还就行了。稳赚不赔，金融业赚钱毫无技术含量。 这个时候，正好有个东西，叫比特币，价格疯涨，本来1块钱一个，一个月涨到100块，再一个月涨到1000块。 很多人看着都眼红。他们都去买比特币，低买高卖。 但是很多人呢，都没有钱，问你银行借，你就借给他们。 随着比特币疯涨，他们用你的钱赚的盆满钵满，都按时还钱。 于是你说，你看，他们信用都很好的，都按时还钱。我还借给他们，稳的一笔。 突然有一天，比特币一下从100000块一个跌倒1块钱一个，瞬间借你钱的人把你借给他们的钱亏的干干净净，谁都还不起钱了。 恭喜你，你遭遇了「系统性风险」，你这100亿，借出去，一分钱都没收回来，在你这存钱的人，你也没钱给他们提，于是银行破产。这1000个人把一辈子的积蓄存在你这里，你给他们全亏了。他们去找政府算账，银行居然倒闭了！政府你们要兜底！ 于是社会不稳定，治安恶化，你损失了社会100亿财富。 你说没关系，让借钱的人用东西来抵押，我再借就行了啊。稳得一笔。 于是很多人用现在最值钱的「房子」来抵押，1000万的房子抵押，你就借700万，你觉得很稳！他们不可能不还，不还我还赚300万呢！ 不过某一天，房价暴跌，本来1000万的房子，就值100万了，他们借了你700万不还了，还倒赚600万呢！ 恭喜你，你又一次遭遇了「系统性风险」。 于是你就很稳，只借给还款能力超强，工作超稳定，资产超多的人钱，他们肯定还得起。稳得一笔。 但问题来了，没有那么多还款能力超强的人啊，没人问你借钱，你还要每年给存款的人3%的利息，没人借钱你怎么赚钱？ 于是你不得不把钱借给一些还款能力不太行的人，拿一些垃圾担保物抵押。不然贷款放不出去啊，没人问你借钱你怎么赚钱啊？ 当然，最后他们不光不还给你利息，连本金都不还了。 恭喜你，你遭遇了「次贷危机」。 所以，如何控制风险，就是个很严重的问题。你说这风险到底怎么控制啊？你不知道。我也不知道。你看，金融也不是那么“毫无技术含量”对吧~？ 另外还有个问题，别人在你这存钱，偶尔大病小灾，婚丧嫁娶，约炮看电影总要用钱，平时总得取一点。别人在你这存了100亿，你总不能把100亿全部拿去放贷吧？万一人家急用钱跟你取钱，你没钱给他怎么办？ 所以呢，你就必须要留「准备金」，以防平时的日常兑现。 但是这个「准备金」是多少呢？留多了，赚的就少了，搞不好还亏。留少了，人家来取钱，你给不出就麻烦了对吧？ 你看，「风险控制」「准备金」这个深奥的学问你就不懂了吧？所以金融看起来毫无技术含量，其实是一个技术含量特别高的行业，连美国的银行精英们都搞不定，把雷曼兄弟搞破产了。何况一般人呢？ 你看，而且就算是正经搞金融的，也会出事。还是因为「金融」的那两个特征。 1，钱生钱 2，时间差 哪怕是专业的机构，有时候也搞不定这两个问题，钱收到了，但是没用好，会亏钱，用错处了，也会亏钱。外部波动，也会出现问题。 关键这钱还不是你自己的，是社会大众的。 而且金融业是面向社会大众的行业，一旦金融机构发生问题，受损的不是一个人两个人，而是成千上万的人……你想想钱宝有多少人受害？ 所以对于金融行业，就必须有严格的「监管」。 监管分为两部分，就是我们说的两个例子： 1，准入机制。 2，风险控制。 政府必须有专业的部门，这个部门在我国叫做银监会保监会和证监会，来管理这些金融机构，首先，政府觉得你没这个能力，就不能让你干金融，万一你卷钱跑了怎么办？ 第二，监管部门必须严格按照程序，设立一系列指标，来控制你的风险，包括「准备金」「内部风险负债率」「会计规范」「信息公开」「产品备案」「资金运用」「消费者风险提示」「信用审查」「定价标准」等一系列规范 这一系列监管，都是必须以「法律规定」的形式来确立的，一旦违反，就是犯法，会被罚款，停业，甚至坐牢。 也正是金融「时间差」「钱生钱」这两个特征，让金融对于一般人来说非常神秘，因为他们评价「金融产品」“好坏”一般是通过「钱生钱」，也就是收益率，而会忽视「时间差」，也就是风险。 所以现代正规监管体制下的金融商品都非常复杂，买一个保险，条款就N页纸，买个理财，风险说明也是一长串。也正是为了保护消费者利益。 所以我们举的两个例子，就对应了两个「监管原则」。 首先，你有没有资格去干金融？ 第二，就算你干了金融，你能不能控制好风险？ 也就是说，金融发不发达。跟规模没有任何关系，规模特别大可能说明你特别落后。监管力度和制度，是评价一国金融发达不发达的一个最重要的标准。其次才是看规模。 在良好的监管下，能做到规模很大，那才叫发达，像欧美日那样的。 监管一坨屎，什么人都能干金融，干金融的想怎么定价怎么定价，资金想怎么用怎么用，信息不用公开，风险不用跟消费者提示，根本不管「风险」，大不了就跑路。这叫“发展”？？ 很遗憾，我国“高速发展”、“非常发达”的「互联网金融」属于后者，根本不能叫“发达”，无序发展，一坨屎。今天这个跑路，明天那个跑路，借贷利率动不动就10%朝上，互联网保险保费比白菜都便宜。 赌场都比他干净。 缺乏监管的金融，不存在“发达”和“发展”。很不巧，我国的金融监管体制极其落后，相关法律法规也极其落后。 「互联网金融」现在就是谁都能干，想怎么干怎么干。可不就“发达”嘛？ 有了完善的监管和法律，才配得上谈“发达”“发展”。 金融业不同于农业和工业，规模和“发达”并不能划等号。 不夸张的讲，如果我国有完善的金融监管体制和法律法规，那些「互联网金融」至少死90%，只能留下一些蚂蚁，京东，腾讯这些有实力，按照规矩来办事的。 你说美国也有“互联网金融”，抱歉，人家那是“金融科技Fintech”，跟我们的不是一码子事，中国基本不存在真正搞科技的，都是去干“毫无技术含量的金融”。金融业用的科技，全是国外的，我国的科技什么水平内行心里都有数。 作为一个金融体制非常落后的国家，信贷覆盖面和规模极小，中小企业融资困难，风险控制能力极差，还在用人家早就淘汰掉的「准备金率」，利率都没自由化国家，股票还有涨跌停板用T+1，金融机构资金运用范围极窄的国家，消费者信用金融才刚刚起步的国家，就已经觉得自己“金融发达”了？ 你跟我说中国金融发达？你TM逗我呢？ 已经有多少人被所谓“发达的金融”弄得倾家荡产，我朝的金融业什么样，自己心里没点B数么…… 还是那句话。 中国「互联网金融」的迅速发展，是中国金融体制极其落后，以及中国极其落后的监管法律造成的产物。 正视差距，明白自己的问题在哪，才能稳步发展，慢慢追上我们和发达国家的差距。别整天做着春秋大梦，自己什么水平自己不知道么。不让某X宝，钱X的是事件一次又一次的发生。 少让一些人因为金融倾家荡产，多给社会一些活力，让企业融资容易点，让企业融资成本低一些，能给员工多发点工资，让消费者和企业在融资的时候能少承担点风险。才能让我们的社会越来越好。 哪怕有一些真的是想好好搞金融的，不是抱着骗钱的目的来的，他们没有监管和政策技术的指导，就能干好吗？缺少监管的金融业必然一团乱。","path":"2019/02/21/783285968/","date":"02-21","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"ANT 通配规则","text":"ANT三种通配符 通配符 说明 ? 匹配任何单字符 * 匹配0或者任意数量的字符 ** 匹配0或者更多的目录 匹配原则ANT使用最长匹配原则(has more characters)例如URL请求/app/dir/file.jsp，现在存在两个路径匹配模式/**/*.jsp和/app/dir/*.jsp，那么会根据模式/app/dir/*.jsp来匹配 示例/app/*.x 匹配(Matches)所有在app路径下的.x文件/app/p?ttern 匹配(Matches) /app/pattern 和 /app/pXttern,但是不包括/app/pttern/**/example 匹配(Matches) /app/example, /app/foo/example, 和 /example/app/**/dir/file.* 匹配(Matches) /app/dir/file.jsp, /app/foo/dir/file.html,/app/foo/bar/dir/file.pdf, 和 /app/dir/file.java/**/*.jsp 匹配(Matches)任何的.jsp 文件","path":"2019/02/20/1504490322/","date":"02-20","excerpt":"","tags":[{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://yihuishou.github.io/tags/SpringSecurity/"}]},{"title":"用 Lombok 来简化代码","text":"引入&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; #### 常用注解 注解名 注解位置 功能 备注 @Getter/@Setter 类/属性 提供 Get/Set 方法 @Getter(lazy=true) 类/属性 提供双重锁的 Get 方法 @ToString 类/属性 提供重写的 toString 方法 @EqualsAndHashCode 类/属性 提供重写的equals方法和hashCode方法 @Data 类 提供包含 @Getter/@Setter @EqualsAndHashCode @RequiredArgsConstructor 的整合注解 @Value 类 @Data 的变体 但属性被 final 修饰 没有Set方法 @Builder 类 提供建造模式方法 Default默认值在Lombok 1.18.4版前有Bug @Log 类 提供日志类注入支持，需要指定实现日志类型 @Cleanup 类 提供资源回收支持，自动调用 close 方法 @Synchronized 方法 提供同步锁支持， @NoArgsConstructor 类 提供无参构造方法 @AllArgsConstructor 类 提供所有参数的构造方法 @RequiredArgsConstructor 类 提供包含常量和空值校验的构造方法 @NonNull 参数前 提供空值校验 @Log4j 类 提供Log4j日志类 logo 支持 @Slf4j 类 提供Slf4j日志类 logo 支持","path":"2019/01/25/2610927596/","date":"01-25","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Tensorflow 安装注意事项","text":"主要问题时 Tensorflow 对 GPU 加速的版本有兼容性要求 下表是主要对应关系 Tensorflow 版本 CPU/GPU Python 版本 cuDNN CUDA tensorflow-1.8.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.8.0 GPU 2.7, 3.3-3.6 7 9 tensorflow-1.7.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.7.0 GPU 2.7, 3.3-3.6 7 9 tensorflow-1.6.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.6.0 GPU 2.7, 3.3-3.6 7 9 tensorflow-1.5.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.5.0 GPU 2.7, 3.3-3.6 7 9 tensorflow-1.4.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.4.0 GPU 2.7, 3.3-3.6 6 8 tensorflow-1.3.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.3.0 GPU 2.7, 3.3-3.6 6 8 tensorflow-1.2.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.2.0 GPU 2.7, 3.3-3.6 5.1 8 tensorflow-1.1.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.1.0 GPU 2.7, 3.3-3.6 5.1 8 tensorflow-1.0.0 CPU 2.7, 3.3-3.6 N/A N/A tensorflow_gpu-1.0.0 GPU 2.7, 3.3-3.6 5.1 8 安装固定版本的 tensorflow pip install tensorflow_gpu==1.1.0 安装CUDA的注意事项： 环境变量需要自行配置 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\binC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\lib\\x64C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\libnvvp cuDNN 解压放到 CUDA\\v8.0 目录中 检测python脚本 import ctypes import imp import sys def main(): try: import tensorflow as tf print(\"TensorFlow successfully installed.\") if tf.test.is_built_with_cuda(): print(\"The installed version of TensorFlow includes GPU support.\") else: print(\"The installed version of TensorFlow does not include GPU support.\") sys.exit(0) except ImportError: print(\"ERROR: Failed to import the TensorFlow module.\") candidate_explanation = False python_version = sys.version_info.major, sys.version_info.minor print(\"\\n- Python version is %d.%d.\" % python_version) if not (python_version == (3, 5) or python_version == (3, 6)): candidate_explanation = True print(\"- The official distribution of TensorFlow for Windows requires \" \"Python version 3.5 or 3.6.\") try: _, pathname, _ = imp.find_module(\"tensorflow\") print(\"\\n- TensorFlow is installed at: %s\" % pathname) except ImportError: candidate_explanation = False print(\"\"\" - No module named TensorFlow is installed in this Python environment. You may install it using the command `pip install tensorflow`.\"\"\") try: msvcp140 = ctypes.WinDLL(\"msvcp140.dll\") except OSError: candidate_explanation = True print(\"\"\" - Could not load 'msvcp140.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. You may install this DLL by downloading Microsoft Visual C++ 2015 Redistributable Update 3 from this URL: https://www.microsoft.com/en-us/download/details.aspx?id=53587\"\"\") try: cudart64_80 = ctypes.WinDLL(\"cudart64_80.dll\") except OSError: candidate_explanation = True print(\"\"\" - Could not load 'cudart64_80.dll'. The GPU version of TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL: https://developer.nvidia.com/cuda-toolkit\"\"\") try: nvcuda = ctypes.WinDLL(\"nvcuda.dll\") except OSError: candidate_explanation = True print(\"\"\" - Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Typically it is installed in 'C:\\Windows\\System32'. If it is not present, ensure that you have a CUDA-capable GPU with the correct driver installed.\"\"\") cudnn5_found = False try: cudnn5 = ctypes.WinDLL(\"cudnn64_5.dll\") cudnn5_found = True except OSError: candidate_explanation = True print(\"\"\" - Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Note that installing cuDNN is a separate step from installing CUDA, and it is often found in a different directory from the CUDA DLLs. You may install the necessary DLL by downloading cuDNN 5.1 from this URL: https://developer.nvidia.com/cudnn\"\"\") cudnn6_found = False try: cudnn = ctypes.WinDLL(\"cudnn64_6.dll\") cudnn6_found = True except OSError: candidate_explanation = True if not cudnn5_found or not cudnn6_found: print() if not cudnn5_found and not cudnn6_found: print(\"- Could not find cuDNN.\") elif not cudnn5_found: print(\"- Could not find cuDNN 5.1.\") else: print(\"- Could not find cuDNN 6.\") print(\"\"\" The GPU version of TensorFlow requires that the correct cuDNN DLL be installed in a directory that is named in your %PATH% environment variable. Note that installing cuDNN is a separate step from installing CUDA, and it is often found in a different directory from the CUDA DLLs. The correct version of cuDNN depends on your version of TensorFlow: * TensorFlow 1.2.1 or earlier requires cuDNN 5.1. ('cudnn64_5.dll') * TensorFlow 1.3 or later requires cuDNN 6. ('cudnn64_6.dll') You may install the necessary DLL by downloading cuDNN from this URL: https://developer.nvidia.com/cudnn\"\"\") if not candidate_explanation: print(\"\"\" - All required DLLs appear to be present. Please open an issue on the TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues\"\"\") sys.exit(-1) if __name__ == \"__main__\": main()","path":"2019/01/21/3194033158/","date":"01-21","excerpt":"","tags":[{"name":"Deepleanring","slug":"Deepleanring","permalink":"https://yihuishou.github.io/tags/Deepleanring/"}]},{"title":"分布式调用的第一原则就是不要分布式","text":"美国计算机科学家，LaTex的作者Leslie Lamport说：“分布式系统就是这样一个系统，系统中一个你甚至都不知道的计算机出了故障，却可能导致你自己的计算机不可用。”一语道破了开发分布式系统的玄机，那就是它的复杂与不可控。所以Martin Fowler强调：分布式调用的第一原则就是不要分布式。这句话看似颇具哲理，然而就企业应用系统而言，只要整个系统在不停地演化，并有多个子系统共同存在时，这条原则就会被迫打破。盖因为在当今的企业应用系统中，很难寻找到完全不需要分布式调用的场景。 服务的拆分 首先我们应该知道一个概念，服务拆分是对系统而言，是通过某个维度（一般是系统高可用）去做到服务责任单一，比方说，商城系统有详情页，订单等模块，对于大型商城，详情页的读多写少，这个时候可以做成一个微服务。原则是拆分粒度应该保证微服务具有业务的独立性和完整性，服务的拆分围绕业务模块进行拆分。服务的拆分围绕业务模块进行拆分是一种理想状态下的拆分方法，换句话说，我们在架构设计之初就假定我们可以掌握一切。然而，不同的服务可能由不同的团队开发与维护，实际场景下，微服务的便利性更多的在于团队内部能够产生闭环，换句话说，团队内部可以易于开发与维护，便于沟通与协作，但是对于外部团队就存在很大的沟通成本与协作成本。现在，我们来看一个案例。团队A 考虑到功能的复用性而开发了一个“互动组件”，其中包括 “评论模块”功能。此时，团队 B 并不知情也开发了一个类似的“互动组件”。而团队 C也有这个需求，它知道团队 A 有这个“互动组件”，希望可以复用，但是由于这个“互动组件”在设计的时候更多地考虑了团队 A的当前业务，没有很好的复用性，例如不支持“评论盖楼”功能，而由于团队 A 出于当前其他项目的进度原因无法马上提供支持，团队 B评估后决定花一周时间自己开发一个符合自己业务需求的“互动组件”。此时，各个项目团队各自维护了一个“互动组件”。此外，我们再来看一个案例。一个OA系统拥有“用户管理”、“文件管理”、“公告管理”、“政策管理”、“公文管理”、“任务管理”、“审批管理”等功能，如果按照微服务架构思想可以围绕业务模块进行拆分，但是事实上这个OA 系统的最终用户只有 30多人，使用微服务架构可能有点“杀鸡用牛刀”的感觉了。回顾下，第一个案例中，由于团队之间的职责与边界导致了服务的复用存在局限性，甚至造成各自为战的局面，这种情况一般需要公司层面进行规划和统筹。第二案例中，由于用户量不大，系统也不复杂，使用微服务反而带来了不必要的设计和运维难度，同时也带来了一些技术的复杂度。此外，我们还需要考虑服务依赖，链式调用、数据一致性、分布式事务等问题。 总结下，服务的拆分是一个非常有学问的技术活，要围绕业务模块进行拆分，拆分粒度应该保证微服务具有业务的独立性与完整性，尽可能少的存在服务依赖，链式调用。但是，在实际开发过程中，有的时候单体架构更加适合当前的项目。实际上，微服务的设计并不是一蹴而就的，它是一个设计与反馈过程。因此，我们在设计之初可以将服务的粒度设计的大一些，并考虑其可扩展性，随着业务的发展，进行动态地拆分也是一个不错的选择。","path":"2019/01/18/3499735000/","date":"01-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"跟上Java8 简捷的文件","text":"//以当前路径作为Path对象Path p = Paths.get(“.”);//使用传入的字符串返回一个Path对象Path p2 = Paths.get(“D”,”ReviewIO”,”URL”);//对应的路径System.out.println(“p对象的对应路径：” + p.toString());System.out.println(“p2对象的对应路径：” + p2.toString());//路径数量是以路径名的数量作为标准System.out.println(“p路径数量：” + p.getNameCount());System.out.println(“p2路径数量：” + p2.getNameCount());//获取绝对路径System.out.println(“p绝对路径：” + p.toAbsolutePath());System.out.println(“p2绝对路径：” + p2.toAbsolutePath());//获取父路径System.out.println(“p父路径：” + p.getParent());System.out.println(“p2父路径：” + p2.getParent());//获取p2对象的文件名或者文件目录名System.out.println(p2.getFileName());//通过Path对象返回一个分隔符对象Spliterator split = p2.spliterator(); Paths类获取文件或文件目录路径可以使用采用多个字符串形式，也可以使用Path.get(D:\\ReviewIO\\URL)这种形式。返回的Path对象完全可以代替File类用于文件IO操作。 Files类Files完成文件复制的方法，方法很简单。Path source = Paths.get(“F:”,”Java经典练习题.pdf”);Path dest = Paths.get(“F:”,”files.txt”);File f = new File(“F:\\ok.pdf”);f.createNewFile();//如果f对象对应路径不存在就创建一个。System.out.println(“source对象的文件路径：” + source);//复制文件Files.copy(source, new FileOutputStream(f)); Files完成写入文件的方法//写入内容到文件ArrayList as = new ArrayList&lt;&gt;();as.add(“A”);as.add(“B”);as.add(“C”);Files.write(dest, as, Charset.forName(“GBK”));实例说明：个人觉得用起来不怎么方便。方法参数很多，尤其是Iterable&lt;? extends CharSequence&gt;参数，Iterable是个顶级接口，实现类几乎都是集合类，并且限制了类型通配符上限是CharSequence，这意味着要使用泛型为字符类型的集合类作为数据写入指定文件中，很麻烦。如果只是简单写入内容到文件中，建议使用重定向标准输出流，然后使用打印流写入，简单粗暴。使用Files类读取文件内容就不介绍了，个人觉得除了文件复制比较简洁通用，其他两个方法个人认为使用IO流或者NIO流比较方便一点。剩下来会介绍一些Files类的方法。public static void main(String[] args) throws IOException {Path source = Paths.get(“F:”,”Java经典练习题.pdf”);/** 返回值为boolean的操作方法样例 */System.out.println(Files.isHidden(source));//文件是否隐藏System.out.println(Files.isExecutable(source));//文件是否可执行System.out.println(Files.isWritable(source));//文件是否可写//获取Paths对象对应的文件路径的文件储存FileStore f = Files.getFileStore(Paths.get(“F:”));FileStore e = Files.getFileStore(Paths.get(“E:”));System.out.println(“F盘的总大小” + f.getTotalSpace());System.out.println(“F盘的可用大小” + f.getUsableSpace());System.out.println(“F盘的未分配空间” + f.getUnallocatedSpace()); } 除了以上的方法之外，Files类还提供遍历文件和目录、监控文件变化、读取和设置文件权限、查看文件属性的方法，功能十分强大。 Path 与 Paths java.nio.file.Path接口代表一个平台无关的平台路径，描述了目 录结构中文件的位置 Paths 提供的 get() 方法用来获取 Path 对象： Path get(String first, String … more) : 用于将多个字符串串连成路径 Path 常用方法： boolean endsWith(String path) : 判断是否以 path 路径结束 boolean startsWith(String path) :判断是否以 path 路径开始boolean isAbsolute() : 判断是否是绝对路径 Path getFileName() : 返回与调用Path 对象关联的文件名Path getName(int idx) : 返回的指定索引位置 idx 的路径名称 int getNameCount() : 返回 Path 根目录后面元素的数量Path getParent() ：返回 Path 对象包含整个路径，不包含 Path 对象指定的文件路径 Path getRoot() ：返回调用 Path 对象的根路径 Path resolve(Path p) : 将相对路径解析为绝对路径 Path toAbsolutePath() : 作为绝对路径返回调用 Path 对象 String toString() ： 返回调用 Path 对象的字符串表示形式 Files 类 java.nio.file.Files 用于操作文件或目录的工具类。 Files 常用方法： Path copy(Path src,Path dest, CopyOption … how) : 文件的复制Path createDirectory(Path path,FileAttribute&lt;?&gt; … attr) : 创建一个目录 Path createFile(Path path,FileAttribute&lt;?&gt; … arr) : 创建一个文件void delete(Path path) : 删除一个文件 Pathmove(Path src, Path dest, CopyOption…how) : 将 src 移动到 dest 位置long size(Pathpath) : 返回 path 指定文件的大小Files 类boolean exists(Path path,LinkOption … opts) : 判断文件是否存在boolean isDirectory(Path path, LinkOption …opts) : 判断是否是目录boolean isExecutable(Path path) : 判断是否是可执行文件 booleanisHidden(Path path) : 判断是否是隐藏文件boolean isReadable(Path path) : 判断文件是否可读boolean isWritable(Path path) : 判断文件是否可写 boolean notExists(Path path,LinkOption … opts) : 判断文件是否不存在public static A readAttributes(Path path,Class type,LinkOption… options) : 获取与 path指定的文件相关联的属性 。Files 常用方法： 用于操作内容 SeekableByteChannel newByteChannel(Path path, OpenOption…how) : 获取与指定文件的连接， how 指定打开方式。DirectoryStream newDirectoryStream(Path path) : 打开 path 指定的目录 InputStream newInputStream(Path path, OpenOption…how): 获取 InputStream 对象 OutputStream newOutputStream(Path path, OpenOption…how) : 获取 OutputStream 对象自动 资源管理","path":"2019/01/15/2862273391/","date":"01-15","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"太阳可能没有核聚变","text":"太阳核聚变理论存在很多严重的错误 启示：盲目的相信书本中的知识，而不加思考的学习是很可怕的 摘要：大铁球放火中烧到1000℃，通红放外面冷却半小时都还能有很高温度。体积和质量是铁球数万倍的一座高山，整体加热到1000℃放自然环境中冷却，冷却时间也是铁球冷却的数万倍。青藏高原海拨约5000米，总面积250万平方公里(可覆盖内陆15个省);体积和质量也将是铁球的数百亿倍，如能整体加热到3000℃放环境空间中冷却，即使冷却时间为铁球的数十亿倍，表面和内部温度仍然很高。地球半径6378公里，32公里厚度的地壳相对于地球半径来说只不过是“一层膜”;青藏高原也只是膜上的“粉尘”。如果地球的原始温度为1500万摄氏度，即使内部没有核聚变产生能量，地球表面温度由1500万℃降低到6000℃或者零度，也需约数亿年的时间。太阳光球表面温度6000℃，进光球内一点温度就有可能达到10万℃、20万℃、50万℃甚至300万℃、800万℃、1000万℃;核心区域温度1500万℃，体积约20735个地球。如清华教授所述，太阳中心区域没有核聚变产生能量，1000年后我们去测量太阳表面温度也不会有明显变化，这就是太阳表面温度能够保持恒定的真正内因。 组成太阳的化学元素，以质量计算，氢占74.9%，氦占23.8%，重金属元素只占不到2%，氧(占1%)、碳(0.3%)、氖(0.2%)、和铁(0.2%);地球化学成分及元素丰度:铁占34.6%、氧占29.5%、硅占15.2%、镁12.7%、镍2.4%、硫1.9%、钛0.05%、其他元素占3.65%。 地球元素丰度数据得自科学家全球采集数以百万计的样本，汇总后获得地球元素丰度数据。但是不管科学家们采集多少样本，都只能采自地表;地球内部30公里、50公里、100公里、1000公里、3000公里下面的成份;科学家肯定是无法采集到。地表采集的样本数量再多，也只能是代表地表。不能代表地下也一样成分，更不能代表整个地球的元素丰度。 1970到1994年，深度钻探解构地球核心，世界最深钻井俄罗斯科拉钻井，钻孔深达12.262公里。金含量达4克/吨就具有商业开采价值，表层很少能找到含量超10克/吨的金矿;当钻探深度达到9500米时，钻头钻进了一个含有黄金和钻石的地层，取出岩芯经分析，金含量居然高达80克/吨;由此可以看出地球深处与地球表面是完全不同的。地表下100公里，1000公里下面是什么成分只有鬼知道。任何人采用任何仪器设备，都不可能进行探测和获知。 我们做一个球。外面10米是铁;里面10米铜;再里面10米是铅，再10米是锰;邀请光谱专家采用全世界最好的光谱设备探测一下这球的成份和元素丰度;为方便探测还可以将球放置山顶或者悬挂起来，应该说全世界所有的光谱专家都无法探测。这样一个小球科学家们都不能够搞定，遥远的陨石元素丰度更加难以探测分析。还有土星木星、天王星海王星、冥王星以及我们的地球太阳，光谱根本不可能探测分析出其内部成分数据，那些数据应该说全都是虚假的。鸡蛋壳是什么成份数据，整个鸡蛋就是什么成份数据吗?显然我们不能犯这种低级错误。组成太阳的化学元素，以质量计算，氢占74.9%，氦占23.8%，重金属元素只占不到2%，这些数据没有依据，因此太阳中心每秒燃烧6.2亿吨氢，持续热核聚变为5.96亿吨氦的热核聚变也是没有依据。太阳热核聚变理论已经有100年历史了，随着科技的进步，真相也会慢慢浮出水面。 核聚变的反应时间不可控，温度也不可控。制造1吨、1千吨、1万吨氢弹，核反应时间为一瞬间;制造1千万吨、1亿吨、一亿亿亿吨氢弹，反应时间也应该是一瞬间。太阳相当于放大版氢弹，究竟氢弹造多大以后开始延长反应时间?每增加多少万吨?热核聚变延长多少秒?太阳已经核聚变50亿年，未来还有50亿年是如何计算出来的，还没有一个可信服的解释。 氘氚是最低端热核聚变，据中国原子能机构了解，氘氚核聚变的点火温度约5500万℃，氢弹核聚变产生的最高温度据说可达100亿℃;即使我们人类利用氘氚热核聚变能产生出100亿℃超高温，也无法在氘氚氢弹外再添加真正的氢气或者液氢，利用氘氚热核聚变产生的100亿℃超高温，去点燃真正的氢或氦进行热核聚变。从而制造温度更高温度和威力更大的热核聚变，这种成本极低的热核聚变实验，美国苏联中国都无法实现。激光武器产生那么高的温度，也都无法点燃真正的氢气进行核聚变，真正氢热核聚变的点火温度，及真正氢热核聚变产生的温度是多少，至今都还没有任何国家报道，更加不要说进行氦热核聚变。 太阳核心区域为太阳半径1/4(约20735地球)，按太阳核聚变理论说法，即使太阳中心1500万℃能实现点火条件，那么太阳每秒燃烧6.2亿吨真正氢，热核聚变为5.96亿吨氦的持续热核聚变，产生出来的温度也是1500万℃?氢热核聚变反应产生出来的温度与其点火温度完全相同。这也明显违背热核聚变反应条件，因此太阳核聚变理论是不成立的。 另外：太阳核心区域的成分、密度、温度、压力等所有条件都完全相同，每秒核聚变燃烧6.2亿吨氢，是从太阳核心区域哪个位置均匀取出呢?曾与核聚变某教授进行过探讨，该教授的解答是概率。也就是说：太阳核心区域，成分、密度、温度、压力等所有条件都完全相同的情况下，是否核聚变存在着概率问题。既然成分、密度、温度、压力等所有条件都完全相同的情况下存在着概率，也就会出现同时命中概率和同时都没命中概率这两个极端的情况。如果都同时命中概率，太阳核心区域同时核聚变，恒星太阳将会如同氢弹一样爆炸。如果某一时间都没有命中概率，太阳热核聚变熄火了。 地震波是指从震源产生向四外辐射的弹性波;地球内部存在着地震波速度突变的基干界面、莫霍面和古登堡面，将地球内部分为地壳、地幔和地核三个圈层;日震学是利用日震现象，是研究太阳内部结构的科学。唯独只有光谱能够分析出成分和元素丰度。但光谱分析也非常明确说，光谱仪器设备只能够分析物体表面成分，光谱分析绝对不能够探测和分析到星球的内部去，一整块岩石都无法分析。地球太阳、天王星海王星、冥王星陨石内部元素丰度数据绝对是没有依据的。太阳光球以内一片漆黑，根本无法探测分析，也无法证明太阳核心区域73%氢、25%氦构成，整个太阳热核聚变理论体系及其相关数据也就全部都是虚假的，因此那些复杂的太阳核聚变方程式也全部都虚假和没有依据。仅这一个证据就可以推翻太阳恒星核聚变理论，何况还有上面所述的其他依据，任何一个依据都能够推翻太阳恒星核聚变理论体系。 在缅甸赌石市场上多少人一夜暴富，一块石头就能够卖出几千万甚至上亿，瞬间就能成暴发户，也有人一夜倾家荡产;如果能有光谱仪器扫一下就知道是不是翡翠玉石成份，全世界多少有钱人谁不想去购买这种光谱设备，珠宝界也就不再有赌石行业，探矿也就不再需要地质队了。地球上一整块石头光谱科学家们都不能够搞定，也不可能分析出宇宙中的陨石成分。地壳上的东西我们都没整明白，能够通过光谱探测和分析出遥远宇宙中巨大陨石、土星木星、天王星海王星、冥王星和地球太阳内部的元素丰度根本就不可能实现。所有光谱设备都只能探测和分析物体表面毫米甚至微米，如同鸡蛋一样只能够探测表层，不能说鸡蛋表皮是什么成分就代表里面也都一样是什么成分，这种说法绝对是错误的。 研究科学理论必须要一丝不苟，严谨认真!科学理论需要从实践中来，还要能够回到实践中去，并且指导实践。通过上面所有的一系列问题，证明太阳核聚变理论绝对不是从实践中得来，也绝对不能够回到实践中去，绝对是错误的科学理论，太阳及恒星热核聚变理论出现错误，也将会导致一系列的理论出现错误。我们的科学研究和科学理论须要严谨认真、一丝不苟。大自然规律即和谐又统一，也是一点不揉沙子的;我们需要梳理一下，要用所有人的理论去检验所有人，再用所有对的人去检验所有的科学理论，如此不断的反复进行，我们才能够找到追求科学真理的正确方向。 太阳内部及表面温度能够保持恒定的真正原因。整个太阳系99.86%质量都集中在太阳上，质量约1.9891×10^27吨;光球表面温度6000℃，进光球一点温度就能10万℃、20万℃、50万℃甚至200万℃、300万℃、500万℃、800万℃、1000万℃，核心区域温度为1500万摄氏度，体积约20735地球体积(如果按照太阳核心区域的密度和质量计算将远超20735地球)。 从太阳中心区域温度1500万℃取出一个地球体积，裸露放置在3K(-270.15℃)宇宙空间中冷却;地球表面温度由1500万℃冷却到6000℃，冷却时间可能需要数千万年。表面往里一点点温度就可能达到10万℃、30万℃、50万℃甚至300万℃、500万℃、800万℃、1000万℃，中心温度仍然达到1500万℃。地球内部没有核聚变及能量产生，地下岩浆的温度也才1000℃、2000℃、3000℃，有32公里厚的地壳进行保温，即使再经过5000万年后，地下岩浆也都难以冷却成为石头。 太阳系99.86%质量都集中在太阳上，核心区域温度为1500万摄氏度，体积约20735地球(还没有按密度和质量算)。将太阳核心区域取出，裸露放置在-270.15℃的宇宙空间中冷却，完全没核聚变产生能量，经历几十亿年的冷却，内部仍然还有很高温度。经过漫长的时间，表面温度由1500万℃降到6000℃，里面温度仍达10万℃、20万℃，甚至200万℃、500万℃、800万℃、1000万℃，核心区域温度仍能够达到1500万℃，外面还包裹有超级厚度的隔热层进行保温。 水在一个大气压下沸点为100℃，随着压力的增加水温度达到200℃、300℃仍然还是水。虽然太阳表面温度达到6000℃，但是太阳表面压力超级巨大，在这种超级巨大的压力下很可能导致水都无法气化，更何况是超级大量沸点更高的其他物质。我们通过设备观察太阳表面，在太阳表面就如同没盖子的透明“超级高压锅”，如同地球表面各种岩石融化但又无法气化;太阳光球上各种岩石及金属液体混杂一起“熬粥”。太阳光球表面“熬岩石粥”，可比我们家里和大食堂熬大米粥，要巨大和剧烈猛烈很多。光球上的米粒组织我们可看作是“粥锅”正常开锅状态;光球内温度10万℃以上能量在不断的进行加热，熬煮各种熔岩和金属物质在太阳表面“超级巨大的高压锅”里翻滚沸腾，熔岩气化沸腾升起，温度降低又回到表面形成黑子。 光球内部温度达10万℃以上不断加热超级“高压粥锅”，总会产生剧烈沸腾和受热不均匀的情况发生，因此也就有太阳光斑和太阳黑子现象产生。受热不均匀的情况再巨大一些，就会形成太阳耀斑和日冕物质喷发(日珥)等现象;这些现象是由于太阳表面超级巨大“高压粥锅”，加热和受热不均匀及能量汇聚到一起产生的。就如同我们家庭或大食堂煮粥一样，正常开锅如米粒组织，受热不均和能量汇聚会导致粥锅不定时产生大气泡甚至剧烈到溢出粥锅外等情况。这种现象在太阳表面被超级放大，内部温度达到10万℃、100万℃超级巨大的能量，被传递到太阳光球由于能量汇聚和受热不均，就会不定时形成太阳光斑、太阳黑子、太阳耀斑和日珥等现象。 太阳内部蕴藏温度达到50万℃、100万℃、200万℃的超级高温和超级能量，将各种岩石溶液和金属溶液混在一起“煲粥”。太阳光球层巨大的压力如同“超级高压锅”，“锅里”岩浆只能够液化不能够气化或者气化沸腾亮如白昼，释放能量后又瞬间冷却，受太阳巨大引力和巨大压力作用成为液体又返回光球表面。各种各样熔岩和金属液体承受锅底50万℃、100万℃、200万℃超级能量加热，这种“超级高压锅”“煲岩石金属粥”的规模相比我们地球家庭和食堂大锅煮大米粥的情况完全是不一样的。太阳系99.86%质量都集中在太阳上，地球月球体积质量与太阳相比可忽略不计，各种岩浆和金属溶液在太阳对流层和光球层混在一起剧烈翻滚沸腾，随便一个沸腾都有可能达到100个甚至超过1000个珠穆朗玛峰高度。 正如清华教授所说：太阳中心完全没有核聚变，以太阳现有的体积质量及蕴藏的高温能量，温度也不可能瞬间就能冷却得下来。如果月球原始温度为1500万℃(月球相对太阳质量可忽略不计)，该温度也不可能瞬间就能够降低，我们人类在地球上也将会体验到如同烤焦蚂蚁一般的滋味，岩石金属都很有可能被烤化甚至气化(几千年都不一定能够冷却得下来)。更何况太阳体积与质量，高温能量保持几十亿年都完全没有问题。以太阳现在的质量和能量，完全的没有核聚变产生能量，继续冷却100年1000年我们的太阳表面温度都不会有明显降低，这是在太阳中心区域完全不发生核聚变的情况下。太阳现在没有核聚变，将来也不可能再产生和发生核聚变。太阳拥有太阳系99.86%质量，即使我们人类能够再继续监测100万年后，太阳表面的温度都不会有明显变化，这就是太阳表面和内部温度能够保持恒定的真正内因。","path":"2019/01/14/2168753306/","date":"01-14","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"倒车原理示意图","text":"引言记录一下倒车原理的动态示意图。 总结一下就是车辆的实际行驶轨迹是由后轮决定的","path":"2019/01/14/1112713561/","date":"01-14","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Java 8 中的模板字符串","text":"String.fomat例如： String.format(&quot;%s 今年%d 岁&quot;,&quot;我&quot;, 24); 该方法的缺点是必须指定模板的参数类型，例如%s必须传入String类型否则将抛出异常 并且%s不能重用。 例如下面的代码是错误的： String.format(&quot;%s 今年%d 岁，%s 回来了&quot;,&quot;我&quot;, &quot;24&quot;); 填充模板的变量不得少于模板中定义的参数，否则将抛出异常，而多出来的变量会被忽略。 MessageFormat.fomat例如： MessageFormat.fomat(&quot;{0}今年{1}岁&quot;,&quot;我&quot;, 24); 模板参数不要求参数类型，即使是null也会被格式化为null。 但特殊字符仍然需要转义才可被格式化。 填充模板的变量少于模板中定义的参数，会显示为模板{0}，而多出来的变量会被忽略，不会抛出异常。 模板参数可以被重用。 例如下面的代码是正确的的： String.format(“{0}今年{1}岁，{0}回来了”,”我”, 24); 字符串的快速分割与合并例如如下的字符串可以通过split方法来快速分割来转化为数组 String intStr = “1,2,3,4,5,6,7,8,9”; String[] splitStr = intStr.split(“,”); 但快速的逆向操作则是Java8新增的join方法来提供 String joinStr = String.join(“,”, splitStr); join方法的第一个参数为每个元素前追加的分隔符，第二个参数为可迭代的数据源，例如数组之类的。 最终会返回合并之后的数组。 String.fomat的模板参数大全String.format 作为文本处理工具，为我们提供强大而丰富的字符串格式化功能，为了不止步于简单调用 String.format(“Hello %s”, “John”); ，下面将笔记整理并记录下来。 二、重载方法 // 使用当前本地区域对象（Locale.getDefault()）格式化字符串String String.format(String fmt, Object… args); // 自定义本地区域对象格式化字符串String String.format(Locale locale, String fmt, Object… args); 三、占位符 占位符完整格式为： %[index$][标识]*[最小宽度][.精度]转换符 。 针对不同数据类型的格式化，占位符的格式将有所裁剪。 % ，占位符的其实字符，若要在占位符内部使用%，则需要写成 %% 。 [index$] ，位置索引从1开始计算，用于指定对索引相应的实参进行格式化并替换掉该占位符。 [标识] ，用于增强格式化能力，可同时使用多个 [标识] ，但某些标识是不能同时使用的。 [最小宽度] ，用于设置格式化后的字符串最小长度，若使用 [最小宽度] 而无设置 [标识] ，那么当字符串长度小于最小宽度时，则以左边补空格的方式凑够最小宽度。 [.精度] ，对于浮点数类型格式化使用，设置保留小数点后多少位。 转换符 ，用于指定格式化的样式，和限制对应入参的数据类型。 四、对字符、字符串进行格式化 占位符格式为： %[index$][标识][最小宽度]转换符 示例——将”hello”格式化为” hello” String raw = “hello”;String str = String.format(“%1$7s”, raw);// 简化//String str = String.format(“%7s”, raw);示例——将”hello”格式化为”hello “ String raw = “hello”;String str = String.format(“%1$-7s”, raw);// 简化//String str = String.format(“%-7s”, raw);可用标识： -，在最小宽度内左对齐，右边用空格补上。 可用转换符： s，字符串类型。 c，字符类型，实参必须为char或int、short等可转换为char类型的数据类型，否则抛IllegalFormatConversionException异常。 b，布尔类型，只要实参为非false的布尔类型，均格式化为字符串true，否则为字符串false。 n，平台独立的换行符（与通过 System.getProperty(“line.separator”) 是一样的） 五、对整数进行格式化 占位符格式为： %[index$][标识]*[最小宽度]转换符 示例——将1显示为0001 int num = 1;String str = String.format(“%04d”, num)示例——将-1000显示为(1,000) int num = -1000;String str = String.format(“%(,d”, num)可用标识： -在最小宽度内左对齐,不可以与0标识一起使用。 0若内容长度不足最小宽度，则在左边用0来填充。 #对8进制和16进制，8进制前添加一个0,16进制前添加0x。 +结果总包含一个+或-号。 空格正数前加空格，负数前加-号。 ,只用与十进制，每3位数字间用,分隔。 ()若结果为负数，则用括号括住，且不显示符号。 可用转换符： b，布尔类型，只要实参为非false的布尔类型，均格式化为字符串true，否则为字符串false。d，整数类型（十进制）。x，整数类型（十六进制）。o，整数类型（八进制）n，平台独立的换行符, 也可通过System.getProperty(“line.separator”)获取 六、对浮点数进行格式化 占位符格式为： %[index$][标识]*[最小宽度][.精度]转换符 示例： double num = 123.4567899;System.out.print(String.format(“%f %n”, num)); // 123.456790System.out.print(String.format(“%a %n”, num)); // 0x1.edd3c0bb46929p6System.out.print(String.format(“%g %n”, num)); // 123.457可用标识： -，在最小宽度内左对齐,不可以与0标识一起使用。0，若内容长度不足最小宽度，则在左边用0来填充。#，对8进制和16进制，8进制前添加一个0,16进制前添加0x。+，结果总包含一个+或-号。空格，正数前加空格，负数前加-号。,，只用与十进制，每3位数字间用,分隔。(，若结果为负数，则用括号括住，且不显示符号。 可用转换符： b，布尔类型，只要实参为非false的布尔类型，均格式化为字符串true，否则为字符串false。n，平台独立的换行符, 也可通过System.getProperty(“line.separator”)获取。f，浮点数型（十进制）。显示9位有效数字，且会进行四舍五入。如99.99。a，浮点数型（十六进制）。e，指数类型。如9.38e+5。g，浮点数型（比%f，%a长度短些，显示6位有效数字，且会进行四舍五入） 七、对日期时间进行格式化 占位符格式为： %[index$]t转换符 示例： Date now = new Date();String str = String.format(“%tF”, now); // 2014-10-12可用转换符 日期的转换符 c，星期六 十月 27 14:21:20 CST 2007F，2007-10-27D，10/27/07r，02:25:51 下午T，14:28:16R，14:28b, 月份简称B, 月份全称a, 星期简称A, 星期全称C, 年前两位（不足两位补零）y, 年后两位（不足两位补零）j, 当年的第几天m, 月份（不足两位补零）d, 日期（不足两位补零）e, 日期（不足两位不补零） 时间的转换符 H, 24小时制的小时（不足两位补零）k, 24小时制的小时（不足两位不补零）I, 12小时制的小时（不足两位补零）i, 12小时制的小时（不足两位不补零）M, 分钟（不足两位补零）S, 秒（不足两位补零）L, 毫秒（不足三位补零）N, 毫秒（不足9位补零）p, 小写字母的上午或下午标记，如中文为“下午”，英文为pmz, 相对于GMT的时区偏移量，如+0800Z, 时区缩写，如CSTs, 自1970-1-1 00:00:00起经过的秒数Q, 自1970-1-1 00:00:00起经过的豪秒 八、其他转换符 &lt;，用于格式化前一个转换符所描述的参数。 示例： int num = 1000;String str = String.format(“%d %&lt;,d”, num);// 结果”1000 1,000","path":"2019/01/09/2697897267/","date":"01-09","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Mybatis 中注解式多表关联查询","text":"@Results 对应XML 中的 resultMap@Result 对应XML 中的 resultType@resultMap 只接收@Reults 中ID的参数，来实现@Results的复用 @Reults 有ID和value两个值 ID接收字符串 value接受{} 内包含至少一个@Result 默认值可仅使用value 可省略 @Reults({@Result()}) @Result 可使用对应注解 many=@many() @many() 有两个属性 select 参数为其他mapper方法的完整路径名 和 加载方式参数 one-@one() @Select(“SELECT r.roleDetails,r.roleID,r.roleName FROM role r LEFT JOIN account_role ar ON r.roleID=ar.roleID WHERE ar.Uuid=#{uuid}”)@Results({@Result(property = “roleid”, column = “roleid”), @Result(property = “powerList”, column = “roleID”, many = @Many(select = “com.mapper.PowerMapper.findPower”, fetchType = FetchType.LAZY))}) fetchType = FetchType.LAZY 既使用延迟加载模式，不加该属性默认不使用延迟加载延迟加载有可能会追加多余的字段hander，在配合缓存使用时，会造成序列化异常，故不建议一起使用 作为传递关联查询的参数需要额外填写对应关系，否则映射对象不能获取值 @Results({@Result(property = “映射一对多对象的属性名”, column = “实体列名”), @Result(property = “映射一对多对象的属性名”, column = “实体列名，同时也是传递到级联查询的参数”, many = @Many(select = “级联查询的完整方法名”, fetchType = 加载方式))}) 3.53批量插入使用备注 /** * 通用Mapper接口,特殊方法，批量插入，支持批量插入的数据库都可以使用，例如mysql,h2等 * * @param &lt;T&gt; 不能为空 * @author liuzh */public interface InsertListMapper&lt;T&gt; &#123; /** * 批量插入，支持批量插入的数据库可以使用，例如MySQL,H2等，另外该接口限制实体包含`id`属性并且必须为自增列 * * @param recordList * @return */ @Options(useGeneratedKeys = true, keyProperty = &quot;id&quot;) @InsertProvider(type = SpecialProvider.class, method = &quot;dynamicSQL&quot;) int insertList(List&lt;T&gt; recordList); /** * ======如果主键不是id怎么用？========== * 假设主键的属性名是uid,那么新建一个Mapper接口如下 * &lt;pre&gt; public interface InsertUidListMapper&lt;T&gt; &#123; @Options(useGeneratedKeys = true, keyProperty = &quot;uid&quot;) @InsertProvider(type = SpecialProvider.class, method = &quot;dynamicSQL&quot;) int insertList(List&lt;T&gt; recordList); &#125; * 只要修改keyProperty = &quot;uid&quot;就可以 * * 然后让你自己的Mapper继承InsertUidListMapper&lt;T&gt;即可 * * &lt;/pre&gt; */&#125;/** * 通用Mapper接口,特殊方法，批量插入，支持批量插入的数据库都可以使用，例如mysql,h2等 * * @param &lt;T&gt; 不能为空 * @author liuzh */public interface InsertUseGeneratedKeysMapper&lt;T&gt; &#123; /** * 插入数据，限制为实体包含`id`属性并且必须为自增列，实体配置的主键策略无效 * * @param record * @return */ @Options(useGeneratedKeys = true, keyProperty = &quot;id&quot;) @InsertProvider(type = SpecialProvider.class, method = &quot;dynamicSQL&quot;) int insertUseGeneratedKeys(T record); /** * ======如果主键不是id怎么用？========== * 假设主键的属性名是uid,那么新建一个Mapper接口如下 * &lt;pre&gt; public interface InsertUidMapper&lt;T&gt; &#123; @Options(useGeneratedKeys = true, keyProperty = &quot;id&quot;) @InsertProvider(type = SpecialProvider.class, method = &quot;dynamicSQL&quot;) int insertUseGeneratedKeys(T record); &#125; * 只要修改keyProperty = &quot;uid&quot;就可以 * * 然后让你自己的Mapper继承InsertUidListMapper&lt;T&gt;即可 * * &lt;/pre&gt; */&#125;","path":"2018/12/21/3764698259/","date":"12-21","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"理解函数式编程中的 Side Effects","text":"side effects 在维基百科上直接翻译为 “函数副作用”。 首先要明确“副作用”这个词没有贬义成分，不是“负面作用”，而是“在满足主要功能（主作用？）的同时，顺便完成了一些其他的副要功能”。有个答主说“附作用”表示附加作用，我觉得很好。 从数学的角度来讲，作为一个函数，例如 f(x) = 2x，这个函数，最重要的目的是什么？就是对于传入的x值，找到它所对应的值，在这个例子里就是 2乘以x。从编程的角度来说，传入的x 就是一个函数的参数，而找到的对应的值，就是函数的输出值，很多语言里用 return 这个关键字。所以 y = f(2)，得到了 y = 4，这里y 被赋值了，很开心。函数也完成了它最主要的作用：对每个自变量 x 计算出一个相对应的因变量 y。 从这个角度来说，如果一个函数除了计算最终要返回的结果之外，还做了任何其他事情，都可以成为“副作用”，因为这不是一个函数的首要功能。至于这个“副作用”惊喜不惊喜，意外不意外，与它是不是副作用的定义本身无关。 有些时候，函数的副作用可能会比首要功能更重要。例如有 write() 这个函数，把一些字符写到一个文件里，传回true/false表示是否写成功，甚至不回传。这里明显可以看出，我们叫这个函数，主要还是希望它能把东西写到文件里的。可惜从数学的角度来讲，函数的首要功能永远都是返回值，所以这里“写文件”操作也被定义为“副作用”。 实际编程中，我们不一定需要尽量避免副作用，但是一定要尽量避免“意外的”副作用。比如我们可以通过合适的函数名或注释，提醒调用函数的人，这个函数有副作用。 举个简单例子，假如我们设计一个函数，从一个数组里找出最大的数字，两种写法：第一种，直接遍历数组，找到最大的数字并返回结果，O(n) 代码略。这个函数没有副作用，我们如果给它取名为 findMax() （找最大值）还算妥当。第二种写法，对传入的数组进行从大到小排序，之后返回数组的第一项，O(n log n) 代码略。这个函数会把数组原先的顺序破坏，算是副作用（但不一定是坏事）。不过如果我们依然给函数取名为 findMax() 的话，那别人发现自己的数组顺序被破坏了可能会凌乱。为了提醒大家，比如我们可以给它取名为 sortArrayAndReturnMax() （排序并找最大值） 至少就比 findMax() （找最大值）更清晰些。（举例而已，实际使用中最好还是拆成两个函数吧。）","path":"2018/12/21/3314626403/","date":"12-21","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Return 与 Finally 的执行顺序","text":"return返回的是return指令执行的时刻，操作数栈顶的值，不管expression是一个怎样的表达式，究竟做了些什么工作，对于return指令来说都不重要，他只负责把操作数栈顶的值返回。而return expression是分成两部分执行的:执行：expression；执行：return指令；例如：return x+y；这句代码先执行x+y，再执行return；首先执行将x以及y从局部变量区复制到操作数栈顶的指令，然后执行加法指令，这个时候结果x+y的值会保存在操作数栈的栈顶，最后执行return指令，返回操作数栈顶的值。对于return x；先执行x，x也是一个表达式，这个表达式只有一个操作数，会执行将变量x从局部变量区复制到操作数栈顶的指令，然后执行return，返回操作数栈顶的值。因此return x实际返回的是return指令执行时，x在操作数栈顶的一个快照或者叫副本，而不是x这个值。而当存在finally语句块的时候， 首先我们知道，finally语句是一定会执行，但他们的执行顺序是怎么样的呢？他们的执行顺序如下：1、执行：expression，计算该表达式，结果保存在操作数栈顶；2、执行：操作数栈顶值（expression的结果）复制到局部变量区作为返回值；3、执行：finally语句块中的代码；4、执行：将第2步复制到局部变量区的返回值又复制回操作数栈顶；5、执行：return指令，返回操作数栈顶的值；我们可以看到，在第一步执行完毕后，整个方法的返回值就已经确定了，由于还要执行finally代码块，因此程序会将返回值暂存在局部变量区，腾出操作数栈用来执行finally语句块中代码，等finally执行完毕，再将暂存的返回值又复制回操作数栈顶。所以无论finally语句块中执行了什么操作，都无法影响返回值，所以试图在finally语句块中修改返回值是徒劳的。因此，finally语句块设计出来的目的只是为了让方法执行一些重要的收尾工作，而不是用来计算返回值的。所以在finally中更改返回值是无效的，因为它只是更改了操作数栈顶端复制到局部变量区的快照，并不能真正的更改返回值，但是如果在finally中使用return的话则是会将新的操作数栈的顶端数据返回，而不是之前复制到局部变量区用作返回内容快照的值返回，所以这样是可以返回的，同样的在cathch语句块里也是这样，只有重新出现了return才有可能更改返回值。 try catch finally 中 1、不管有木有出现异常，finally块中代码都会执行；2、当try和catch中有return时，finally仍然会执行；3、finally是在return后面的表达式运算后执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），所以函数返回值是在finally执行前确定的；4、finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值。 任何执行try 或者catch中的return语句之前，都会先执行finally语句，如果finally存在的话。如果finally中有return语句，那么程序就return了，所以finally中的return是一定会被return的，编译器把finally中的return实现为一个warning。","path":"2018/12/21/1183918086/","date":"12-21","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"用多态来编写简洁代码","text":"多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量倒底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。因为在程序运行时才确定具体的类，这样，不用修改源程序代码，就可以让引用变量绑定到各种不同的类实现上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 既：使用父类类型来说明变量，并使用子类实例化。 Java实现多态有三个必要条件：继承、重写、向上转型。 继承：在多态中必须存在有继承关系的子类和父类。 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 向上转型：在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 只有满足了上述三个条件，我们才能够在同一个继承结构中使用统一的逻辑实现代码处理不同的对象，从而达到执行不同的行为。 对于Java而言，它多态的实现机制遵循一个原则： 当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法， 但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法。重载和扩展的方法并不能通过父类引用进行调用。 所以对于引用子类的父类类型，在处理该引用时，它适用于继承该父类的所有子类，子类对象的不同，对方法的实现也就不同，执行相同动作产生的行为也就不同。 也就达成了一种引用类型会有多种状态的形式。 多态中的方法调用优先级： 当超类对象引用变量引用子类对象时，被引用对象的类型而不是引用变量的类型决定了调用谁的成员方法， 但是这个被调用的方法必须是在超类中定义过的，也就是说被子类覆盖的方法，但是它仍然要根据继承链中方法调用的优先级来确认方法，该优先级为： this.show(O)、super.show(O)、this.show((super)O)、super.show((super)O)。 用多态减少 if/else if 和 switch 分支 if/else if 和 switch 之争 先说可读性，switch和if..else if是半斤八两的写法，可读性差不多，switch显得更整齐，if else可以更灵活。 他们的条件分支数量是一样的。如果分支数目过多，都非常不利于写unit test，都会容易藏入bug， 都是有坏味道的代码。尤其在分支多时，不是你把if换成switch就能解决问题的。 虽然 switch 有 性能方面上来讲 if/else if 和 switch 差别不大 （条件分支小于450个，一般没有这么多的分支） 1、很多人确实不知道 switch 和 if else 之间到底有什么区别，仅仅知道，这两种方式都能实现同一个目的罢了。 2、就是很多人知道，但并不在在乎他们之间的区别，优势和特点，我能实现我想要的功能和结果就行。 关于 if else 只是单纯地一个接一个比较；if…elseif可能每个条件都计算一遍； 而 switch 使用了Binary Tree算法；绝大部分情况下switch会快一点，除非是if-else的第一个条件就判断到了。 编译器编译switch与编译if…else…不同。不管有多少case，都直接跳转，不需逐个比较查询；switch只计算一次值，然后都是test , jmp, 有很多else if的时候，用switch case比较清晰！ switch使用查找表的方式决定了case的条件必须是一个连续的常量。而if-else则可以灵活的多。 所以，只有分支比较少的时候，if效率比switch高，因为switch有跳转表。 多态并不能消灭条件分支语句，只能减少其使用。 另外多用异常减少使用返回码，也能减少if 的使用","path":"2018/12/10/517841942/","date":"12-10","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"三范式与反三范式","text":"数据库范式 一、 三范式 主键： 创建表时可以不设置主键 ， 但是没有设置主键的表 ， 底层会认为所有的键都是主键 ，所以在创建时使用了所有的字段创建索引 ， 在查询时索引的存在几乎没有意义 。复合主键： 两个或两个以上的字段作为评价一条数据记录的唯一性标志 。第一范式：强调列的原子性 ， 即：列不能分成几列只要是关系型数据库 ， 就自然的遵循第一范式第二范式：首先满足第一范式必须有主键没有包含在主键中的列必须完全依赖于主键， 而不能只依赖主键的一部分第三范式：首先满足第一范式也属于第二范式的一种情况任何非主键字段不能依赖于其他非主键字段三范式是在数据库初期使用（时间换取空间） ， 能外键关联就外键关联 ， 能不冗余数据设计 ， 就不冗余。但是现在的系统对性能要求高， 对存储要求低（空间换时间）二、 反范式 但是现在的系统对性能要求高， 对存储要求低（空间换时间） ， 所以出现了一套反范式反范式： 只要违反了第二范式和第三范式 ， 就能做到空间换时间 ， 获的最大的效率 。 数据库设计时要满足规范化这个道理大家都非常清楚，甚至有数据库的三范式, 好吧, 这有点让我想起了机器人的三定律.但是否数据的规范化程度越高越好呢？这还是由实际需求来决定。 因为规范化越高，那么产生的关系就越多，关系过多的直接结果就是导致表之间的连接操作越频繁，而表之间的连接操作是性能较低的操作，直接影响到査询的速度，所以，对于査询较多的应用，就需要根据实际情况运用逆规范化对数据进行设计，通过逆规范化来提高査询的性能。 例如，移动电话的用户每月都会査询自己的账单，账单信息一般包含用户的名字和本月消费总金额，设想一下，如果用户的姓名和属性信息存放在一个表中，假设表名为A,而用户的 编号和他对应的账单信息存放在另外一张B表中，那么，用户每次查询自己的月账单时，数据库査询时都要进行表连接，因为账单表B中并不包含用户的名字，所以必须通过关联A表取 过来，如果在数据库设计时考虑到这一点，就可以在B表增加一个冗余字段存放用户的名字， 这样在査询账单时就不用再做表关联，可以使査询有更好的性能。 反规范的好处是降低连接操作的需求、降低外码和索引的数目，还可能减少表的数目，相 应带来的问题是可能出现数据的完整性问题。加快查询速度，但会降低修改速度。因此，决定 做反规范时，一定要权衡利弊，仔细分析应用的数据存取需求和实际的性能特点，好的索引和 其他方法经常能够解决性能问题，而不必采用反规范这种方法。 在进行反规范操作之前，要充分考虑数据的存取需求、常用表的大小、一些特殊的计算（例 如合计）、数据的物理存储位置等。常用的反规范技术有增加冗余列、增加派生列、重新组表 和分割表。 增加冗余列：指在多个表中具有相同的列，它常用来在查询时避免连接操作。增加派生列：指增加的列来自其他表中的数据，由其他表中的数据经过计算生成。增 加的派生列其作用是在查询时减少连接操作，避免使用集函数。重新组表：指如果许多用户需要查看两个表连接出来的结果数据，则把这两个表重新 组成一个表来减少连接而提高性能.另外，逆规范技术需要维护数据的完整性。无论使用何种反规范技术，都需要一定的管理 来维护数据的完整性，常用的方法是批处理维护、应用逻辑和触发器。 批处理维护是指对复制列或派生列的修改积累一定的时间后，运行一批处理作业或存 储过程对复制或派生列进行修改，这只能在对实时性要求不高的情况下使用. 数据的完整性也可由应用逻辑来实现，这就要求必须在同一事务中对所有涉及的表进 行增、删、改操作.用应用逻辑来实现数据的完整性风险较大，因为同一逻辑必须在所有的应 用中使用和维护，容易遗漏，特别是在需求变化时，不易于维护。 另一种方式就是使用触发器，对数据的任何修改立即触发对复制列或派生列的相应修 改，触发器是实时的，而且相应的处理逻辑只在一个地方出现，易于维护•一般来说，是解决 这类问题比较好的办法。","path":"2018/12/07/1579038364/","date":"12-07","excerpt":"","tags":[{"name":"SQL","slug":"SQL","permalink":"https://yihuishou.github.io/tags/SQL/"}]},{"title":"Vuter 插件的简单配置","text":"Vuter插件是VsCode中的Vue代码格式化和代码提示辅助插件 该插件需要依赖Prettier才能对Vue文件进行自定义格式化 如果未安装Prettier插件则会调用VsCode的内置Javascript插件对Vue文件进行格式化 下面记述了一些Vuter和Prettier插件的配置： 语句末尾不使用分号“prettier.semi”: false使用单引号代替双引号“prettier.singleQuote”: true函数的括号前添加空格“javascript.format.insertSpaceBeforeFunctionParenthesis”: true使用beautify格式化Vue文件中的Template部分代码“vetur.format.defaultFormatter.html”: “js-beautify-html”beautify格式化Vue文件配置“vetur.format.defaultFormatterOptions”: { “js-beautify-html”: { // 属性强制折行对齐 // “wrap_attributes”: “force-aligned”, // 属性单行 “wrap_attributes”: “auto”, // 属性强制折多行对齐 // “wrap_attributes”: “force-expand-multiline”, }} ESlinet保存时自动修正错误“eslint.autoFixOnSave”: true,ESlinet添加 vue 支持“eslint.validate”: [ “javascript”, “javascriptreact”, { “language”: “vue”, “autoFix”: true }]","path":"2018/11/26/1836404574/","date":"11-26","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"Vue-hooks 简单使用","text":"Vue风格的使用方法 数据类： useData useComputed useWatch 生命周期类： useUpdated useMounted useDestroyed 使用前提： 获取实例 挂载hooks 使用hooks函数 返回页面数据对象 只可在顶级代码块中调用 Hooks，而不能在循环、条件或嵌套函数中使用 useData(初始化数据) useComputed(函数) useWatch(观测数据函数,操作数据函数) 生命周期类： useUpdated(函数) useMounted(函数) useDestroyed(函数) 示例： &lt;template&gt; &lt;div @click=&quot;data.count++&quot;&gt; &#123;&#123; data.count &#125;&#125; &#123;&#123; double &#125;&#125; &lt;/div&gt;&lt;/template&gt;import &#123; hooks &#125; from &quot;vue-hooks&quot;;import Vue from &quot;vue&quot;;Vue.use(hooks);export default &#123; hooks() &#123; const data = useData(&#123; count: 0 &#125;) const double = useComputed(() =&gt; data.count * 2) return &#123; data, double &#125; &#125;&#125; 改变数据即可触发逻辑 &lt;template&gt; &lt;div @click=&quot;changdata&quot;&gt; &#123;&#123; data.count &#125;&#125; &#123;&#123; double &#125;&#125; &lt;/div&gt;&lt;/template&gt;import &#123; hooks &#125; from &quot;vue-hooks&quot;;import Vue from &quot;vue&quot;;imoprt &#123; myhooks &#125; from &quot;../myhooks&quot;;Vue.use(hooks);export default &#123; hooks() &#123; const data = useData(&#123; count: 0 &#125;) const double = useComputed(() =&gt; data.count * 2) return &#123; data, double &#125; &#125;, methods:&#123; changdata()&#123; this.data.count++ &#125; &#125;&#125;``` 抽取自定义hooks函数，实现逻辑复用，其中`myhooks`导出了自定义的数据逻辑，在组件中可以使用相关Hooks 在组件中多次使用相同的Hooks逻辑，其中的数据是相互隔离的。自定义Hooks示例： import { useComputed, useData, useUpdated} from “vue-hooks” export default function () { const data = useData({ money: 223 }) const result = useComputed(() =&gt; { return data.money * 2 }) useUpdated(() =&gt; { console.log(&apos;updated!&apos;) }) return { data, result, }}","path":"2018/11/22/2133883235/","date":"11-22","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"简明 ES6/7","text":"let/count在ES6之前，我们都是用var关键字声明变量。无论声明在何处，都会被视为声明在函数的最顶部(不在函数内即在全局作用域的最顶部)。这就是函数变量提升例如: function aa() &#123; if(flag) &#123; var test = &apos;hello man&apos; &#125; else &#123; console.log(test) &#125;&#125; 以上的代码实际上是： function aa() &#123; var test // 变量提升，函数最顶部 if(flag) &#123; test = &apos;hello man&apos; &#125; else &#123; //此处访问 test 值为 undefined console.log(test) &#125; //此处访问 test 值为 undefined &#125; 我们通常用 let 和 const 来声明，let 表示变量、const 表示常量。let 和 const 都是块级作用域。 只要在{}花括号内的代码块即可以认为 let 和 const 的作用域 let 的作用域是在它所在当前代码块，但不会被提升到当前函数的最顶部。 再来说说 constconst 声明的变量必须提供一个值，而且会被认为是常量，意思就是它的值被设置完成后就不能再修改了。 还有，如果 const 的是一个对象，对象所包含的值是可以被修改的。抽象一点儿说，就是对象所指向的地址不能改变，而变量成员是可以修改的。 解构赋值解构（Destructuring）：是将一个数据结构分解为更小的部分的过程。ES6中，从数组和对象中提取值，对变量进行赋值。 两种简写 {name:name,age=age} = {name,age} {open:function(){ console.log(“kl”) }} = {open(){ console.log(“kl”) }} let {对象属性名} = {对象属性名:对象属性} let 对象属性名 = 对象属性 const people = &#123; name: &apos;lux&apos;, age: 20&#125;const name = people.nameconst age = people.ageconsole.log(name + &apos; --- &apos; + age) const people = &#123; name: &apos;lux&apos;, age: 20&#125;const &#123; name, age &#125; = people 虽然通过解构可以无需声明来赋值一个变量。 但最好还是使用声明解构 var people = [ &#123; name: &quot;Mike Smith&quot;, family: &#123; mother: &quot;Jane Smith&quot;, father: &quot;Harry Smith&quot;, sister: &quot;Samantha Smith&quot; &#125;, age: 35 &#125;, &#123; name: &quot;Tom Jones&quot;, family: &#123; mother: &quot;Norah Jones&quot;, father: &quot;Richard Jones&quot;, brother: &quot;Howard Jones&quot; &#125;, age: 25 &#125;];for (var &#123;name: n, family: &#123; father: f &#125; &#125; of people) &#123; console.log(&quot;Name: &quot; + n + &quot;, Father: &quot; + f);&#125;// &quot;Name: Mike Smith, Father: Harry Smith&quot;// &quot;Name: Tom Jones, Father: Richard Jones&quot; import/exportas 为命名空间别名 可以导出let var function class const // 导出默认, 有且只有一个默认export default App =2export default function open()&#123; console.log(alphabets) &#125;// 部分导出export let a = 2;export function open()&#123; console.log(alphabets) &#125;let opens = function ()&#123; console.log(alphabets) &#125;let s = 3export &#123;opens,s&#125;//全部导入import people from &apos;./example&apos;//有一种特殊情况，即允许你将整个模块当作单一对象进行导入//该模块的所有导出都会作为对象的属性存在import * as example from &quot;./example.js&quot;console.log(example.name)console.log(example.age)console.log(example.getName())//导入部分import &#123;name, age&#125; from &apos;./example&apos; 1.当用export default people导出时，就用 import people 导入（不带大括号） 2.一个文件里，有且只能有一个export default。但可以有多个export。 3.当用export name 时，就用import { name }导入（记得带上大括号） 4.当一个文件里，既有一个export default people, 又有多个export name 或者 export age时，导入就用 import people, { name, age } 5.当一个文件里出现n多个 export 导出很多模块，导入时除了一个一个导入，也可以用import * as example 扩展运算符... //数组 const color = [&apos;red&apos;, &apos;yellow&apos;] const colorful = [...color, &apos;green&apos;, &apos;pink&apos;] console.log(colorful) //[red, yellow, green, pink] //对象 const alp = &#123; fist: &apos;a&apos;, second: &apos;b&apos;&#125; const alphabets = &#123; ...alp, third: &apos;c&apos; &#125; console.log(alphabets) //&#123; &quot;fist&quot;: &quot;a&quot;, &quot;second&quot;: &quot;b&quot;, &quot;third&quot;: &quot;c&quot;&#125; const first = &#123; a: 1, b: 2, c: 6, &#125; const second = &#123; c: 3, d: 4 &#125; const total = &#123; ...first, ...second &#125; console.log(total) // &#123; a: 1, b: 2, c: 3, d: 4 &#125; 解构赋值中的剩余模式 当解构一个数组时，可以使用剩余模式，将数组剩余部分赋值给一个变量。 var [a, ...b] = [1, 2, 3];console.log(a); // 1console.log(b); // [2, 3] 剩余元素必须是数组的最后一个元素。…只能在数组最后一个变量 默认值参数默认值 function action(num = 200) &#123; console.log(num) &#125; action(0) // 0 action() //200 action(300) //300 数组对象默认值 let oldArry =[1,2,3,4]let [a,b.c=2] = oldArry let ary = &#123; name: &quot;阿里&quot;, age: 18, money: 0 &#125;; let &#123; name ,age=12312,mo=4&#125; = ary; lambdaES6很有意思的一部分就是函数的快捷写法。也就是箭头函数。 箭头函数最直观的三个特点。 不需要 function 关键字来创建函数省略 return 关键字继承当前上下文的 this 关键字 ()=&gt; dosomething()data =&gt; data++(a,b) =&gt; a+bdata =&gt;&#123;dosomething()return data++ &#125; Promise在promise之前代码过多的回调或者嵌套，可读性差、耦合度高、扩展性低。通过Promise机制，扁平化的代码机构，大大提高了代码可读性；用同步编程的方式来编写异步代码，保存线性的代码逻辑，极大的降低了代码耦合性而提高了程序的可扩展性。 setTimeout(function() &#123; console.log(1) &#125;, 0); new Promise(function executor(resolve) &#123; console.log(2); for( var i=0 ; i&lt;10000 ; i++ ) &#123; i == 9999 &amp;&amp; resolve(); &#125; console.log(3); &#125;).then(function() &#123; console.log(4); &#125;); console.log(5); 模板字符串基本的字符串格式化。将表达式嵌入字符串中进行拼接。用${}来界定。 //ES5 var name = &apos;lux&apos;console.log(&apos;hello&apos; + name)//es6const name = &apos;lux&apos;console.log(`hello $&#123;name&#125;`) //hello lux async/awaitasync function 声明用于定义一个返回 AsyncFunction 对象的异步函数。异步函数是指通过事件循环异步执行的函数，它会通过一个隐式的 Promise 返回其结果。但是如果你的代码使用了异步函数，它的语法和结构会更像是标准的同步函数。 当调用一个 async 函数时，会返回一个 Promise 对象。当这个 async 函数返回一个值时，Promise 的 resolve 方法会负责传递这个值；当 async 函数抛出异常时，Promise 的 reject 方法也会传递这个异常值。 async 函数中可能会有 await 表达式，这会使 async 函数暂停执行，等待 Promise 的结果出来，然后恢复async函数的执行并返回解析值（resolved）。 注意， await 关键字仅仅在 async function中有效。如果在 async function函数体外使用 await ，你只会得到一个语法错误（SyntaxError）。function resolveAfter2Seconds() &#123; return new Promise(resolve =&gt; &#123; setTimeout(() =&gt; &#123; resolve(&apos;resolved&apos;); &#125;, 2000); &#125;);&#125;async function asyncCall() &#123; console.log(&apos;calling&apos;); var result = await resolveAfter2Seconds(); console.log(result); // expected output: &apos;resolved&apos;&#125;asyncCall();","path":"2018/11/22/2885027022/","date":"11-22","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"Vue 中的 this","text":"this普通函数的 this 普通函数的 this 是由动态作用域决定，它总指向于它的直接调用者。具体可以分为以下四项： this 总是指向它的直接调用者， 例如 obj.func() ,那么 func()里的 this 指的是 obj。 在默认情况(非严格模式,未使用 ‘use strict’)，如果函数没有直接调用者，this 为 window 在严格模式下,如果函数没有直接调者，this 为 undefined 使用 call,apply,bind 绑定的，this 指的是绑定的对象 箭头函数的 this箭头函数是没有绑定自己的 this，函数内使用的 this 是由静态作用域（也成为词法作用域，参考 this）决定。静态作用域就是说箭头函数里 this 是由定义它的代码决定，而不是执行调用箭头函数的代码。 上面的说法有时很难理解，我自己总结的方法是：找出定义箭头函数的上下文（即包含箭头函数最近的函数或者对象）那么上下文所处的父上下文（上一级上下文）即为 this 的指向。 Vue 中的 this虽然在绝大多数的 Vue 方法中，this 都指向 Vue 实例 在 Vue 所有的生命周期钩子方法（如 created，mounted， updated 以及 destroyed）里使用 this，this 指向调用它的 Vue 实例，且不应该使用箭头函数。 但是也有部分例外： data 中的箭头函数不会指向组件实例,this 指向 Vue 实例 computed 中的箭头函数不会指向组件实例,this 指向 Vue 实例 methods 中的箭头函数不会指向组件实例且不应该使用箭头函数来定义 method 函数,this 指向 Vue 实例 watch 中的 this 指向 windows不应该使用箭头函数来定义 watch 函数","path":"2018/11/20/1481638674/","date":"11-20","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"JavaScript 中的各种简写","text":"1.三元操作符当想写if…else语句时，使用三元操作符来代替。 const x = 20;let answer;if (x &gt; 10) &#123; answer = &apos;is greater&apos;;&#125; else &#123; answer = &apos;is lesser&apos;;&#125; 简写： const answer = x &gt; 10 ? &apos;is greater&apos; : &apos;is lesser&apos;; 也可以嵌套if语句： const big = x &gt; 10 ? &quot; greater 10&quot; : x 2.短路求值简写方式当给一个变量分配另一个值时，想确定源始值不是null，undefined或空值。可以写撰写一个多重条件的if语句。 if (variable1 !== null || variable1 !== undefined || variable1 !== &apos;&apos;) &#123; let variable2 = variable1;&#125; 或者可以使用短路求值方法： const variable2 = variable1 || &apos;new&apos;; 3.声明变量简写方法 let x;let y;let z = 3; 简写方法： let x, y, z=3; 4.if存在条件简写方法 if (likeJavaScript === true) 简写： if (likeJavaScript) 只有likeJavaScript是真值时，二者语句才相等 如果判断值不是真值，则可以这样： let a;if ( a !== true ) &#123;// do something...&#125; 简写： let a;if ( !a ) &#123;// do something...&#125; 5.JavaScript循环简写方法 for (let i = 0; i &lt; allImgs.length; i++) 简写： for (let index in allImgs) 也可以使用Array.forEach： function logArrayElements(element, index, array) &#123; console.log(&quot;a[&quot; + index + &quot;] = &quot; + element);&#125;[2, 5, 9].forEach(logArrayElements);// logs:// a[0] = 2// a[1] = 5// a[2] = 9 6.短路评价给一个变量分配的值是通过判断其值是否为null或undefined，则可以： let dbHost;if (process.env.DB_HOST) &#123; dbHost = process.env.DB_HOST;&#125; else &#123; dbHost = &apos;localhost&apos;;&#125; 简写： const dbHost = process.env.DB_HOST || &apos;localhost&apos;; 7.十进制指数当需要写数字带有很多零时（如10000000），可以采用指数（1e7）来代替这个数字： for (let i = 0; i &lt; 10000; i++) &#123;&#125; 简写： for (let i = 0; i &lt; 1e7; i++) &#123;&#125;// 下面都是返回true1e0 === 1;1e1 === 10;1e2 === 100;1e3 === 1000;1e4 === 10000;1e5 === 100000; 8.对象属性简写如果属性名与key名相同，则可以采用ES6的方法： const obj = &#123; x:x, y:y &#125;; 简写： const obj = &#123; x, y &#125;; 9.箭头函数简写传统函数编写方法很容易让人理解和编写，但是当嵌套在另一个函数中，则这些优势就荡然无存。 function sayHello(name) &#123; console.log(&apos;Hello&apos;, name);&#125;setTimeout(function() &#123; console.log(&apos;Loaded&apos;)&#125;, 2000);list.forEach(function(item) &#123; console.log(item);&#125;); 简写： sayHello = name =&gt; console.log(&apos;Hello&apos;, name);setTimeout(() =&gt; console.log(&apos;Loaded&apos;), 2000);list.forEach(item =&gt; console.log(item)); 10.隐式返回值简写经常使用return语句来返回函数最终结果，一个单独语句的箭头函数能隐式返回其值（函数必须省略{}为了省略return关键字） 为返回多行语句（例如对象字面表达式），则需要使用()包围函数体。 function calcCircumference(diameter) &#123; return Math.PI * diameter&#125;var func = function func() &#123; return &#123; foo: 1 &#125;;&#125;; 简写： calcCircumference = diameter =&gt; ( Math.PI * diameter;)var func = () =&gt; (&#123; foo: 1 &#125;); 11.默认参数值为了给函数中参数传递默认值，通常使用if语句来编写，但是使用ES6定义默认值，则会很简洁： function volume(l, w, h) &#123; if (w === undefined) w = 3; if (h === undefined) h = 4; return l * w * h;&#125; 简写： volume = (l, w = 3, h = 4 ) =&gt; (l * w * h);volume(2) //output: 24 12.模板字符串传统的JavaScript语言，输出模板通常是这样写的。 const welcome = &apos;You have logged in as &apos; + first + &apos; &apos; + last + &apos;.&apos;const db = &apos;http://&apos; + host + &apos;:&apos; + port + &apos;/&apos; + database; ES6可以使用反引号和${}简写： const welcome = `You have logged in as $&#123;first&#125; $&#123;last&#125;`;const db = `http://$&#123;host&#125;:$&#123;port&#125;/$&#123;database&#125;`; 13.解构赋值简写方法在web框架中，经常需要从组件和API之间来回传递数组或对象字面形式的数据，然后需要解构它 const observable = require(&apos;mobx/observable&apos;);const action = require(&apos;mobx/action&apos;);const runInAction = require(&apos;mobx/runInAction&apos;);const store = this.props.store;const form = this.props.form;const loading = this.props.loading;const errors = this.props.errors;const entity = this.props.entity; 简写： import &#123; observable, action, runInAction &#125; from &apos;mobx&apos;;const &#123; store, form, loading, errors, entity &#125; = this.props; 也可以分配变量名： const &#123; store, form, loading, errors, entity:contact &#125; = this.props; //最后一个变量名为contact14.多行字符串简写需要输出多行字符串，需要使用+来拼接： const lorem = &apos;Lorem ipsum dolor sit amet, consectetur\\n\\t&apos; + &apos;adipisicing elit, sed do eiusmod tempor incididunt\\n\\t&apos; + &apos;ut labore et dolore magna aliqua. Ut enim ad minim\\n\\t&apos; + &apos;veniam, quis nostrud exercitation ullamco laboris\\n\\t&apos; + &apos;nisi ut aliquip ex ea commodo consequat. Duis aute\\n\\t&apos; + &apos;irure dolor in reprehenderit in voluptate velit esse.\\n\\t&apos; 使用反引号，则可以达到简写作用： const lorem = `Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse.` 15.扩展运算符简写扩展运算符有几种用例让JavaScript代码更加有效使用，可以用来代替某个数组函数。 // joining arraysconst odd = [1, 3, 5];const nums = [2 ,4 , 6].concat(odd);// cloning arraysconst arr = [1, 2, 3, 4];const arr2 = arr.slice(); 简写： // joining arraysconst odd = [1, 3, 5 ];const nums = [2 ,4 , 6, ...odd];console.log(nums); // [ 2, 4, 6, 1, 3, 5 ]// cloning arraysconst arr = [1, 2, 3, 4];const arr2 = [...arr]; 不像concat()函数，可以使用扩展运算符来在一个数组中任意处插入另一个数组。 const odd = [1, 3, 5 ];const nums = [2, ...odd, 4 , 6]; 也可以使用扩展运算符解构： const &#123; a, b, ...z &#125; = &#123; a: 1, b: 2, c: 3, d: 4 &#125;;console.log(a) // 1console.log(b) // 2console.log(z) // &#123; c: 3, d: 4 &#125; 16.强制参数简写JavaScript中如果没有向函数参数传递值，则参数为undefined。为了增强参数赋值，可以使用if语句来抛出异常，或使用强制参数简写方法。 function foo(bar) &#123; if(bar === undefined) &#123; throw new Error(&apos;Missing parameter!&apos;); &#125; return bar;&#125; 简写： mandatory = () =&gt; &#123; throw new Error(&apos;Missing parameter!&apos;);&#125;foo = (bar = mandatory()) =&gt; &#123; return bar;&#125; 17.Array.find简写想从数组中查找某个值，则需要循环。在ES6中，find()函数能实现同样效果。 const pets = [ &#123; type: &apos;Dog&apos;, name: &apos;Max&apos;&#125;, &#123; type: &apos;Cat&apos;, name: &apos;Karl&apos;&#125;, &#123; type: &apos;Dog&apos;, name: &apos;Tommy&apos;&#125;,]function findDog(name) &#123; for(let i = 0; i&lt;pets.length; ++i) &#123; if(pets[i].type === &apos;Dog&apos; &amp;&amp; pets[i].name === name) &#123; return pets[i]; &#125; &#125;&#125; 简写： pet = pets.find(pet =&gt; pet.type ===&apos;Dog&apos; &amp;&amp; pet.name === &apos;Tommy&apos;);console.log(pet); // &#123; type: &apos;Dog&apos;, name: &apos;Tommy&apos; &#125; Object[key]简写考虑一个验证函数 function validate(values) &#123; if(!values.first) return false; if(!values.last) return false; return true;&#125;console.log(validate(&#123;first:&apos;Bruce&apos;,last:&apos;Wayne&apos;&#125;)); // true 假设当需要不同域和规则来验证，能否编写一个通用函数在运行时确认？ // 对象验证规则const schema = &#123; first: &#123; required:true &#125;, last: &#123; required:true &#125;&#125;// 通用验证函数const validate = (schema, values) =&gt; &#123; for(field in schema) &#123; if(schema[field].required) &#123; if(!values[field]) &#123; return false; &#125; &#125; &#125; return true;&#125;console.log(validate(schema, &#123;first:&apos;Bruce&apos;&#125;)); // falseconsole.log(validate(schema, &#123;first:&apos;Bruce&apos;,last:&apos;Wayne&apos;&#125;)); // true 现在可以有适用于各种情况的验证函数，不需要为了每个而编写自定义验证函数了 19.双重非位运算简写有一个有效用例用于双重非运算操作符。可以用来代替Math.floor()，其优势在于运行更快，可以阅读此文章了解更多位运算。 Math.floor(4.9) === 4 //true 简写： ~~4.9 === 4 //true","path":"2018/11/20/4151092854/","date":"11-20","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"不那么安全的 Raid5","text":"Raid5也不是那么可靠很多人遇到过服务器RAID5挂掉，往往掉一个盘后，第二个盘也立刻挂掉。大家都知道RAID5 一次允许一个盘缺失，RAID 5也是以数据的校验位来保证数据的安全，但它不是以单独硬盘来存放数据的校验位，而是将数据段的校验位交互存放于各个硬盘上。这样，任何一个硬盘损坏，都可以根据其它硬盘上的校验位来重建损坏的数据。硬盘的利用率为n-1。如果挂掉两个盘，数据就玩完了。 理论上两个硬盘同时失效的概率是很低的，但为什么会这样呢？ 从数学角度说，每个磁盘的平均无故障时间 (MTBF) 大约为 50 万至 150 万小时(也就是每 50～150 年发生一次硬盘损坏)。实际往往不能达到这种理想的情况，在大多数散热和机械条件下，都会造成硬盘正常工作的时间大幅减少。考虑到每个磁盘的寿命不同，阵列中的任何磁盘都可能出现问题，从统计学角度说，阵列中 N 个磁盘发生故障的机率比单个磁盘发生故障的机率要大 N 倍。结合上述因素，如果阵列中的磁盘数量合理，且这些磁盘的平均无故障时间 (MTBF) 较短，那么在磁盘阵列的预期使用寿命过程中，就很有可能发生磁盘故障(比方说每几个月或每隔几年就会发生一次故障)。 两块磁盘同时损坏的几率有多大呢(“同时”就是指一块磁盘尚未完全修复时另一块磁盘也坏掉了)? 如果说 RAID 5 阵列的MTBF相当于MTBF^2，那么这种几率为每隔10^15个小时发生一次(也就是1万多年才出现一次)，因此不管工作条件如何，发生这种情况的概率是极低的。从数学理论角度来说，是有这种概率，但在现实情况中我们并不用考虑这一问题。不过有时却是会发生两块磁盘同时损坏的情况，我们不能完全忽略这种可能性，实际两块磁盘同时损坏的原因与MTBF基本没有任何关系。 对这种情况来说，这里首先要引入一个一般人不常接触到的概念：BER 硬盘误码率,英文是BER(Bit Error Rate),是描述硬盘性能的一个非常重要的参数,是衡量硬盘出错可能性的一个参数。这个参数代表你写入硬盘的数据，在读取时遇到不可修复的读错误的概率。(不能恢复的ECC读取错误)从统计角度来说也比较少见，一般来说是指读取多少位后会出现一次读取错误。随着硬盘容量增加，驱动器读取数据的误读率就会增加，而硬盘容量暴涨，误码率的比例一直保持相对增加。一个1TB的驱动器是需要更多读取整个驱动器，这是在RAID重建期间发生错误的概率会比300G 驱动器遇到错误的几率更大。那这个错误的几率到底有多大呢？或者说，我们写入多少GB数据，才会遇到1byte的读取错误呢？对于不同类型的硬盘（以前企业级、服务器、数据中心级硬盘用SCSI/光纤，曾经商用、民用级别是IDE；现在对应的则是SAS/SATA；他们的MRBF（平均无故障时间）是接近的，但是BER便宜的SATA硬盘要比昂贵的SCSI硬盘的误码率（BER）要高得多。也就是说，出现某个sector无法读取的情况，SATA要比SCSI严重得多。这两种硬盘（企业级的SCSI/ FC/ SAS 磁盘）/（商用/民用级的IDE/SATA）BER的差距大概是1-2个数量级。按照文中的计算，一个1TB的硬盘，通常你无法读取所有sector的概率达到了56%，因此你用便宜的大容量SATA盘，在出现硬盘故障的情况下重建RAID的希望是：无法实现。我们回到RAID5的情况来。在RAID5大行其道之初，硬盘的容量基本不超过100GB。在过去，做RAID5一般RAID的磁盘容量都不大，比如72GB。无法恢复一个RAID的概率按照文献是1.1%（注意，1.1%已经很不错了，因为你在硬盘故障之后，才需要去恢复RAID。两个概率是要相乘的。当硬盘容量上升到200GB，假设出现故障的概率是线性增长的。那么失败率有11%，估计负责存储的人就被老板操的厉害了。但是当你用1TB的SATA硬盘做RAID5的话，无法恢复一个RAID的概率将会是56%，当你遇到一个硬盘失效的情况，几乎剩下的两个以上硬盘（RAID5最少组合是3个）铁定会遇到一个硬盘读取错误，从而重建失败。所以，以前小硬盘做RAID5，基本很少遇到同时挂掉两个盘的情况；现在硬盘大了，出问题的概率也越来越大了。有人会问：56%？文章里面这个数据还是显得有些“不可信”。大概是因为下面两个原因，我们才没有怎么听说过这么高的BER吧。首先，我们自己用的硬盘都不会跑RAID。虽然现在我们自己的硬盘容量也变得很大（现在主流台式机SATA硬盘应该就是500G），但是这个量级的硬盘上，你往往不会把500G硬盘全部写满；而大多数数据你都很少去读取它。因此从概率上讲，坏道出现在那些没卵味的电影和音乐上的可能性大很多：大多数电影和音乐都没卵味。但是对于跑RAID的用户，对整个硬盘进行读取的事情经常发生。即使系统足够和谐，知道不对你报告那些出现在你从不读取的文件中的坏道，但是也只是略过了报告这一步：它还是会找到所有的坏道，56%就来了。其次，虽然你丢了一些sector，一般情况下也没啥关系。还是以电影和音乐为例，大多数的压缩算法都从设计上允许有一些这样或者那样的误码。丢了几个sector的数据，也许对你来说就是松岛枫身上一些无名的马赛克而已，你都不知道是硬盘作祟。现在还有所谓的监控专用企业级SATA，其原理就是在固件上做手脚，让硬盘即使遇到写入的数据读取错误，也不管三七二十一直接跳过，不再重试读取（标准硬盘的读取方式是遇到某个扇区CRC错误自动重新再去读，直到读到正确的数据为止）。这对监控数据来说是理所当然的（大多数监控的硬盘都是在不停地写入，但是很少需要读取），除非遇到出现问题需要重现影像时。遇到这种情况概率是很低的，我手头的数十个十六路硬盘摄像机，镜头也过百个，基本上几个月才需要用到回放一次，而即使需要回放，也只需要其中的很小一部分数据（比如某几个摄像头，某一天中一个小时的录像）。但是拿这种硬盘来做RAID5就更糟糕了，当RAID5重建需要数据百分百正确时，你压根不可能读到正确的数据。我们继续来看今天的测试数据：我用FreeBSD 的RAIDZ软阵列创建了一个6X1TB硬盘的RAID5。当然，我没有硬盘损坏，这六个硬盘都是好的；但是我们不管这个，这里用RAIDZ的原因是RAIDZ有数据巡检（scrub）功能，然后又能直观地看到数据巡检的结果。一般的硬件阵列卡，也就是插在主板PCI/PCIX/PCIE/或者主板集成的RAID5，压根就没这项功能；企业级的数据存储，也只有到盘阵级别（比如IBM DS3000/4000/5000，DELL MD3000….etc）才有这类功能，但是你也看不到检查的结果，最多能在日志里看到某个硬盘CRC失败，然后跳红灯掉出来，阵列柜告警通知你换硬盘。你别想知道这个硬盘到底是彻底挂了呢，还是有读取错误，还是有坏道。。。总之两眼一抹黑。ZFS的好处之一就在这里了：你在命令行打个 zpool scrub tank （tank就是你创建的raid的名字），它就开工忠实地开始巡检整个阵列了，读取上面的每个字节数据，并与当初写入时的md5值进行比较，发现错误的话就报告，并尝试用冗余数据修复。这个过程是后台进行的，并且用户可以直观地看到巡检的进度、速度/所需时间以及结果。 我们也能总结遇到RAID5一次挂掉俩盘的概率： 使用越大容量的硬盘做RAID5，遇到BER 扇区的概率越大；比如用100G硬盘做RAID5就比用1TB的安全； 使用越多盘数的硬盘做RAID5，遇到BER 扇区的概率越大；比如用3个盘做的RAID5，比6个盘做的RAID5安全； 使用越便宜的硬盘做RAID5，遇到BER 扇区的概率越大；比如用SCSI/FC/SAS盘比用IDE/SATA的RAID5安全； RAID5里面存放的数据越多，塞得越满，遇到BER 扇区的概率越大；比如存了100G数据的比存了1TB数据的RAID5安全； 我是下载狂，一定要要放很多数据，数据量以TB计，即将突破三位数；又是穷人，花不起很多钱，只能用最便宜的SATA盘，最好是最便宜又大碗的西数绿盘；技术有差距啊，折腾不起ZFS；胆子又小，担惊受怕不起，看完这篇文章，想到自己RAID里的数据随时会全部莫有，晚上睡觉都睡不着，伤不起啊肿摸办？ 解决方案1. 对于不重要的大量数据，比如可以下载来的影音数据，不要做阵列。直接用单盘，每个盘放一批数据。数据量大到一定程度，目前来说凡是总量在2TB以上的SATA阵列，如果你做了RAID5，不仅数据没保障，万一坏掉一个盘，你有50%以上的概率同时掉第二个盘，那是一定毛都不剩一根。运气好的话，可以通过让第二个挂掉的硬盘强行上线的方式勉强恢复阵列运行，你也必须有同等容量的空间让你腾挪数据；不要说这个数据量的备用空间一般不会有，就算有，来回折腾一次所需要耗费的时间足够让你一个礼拜没个安耽觉睡。有人说不会啊，我这个RAID5读取有300MB/s呢，2TB数据只要两个小时。那是你平时——RAID5缺盘运行时，性能大概只有平时的1/10-1/20，外加上肯定有读不过去的文件需要跳过。。。。再加上读不过去会掉盘，又要重启重新强制上线——这样的事件还不止一次，按照前面的测试，6个1T盘一共遇到24个读取错误，也就是你备份的进度得熄火24次——这些事儿堆一块儿，如果不是一个心理素质非常好的，处理过N起类似事件经验的数据中心老油子，对于第一次遇到这种情况的新手绝对是噩梦般的经历。 解决方案2. 做RAID1阵列。对于重要的、并且经常变动更新数据，比如财务数据、照片、文档资料，建议用RAID1。RAID1多花了一个盘，但是多了一道保障。 解决方案3：光磁介质冷备份。通常我们叫做刻盘，呵呵。或者硬盘冷备——我两个硬盘各复制一份，拔掉一个硬盘放抽屉里，最适合照片之类数据。 解决方案4：RAID6。不过这个需要高级别的RAID卡支持，这个卡通常会很贵，至少贵出1-2个1TB盘的价值；同等容量还要多加一个硬盘，个人觉得在6个硬盘以内，相对RAID1的方案没有优势。既没有经济优势，又没有性能优势——啥都没有，不如老老实实做RAID1。优点当然有咯：即使遇到挂一个盘，它还算是一个RAID5——性能没有大减，数据也还有冗余，我慢慢等硬盘保修回来即可。注意哦，6个1T以上盘。也就是说，你的硬盘总容量少于这个数字，还是不用考虑RAID6了。","path":"2018/11/19/2336528398/","date":"11-19","excerpt":"","tags":[{"name":"Windows","slug":"Windows","permalink":"https://yihuishou.github.io/tags/Windows/"}]},{"title":"你好 querySelector","text":"H5带来的新操作方式querySelector和 querySelectorAll 是H5带来的新的获取Dom元素的方式。 用于替代旧版的document.getElementById``document.getElementsByTagName querySelectordocumen.querySelector() 使用CSS的选择器来进行元素选择，返回匹配到的第一个元素。 代替document.getElementById，如果要获取多个元素需使用documen.querySelectorAll() querySelectorAlldocumen.querySelectorAll()使用CSS的选择器来进行元素选择，返回匹配到的一组元素。 代替document.getElementsByTagName。 需要注意的是querySelectorAll()返回的是当前节点的静态节点列表NodeList 它可以可以使用数组的length属性，也可以利用数组的下标形式进行一些操作，但不具备数组所拥有的方法。 querySelectorAll和document.getElementsByTagName最大的区别是返回的结果不通。 document.getElementsByTagName返回的HTMLCollection是实时更新的 而querySelectorAll返回的NodeList是静态的，也就是说在查询的元素集合中添加或删除元素。 HTMLCollection会受到影响，而NodeList不会。","path":"2018/11/14/2407067064/","date":"11-14","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"SpringBoot 中使用非 Maven 仓库中的 Jar 包","text":"开发中偶尔会用到一些非开源的第三方Jar库，记录一下使用第三库的解决办法。 Maven安装简单粗暴的方法，使用Maven安装命令将第三方jar库直接安装到本地的Maven仓库中。 然后在项目中添加相关依赖信息就可以了。 注意：需要配置Maven到本地系统的环境变量中才能使用Maven命令 示例： mvn install:install-file -Dfile=jar包的位置 -DgroupId=jar包的groupId -DartifactId=jar包的artifactId -Dversion=jar包的version -Dpackaging=jar 依赖使用 &lt;dependency&gt; &lt;groupId&gt;jar包的groupId&lt;/groupId&gt; &lt;artifactId&gt;jar包的artifactId&lt;/artifactId&gt; &lt;version&gt;jar包的version&lt;/version&gt;&lt;/dependency&gt; 使用Maven的System作用域使用Maven的作用域可以不用安装Jar库到本地仓库就可以使用 但必须为依赖指定Jar包的位置，并且将依赖Jar包复制到项目中。 Oracle驱动示例： &lt;dependency&gt; &lt;groupId&gt;oracle&lt;/groupId&gt; &lt;artifactId&gt;oracle-connector-java&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;project.basedir&#125;/src/main/resources/lib/ojdbc6-11.1.0.7.0.jar&lt;/systemPath&gt;&lt;/dependency&gt; systemPath配置jar包的路径，scope必须为system。其他可以随意填写。","path":"2018/11/05/3348988487/","date":"11-05","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"使用 Swagger2 生成在线文档和 PDF","text":"在线文档之前有写过注解的说明 但网络上很少有提及离线文档的生成和其中解决中文乱码的问题 博客中的东西基本都是抄来抄去的东西 以下特此记录一下使用中的坑 SpringBoot中的Start推荐的版本，相对来说比较好用。 &lt;dependency&gt; &lt;groupId&gt;com.spring4all&lt;/groupId&gt; &lt;artifactId&gt;swagger-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.8.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; 入口类上加：@EnableSwagger2Doc 注解用以启用在线文档及自动配置。 application.yml 中的配置： swagger.enabled=是否启用swagger，默认：trueswagger.title=标题swagger.description=描述swagger.version=版本swagger.license=许可证swagger.licenseUrl=许可证URLswagger.termsOfServiceUrl=服务条款URLswagger.contact.name=维护人swagger.contact.url=维护人URLswagger.contact.email=维护人emailswagger.base-package=swagger扫描的基础包，默认：全扫描swagger.base-path=需要处理的基础URL规则，默认：/**swagger.exclude-path=需要排除的URL规则，默认：空swagger.host=文档的host信息，默认：空 通常用以排除SpringBoot自带的错误处理接口swagger.exclude-path= /error通常用以关闭自带的错误码，例如403、404等。必须至少配置一个code代码。apply-default-response-messages: falseswagger.global-response-message.get[0].code=401swagger.global-response-message.get[0].message=error Maven插件生成PDF和HTML文档记得关注官方示例中的配置，版本号一定要和示例中一致 记得关注官方示例中的配置，版本号一定要和示例中一致 记得关注官方示例中的配置，版本号一定要和示例中一致 重要的事情说三次，因为不一致的版本会导致各种奇葩的问题。 所以在这里需要要特别注意。 这里需要引入两个Maven插件和一个依赖 并且要配置两个额外仓库，中心仓库基本无法下载依赖项中的内容。 依赖配置： &lt;dependency&gt; &lt;groupId&gt;io.github.swagger2markup&lt;/groupId&gt; &lt;artifactId&gt;swagger2markup&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt;&lt;/dependency&gt; 仓库配置： &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;jcenter-snapshots&lt;/id&gt; &lt;name&gt;jcenter&lt;/name&gt; &lt;url&gt;http://oss.jfrog.org/artifactory/oss-snapshot-local/&lt;/url&gt; &lt;/pluginRepository&gt; &lt;pluginRepository&gt; &lt;id&gt;jcenter-releases&lt;/id&gt; &lt;name&gt;jcenter&lt;/name&gt; &lt;url&gt;http://jcenter.bintray.com&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;jcentral&lt;/id&gt; &lt;name&gt;bintray&lt;/name&gt; &lt;url&gt;http://jcenter.bintray.com&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;jcenter-snapshots&lt;/id&gt; &lt;name&gt;jcenter&lt;/name&gt; &lt;url&gt;http://oss.jfrog.org/artifactory/oss-snapshot-local/&lt;/url&gt; &lt;/repository&gt;&lt;/repositories&gt; 插件配置： &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;groupId&gt;io.github.swagger2markup&lt;/groupId&gt; &lt;artifactId&gt;swagger2markup-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.swagger2markup&lt;/groupId&gt; &lt;artifactId&gt;swagger2markup-import-files-ext&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.github.swagger2markup&lt;/groupId&gt; &lt;artifactId&gt;swagger2markup-spring-restdocs-ext&lt;/artifactId&gt; &lt;version&gt;1.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;swaggerInput&gt;$&#123;swagger.input&#125;&lt;/swaggerInput&gt; &lt;outputDir&gt;$&#123;generated.asciidoc.directory&#125;&lt;/outputDir&gt; &lt;config&gt; &lt;swagger2markup.markupLanguage&gt;ASCIIDOC&lt;/swagger2markup.markupLanguage&gt; &lt;swagger2markup.pathsGroupedBy&gt;TAGS&lt;/swagger2markup.pathsGroupedBy&gt; &lt;swagger2markup.extensions.dynamicOverview.contentPath&gt;$&#123;project.basedir&#125;/src/docs/asciidoc/extensions/overview&lt;/swagger2markup.extensions.dynamicOverview.contentPath&gt; &lt;swagger2markup.extensions.dynamicDefinitions.contentPath&gt;$&#123;project.basedir&#125;/src/docs/asciidoc/extensions/definitions&lt;/swagger2markup.extensions.dynamicDefinitions.contentPath&gt; &lt;swagger2markup.extensions.dynamicPaths.contentPath&gt;$&#123;project.basedir&#125;/src/docs/asciidoc/extensions/paths&lt;/swagger2markup.extensions.dynamicPaths.contentPath&gt; &lt;swagger2markup.extensions.dynamicSecurity.contentPath&gt;$&#123;project.basedir&#125;src/docs/asciidoc/extensions/security/&lt;/swagger2markup.extensions.dynamicSecurity.contentPath&gt; &lt;swagger2markup.extensions.springRestDocs.snippetBaseUri&gt;$&#123;swagger.snippetOutput.dir&#125;&lt;/swagger2markup.extensions.springRestDocs.snippetBaseUri&gt; &lt;swagger2markup.extensions.springRestDocs.defaultSnippets&gt;true&lt;/swagger2markup.extensions.springRestDocs.defaultSnippets&gt; &lt;swagger2markup.pathSecuritySectionEnabled&gt;false&lt;/swagger2markup.pathSecuritySectionEnabled&gt; &lt;/config&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;convertSwagger2markup&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;groupId&gt;org.asciidoctor&lt;/groupId&gt; &lt;artifactId&gt;asciidoctor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.6&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.asciidoctor&lt;/groupId&gt; &lt;artifactId&gt;asciidoctorj-pdf&lt;/artifactId&gt; &lt;version&gt;1.5.0-alpha.16&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jruby&lt;/groupId&gt; &lt;artifactId&gt;jruby-complete&lt;/artifactId&gt; &lt;version&gt;1.7.21&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;sourceDirectory&gt;$&#123;asciidoctor.input.directory&#125;&lt;/sourceDirectory&gt; &lt;sourceDocumentName&gt;index.adoc&lt;/sourceDocumentName&gt; &lt;attributes&gt; &lt;doctype&gt;book&lt;/doctype&gt; &lt;toc&gt;left&lt;/toc&gt; &lt;toclevels&gt;3&lt;/toclevels&gt; &lt;numbered&gt;&lt;/numbered&gt; &lt;hardbreaks&gt;&lt;/hardbreaks&gt; &lt;sectlinks&gt;&lt;/sectlinks&gt; &lt;sectanchors&gt;&lt;/sectanchors&gt; &lt;generated&gt;$&#123;generated.asciidoc.directory&#125;&lt;/generated&gt; &lt;/attributes&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;output-html&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;process-asciidoc&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;backend&gt;html5&lt;/backend&gt; &lt;outputDirectory&gt;$&#123;asciidoctor.html.output.directory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;output-pdf&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;process-asciidoc&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;backend&gt;pdf&lt;/backend&gt; &lt;outputDirectory&gt;$&#123;asciidoctor.pdf.output.directory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 参数配置： &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;asciidoctor.input.directory&gt;$&#123;project.basedir&#125;/src/docs/asciidoc&lt;/asciidoctor.input.directory&gt; &lt;swagger.output.dir&gt;$&#123;project.build.directory&#125;/swagger&lt;/swagger.output.dir&gt; &lt;swagger.snippetOutput.dir&gt;$&#123;project.build.directory&#125;/asciidoc/snippets&lt;/swagger.snippetOutput.dir&gt; &lt;generated.asciidoc.directory&gt;$&#123;project.build.directory&#125;/asciidoc/generated&lt;/generated.asciidoc.directory&gt; &lt;asciidoctor.html.output.directory&gt;$&#123;project.build.directory&#125;/asciidoc/html&lt;/asciidoctor.html.output.directory&gt; &lt;asciidoctor.pdf.output.directory&gt;$&#123;project.build.directory&#125;/asciidoc/pdf&lt;/asciidoctor.pdf.output.directory&gt; &lt;swagger.input&gt;http://localhost/v2/api-docs&lt;/swagger.input&gt;&lt;/properties&gt; 由于参数配置中指定index.adoc用于合并文档，需要建立 src/docs/asciidoc/index.adoc文档来指定合并内容。 index.adoc的内容如下： include::&#123;generated&#125;/overview.adoc[]include::&#123;generated&#125;/definitions.adoc[]include::&#123;generated&#125;/paths.adoc[]include::&#123;generated&#125;/security.adoc[]include::example.adoc[] 以下是各项合并项的解释： include::{generated}/overview.adoc[]：描述总体大纲include::{generated}/definitions.adoc[]：描述详细参数include::{generated}/paths.adoc[]：描述路径接口include::{generated}/security.adoc[]：描述接口的安全配置 example.adoc：为自定义的追加文档内容，这里可以写一些自己定义的内容。 example.adoc的位置为：src/docs/asciidoc/example.adoc 不想显示的合并内容可以直接删除掉。 要想使这两个插件联合工作，需要执行Maven中的Test生命周期。不要单独使用Maven插件。 由于配置了swaggerJson数据源为在线数据源：http://localhost/v2/api-docs 在执行Test生命周期前，应启动程序实例来为插件提供数据。 Test生命周期结束后会在配置的目录中生成PDF和HTML文档。 解决中文缺字问题其实缺字问题的原因也很简单，插件中依赖的PDF生成库 asciidoctorj-pdf 自带的字体本身就不支持中文。 所以生成的PDF文档自然就缺字了。 解决的思路是到本地仓库中为这个依赖仓库添加支持中文的字体就好。 解决流程： 找到 asciidoctorj-pdf-1.5.0-alpha.16.jar 向 asciidoctorj-pdf-1.5.0-alpha.16.jar\\gems\\asciidoctor-pdf-1.5.0.alpha.16\\data\\fonts 目录中添加支持中文的字体。 注意这里只支持ttf字体，otf字体无法被插件识别3. 修改 asciidoctorj-pdf-1.5.0-alpha.16.jar\\gems\\asciidoctor-pdf-1.5.0.alpha.16\\data\\theme\\default-theme.yml 配置文件 font: catalog: # Noto Serif supports Latin, Latin-1 Supplement, Latin Extended-A, Greek, Cyrillic, Vietnamese &amp; an assortment of symbols Noto Serif: normal: 支持中文的字体.ttf bold: 支持中文的字体.ttf italic: 支持中文的字体.ttf bold_italic: 支持中文的字体.ttf 用修改后的库重新生成的PDF即可完美显示中文文字。","path":"2018/10/24/4110075300/","date":"10-24","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"制作文字的半透明渐变网点图案描边效果","text":"前言记录一下这种比较麻烦的特效实现方式 前后效果： 编写文字 图案描边 复制3个副本 第1个副本改为白色描边描边要比原描边多2-3个像素且描边为文字周围背景色 第2个副本改为黑色外发光添加内层的颜色叠加为白色。去除图案描边效果。 调节外发光中的扩展和大小属性，可以调节最终生成描边的渐变效果。 大小属性不应低于原始描边大小 扩展建议使用：20% 33% 50% 合并两个副本图层 修改图层模式为滤色 完成效果","path":"2018/10/16/844506532/","date":"10-16","excerpt":"","tags":[{"name":"Photoshop","slug":"Photoshop","permalink":"https://yihuishou.github.io/tags/Photoshop/"}]},{"title":"PL/SQL Developer 使用 Oracle 压缩备份","text":"重要的事情必须使用完整版Oracle客户端，使用绿色精简版则不能使用Oracle备份压缩工具。 下载安装客户端客户端示例： 安装必须选择管理员模式 配置PL/SQL Developeroc库配置： 使用Oracle压缩必须指定Oracle压缩工具exp.exe 卸载Oracle客户端如果不想使用Oracle客户端，则可使用Oracle客户端主目录下的卸载脚本进行卸载。 首先停止系统服务中Oracle的相关服务，然后执行卸载脚本。 脚本位置：Oracle主目录\\product\\版本号\\client_1\\deinstall 下的deinstall.bat","path":"2018/10/15/1193253562/","date":"10-15","excerpt":"","tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://yihuishou.github.io/tags/Oracle/"}]},{"title":"Mybatis 分页插件备忘录","text":"重要提示 PageHelper.startPage方法重要提示 只有紧跟在PageHelper.startPage方法后的第一个Mybatis的查询（Select）方法会被分页。 请不要配置多个分页插件 请不要在系统中配置多个分页插件(使用Spring时,mybatis-config.xml和Spring配置方式，请选择其中一种，不要同时配置多个分页插件)！ 分页插件不支持带有for update语句的分页 对于带有for update的sql，会抛出运行时异常，对于这样的sql建议手动分页，毕竟这样的sql需要重视。 分页插件不支持嵌套结果映射 由于嵌套结果方式会导致结果集被折叠，因此分页查询的结果在折叠后总数会减少，所以无法保证分页结果数量正确。 v1.2.4 增加 dialectAlias 参数，允许配置自定义实现的 别名，可以用于根据JDBCURL自动获取对应实现，允许通过此种方式覆盖已有的实现，配置示例如(多个配置用分号;隔开)： pagehelper.dialect-alias=oracle=com.github.pagehelper.dialect.helper.OracleDialect 增加 defaultCount 参数，用于控制默认不带 count 查询的方法中，是否执行 count 查询，默认 true 会执行 count 查询， 这是一个全局生效的参数，多数据源时也是统一的行为。配置示例如： pagehelper.default-count=false 分页插件可选参数如下： dialect：默认情况下会使用 PageHelper 方式进行分页，如果想要实现自己的分页逻辑，可以实现 Dialect(com.github.pagehelper.Dialect) 接口，然后配置该属性为实现类的全限定名称。下面几个参数都是针对默认 dialect 情况下的参数。使用自定义 dialect 实现时，下面的参数没有任何作用。 helperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值：oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby特别注意：使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012，否则会使用 SqlServer2005 的方式进行分页。你也可以实现 AbstractHelperDialect，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。 offsetAsPageNum：默认值为 false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。 rowBoundsWithCount：默认值为false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为true时，使用 RowBounds 分页会进行 count 查询。 pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。 reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum&lt;=0 时会查询第一页， pageNum&gt;pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询。 params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。 supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest。 autoRuntimeDialect：默认值为 false。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择sqlserver2012，只能使用sqlserver），用法和注意事项参考下面的场景五。 closeConn：默认值为 true。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认true关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。 重要提示： 当 offsetAsPageNum=false 的时候，由于 PageNum 问题，RowBounds查询的时候 reasonable 会强制为 false。使用 PageHelper.startPage 方法不受影响。 如何选择配置这些参数 单独看每个参数的说明可能是一件让人不爽的事情，这里列举一些可能会用到某些参数的情况。 场景一 如果你仍然在用类似ibatis式的命名空间调用方式，你也许会用到rowBoundsWithCount， 分页插件对RowBounds支持和 MyBatis 默认的方式是一致，默认情况下不会进行 count 查询，如果你想在分页查询时进行 count 查询， 以及使用更强大的 PageInfo 类，你需要设置该参数为 true。 注： PageRowBounds 想要查询总数也需要配置该属性为 true。 场景二 如果你仍然在用类似ibatis式的命名空间调用方式，你觉得 RowBounds 中的两个参数 offset,limit 不如 pageNum,pageSize 容易理解， 你可以使用 offsetAsPageNum 参数，将该参数设置为 true 后，offset会当成 pageNum 使用，limit 和 pageSize 含义相同。 场景三 如果觉得某个地方使用分页后，你仍然想通过控制参数查询全部的结果，你可以配置 pageSizeZero 为 true， 配置后，当 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果。 场景四 如果你分页插件使用于类似分页查看列表式的数据，如新闻列表，软件列表， 你希望用户输入的页数不在合法范围（第一页到最后一页之外）时能够正确的响应到正确的结果页面， 那么你可以配置 reasonable 为 true，这时如果 pageNum&lt;=0 会查询第一页，如果 pageNum&gt;总页数 会查询最后一页。 场景五 如果你在 Spring 中配置了动态数据源，并且连接不同类型的数据库，这时你可以配置 autoRuntimeDialect 为 true，这样在使用不同数据源时，会使用匹配的分页进行查询。 这种情况下，你还需要特别注意 closeConn 参数，由于获取数据源类型会获取一个数据库连接，所以需要通过这个参数来控制获取连接后，是否关闭该连接。 默认为 true，有些数据库连接关闭后就没法进行后续的数据库操作。而有些数据库连接不关闭就会很快由于连接数用完而导致数据库无响应。所以在使用该功能时，特别需要注意你使用的数据源是否需要关闭数据库连接。 当不使用动态数据源而只是自动获取 helperDialect 时，数据库连接只会获取一次，所以不需要担心占用的这一个连接是否会导致数据库出错，但是最好也根据数据源的特性选择是否关闭连接。 //第二种，Mapper接口方式的调用，推荐这种使用方式。PageHelper.startPage(1, 10);List list = countryMapper.selectIf(1); //第三种，Mapper接口方式的调用，推荐这种使用方式。PageHelper.offsetPage(1, 10);List list = countryMapper.selectIf(1); 除了 PageHelper.startPage 方法外，还提供了类似用法的 PageHelper.offsetPage 方法。 返回 page 对象 在你需要进行分页的 MyBatis 查询方法前调用 PageHelper.startPage 静态方法即可，紧跟在这个方法后的第一个MyBatis 查询方法会被进行分页。 例三，使用PageInfo的用法： //获取第1页，10条内容，默认查询总数countPageHelper.startPage(1, 10);List list = countryMapper.selectAll();//用PageInfo对结果进行包装PageInfo page = new PageInfo(list);//测试PageInfo全部属性//PageInfo包含了非常全面的分页属性assertEquals(1, page.getPageNum());assertEquals(10, page.getPageSize());assertEquals(1, page.getStartRow());assertEquals(10, page.getEndRow());assertEquals(183, page.getTotal());assertEquals(19, page.getPages());assertEquals(1, page.getFirstPage());assertEquals(8, page.getLastPage());assertEquals(true, page.isFirstPage());assertEquals(false, page.isLastPage());assertEquals(false, page.isHasPreviousPage());assertEquals(true, page.isHasNextPage()); PageHelper 安全调用 只要你可以保证在 PageHelper 方法调用后紧跟 MyBatis 查询方法，这就是安全的。因为 PageHelper 在 finally 代码段中自动清除了 ThreadLocal 存储的对象。 如果代码在进入 Executor 前发生异常，就会导致线程不可用，这属于人为的 Bug（例如接口方法和 XML 中的不匹配，导致找不到 MappedStatement 时）， 这种情况由于线程不可用，也不会导致 ThreadLocal 参数被错误的使用。","path":"2018/09/28/3178181323/","date":"09-28","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"SpringBoot 使用 Redis 和 StringRedisTemplate","text":"一定要引入spring-boot-starter-data-redis @EnableCaching 启用缓存配置@Cacheable 指定某个方法的返回值是可以缓存的。在注解属性中指定缓存规则。@Cacheput 将方法的返回值缓存到指定的key中@CacheEvict 删除指定的缓存数据注意@Cacheable和@Cacheput都会将方法的执行结果按指定的key放到缓存中，@Cacheable在执行时，会先检测缓存中是否有数据存在，如果有，直接从缓存中读取。如果没有，执行方法，将返回值放入缓存，而@Cacheput会先执行方法，然后再将执行结果写入缓存。 使用@Cacheput的方法一定会执行 @EnableCaching : 开启SpringBoot缓存策略，放在启动主类。@CacheConfig(cacheNames = “XXX”) : 设置一个名为”XXX”的缓存空间。@Cacheable : Spring在每次执行前都会检查Cache中是否存在相同key的缓存元素，如果存在就不再执行该方法，而是直接从缓存中获取结果进行返回，否则才会执行并将返回结果存入指定的缓存中。@CacheEvict : 清除缓存。@CachePut : @CachePut也可以声明一个方法支持缓存功能。使用@CachePut标注的方法在执行前不会去检查缓存中是否存在之前执行过的结果，而是每次都会执行该方法，并将执行结果以键值对的形式存入指定的缓存中。 # Redis 配置(默认配置)# Redis 数据库索引（默认为0）spring.redis.database=0# Redis 服务器地址spring.redis.host=localhost# Redis 服务器端口spring.redis.port=6379# Redis 服务器密码(默认为空)spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 全局键值生命时间spring.redis.timeout=0 @Cacheable将查询结果缓存到redis中，（key=”#p0”）指定传入的第一个参数作为redis的key。 @CachePut，指定key，将更新的结果同步到redis中 @CacheEvict，指定key，删除缓存数据，allEntries=true,方法调用后将立即清除缓存 Spring Session 分布式系统中，sessiong共享有很多的解决方案，其中托管到缓存中应该是最常用的方案之一。 SpringSession 原理 @EnableRedisHttpSession 这个注解创建了一个名为 springSessionRepositoryFilter 的 bean，负责替换 httpSession,同时由 redis 提供缓存支持。maxInactiveIntervalInSeconds:设置Session失效时间。使用Redis Session之后，原Boot的server.session.timeout属性不再生效。 这次还是spring整合redis，实现方式用到注解。1、@Cacheable：作用是主要针对方法配置，能够根据方法的请求参数对其结果进行缓存主要参数说明：(1)value ：缓存的名称，在 spring 配置文件中定义，必须指定至少一个，例如：@Cacheable(value=”mycache”) 或者 @Cacheable(value={”cache1”,”cache2”}。(2)key ：缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合，例如：@Cacheable(value=”testcache”,key=”#userName”)。(3)condition ：缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存，例如：@Cacheable(value=”testcache”,condition=”#userName.length()&gt;2。当然还包括其他的参数，就不一一说明了。 2、@CachePut：作用是主要针对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用主要参数说明： (1)value ， key 和 condition 参数配置和@Cacheable一样。 3、@CacheEvict：作用是主要针对方法配置，能够根据一定的条件对缓存进行清空主要参数说明： (1)value ， key 和 condition 参数配置和@Cacheable一样。(2)allEntries ：是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存，例如：@CachEvict(value=”testcache”,allEntries=true)。(3)beforeInvocation ：是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存，例如@CachEvict(value=”testcache”，beforeInvocation=true)。 我主要想说的是Redis和Java当中Spring结合起来的时候，使用到的RedisTemplate和StringRedisTemplate 他们两者之间的区别，以及该怎么使用。 RedisTemplate看这个类的名字后缀是Template，如果了解过Spring如何连接关系型数据库的，大概不会难猜出这个类是做什么的 ，它跟JdbcTemplate一样封装了对Redis的一些常用的操作，当然StringRedisTemplate跟RedisTemplate功能类似那么肯定就会有人问，为什么会需要两个Template呢，一个不就够了吗？其实他们两者之间的区别主要在于他们使用的序列化类。 RedisTemplate使用的是 JdkSerializationRedisSerializerStringRedisTemplate使用的是 StringRedisSerializer RedisTemplate使用的序列类在在操作数据的时候，比如说存入数据会将数据先序列化成字节数组然后在存入Redis数据库，这个时候打开Redis查看的时候，你会看到你的数据不是以可读的形式展现的，而是以字节数组显示。 redisTemplate.opsForValue();//操作字符串redisTemplate.opsForHash();//操作hashredisTemplate.opsForList();//操作listredisTemplate.opsForSet();//操作setredisTemplate.opsForZSet();//操作有序set","path":"2018/09/19/3798124554/","date":"09-19","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot 读取配置文件中的信息","text":"@value使用在属性上 @value(“${spirng.xxx}”) ${}表达式获取配置文件中的值，获取失败将报错 @value(“${spirng.xxx:defaultValue}”) 使用:配置默认值 @PropertySource使用在类上 @PropertySource(value = {“classpath:application.properties”},ignoreResourceNotFound = true,encoding = “UTF-8”) value： 指定路径 ignoreResourceNotFound： 是否忽略配置文件未找到错误 encoding：编码","path":"2018/09/19/1177412043/","date":"09-19","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"用纯注解方式来使用 Mybatis","text":"#### @Insert 编写insert语句，实现数据的新增 @Insert(\"insert into users(name, age) values(#&#123;name&#125;, #&#123;age&#125;)\")public int add(Users user); 2、@Update 编写update语句，实现数据的修改 @Update(\"update users set name = #&#123;name&#125;, age = #&#123;age&#125; where id = #&#123;id&#125;\")public int update(Users user); 3、@Delete 编写delete语句，实现数据的删除 @Delete(\"delete from users where id = #&#123;id&#125;\")public int deleteById(int id); 4、@Select 编写select语句，实现数据的查询 @Select(\"select * from users where id = #&#123;id&#125;\")public Users getUserById(int id); 5、@Options 参数设置常用属性：keyPropertyuseGeneratedKeys 获取插入成功后自增主键的值 执行添加操作之后，直接访问对象的主键字段属性即可取得对应值。statementTypekeyColumntimeout 6、@ResultType 标记结果集的数据类型，Class&lt;?&gt;,等价于xml中的resulttype 7、@Results 标记结果集的数据类型，等价于xml中的 @ResultMap 标记结果集的数据类型配置文件id，关联对应的XML配置文件中的id属性 8、@Result 结果集的具体的数据对应常用属性：id：idproperty：映射属性column：数据库列 property，column属性相同时可省略 one:一对一或多对一many：集合，一对多javaType:对应的java中数据类型 9、@One用于@Result注解中实现嵌套查询，一般用于一对一或多对一的关系中常用属性：select：关联查询语句fetchType：抓取策略取值：FetchType.EAGER 急加载FetchType.LAZY 懒加载FetchType.DEFAULT 使用DEFAULT时可省略该属性 10、@Many用于@Result注解中实现嵌套查询，一般用于一对多或多对多常用属性：select：关联查询语句fetchType：抓取策略取值：FetchType.EAGERFetchType.LAZYFetchType.DEFAULT 使用DEFAULT时可省略该属性 1、FetchType.LAZY：懒加载，加载一个实体时，定义懒加载的属性不会马上从数据库中加载。 2、FetchType.EAGER：急加载，加载一个实体时，定义急加载的属性会立即从数据库中加载。 注解版联合查询语句需要分开单读写，即两个表单独查询后，合并结果集。 一对一、一对多实例 public interface TbUserMapper &#123; //嵌套对象：一对一 //连接查询 @Select(\"select u.*,c.* from tb_user u left join tb_cart c on u.cid=c.id\") @Results(&#123; @Result(id=true,property=\"id\",column=\"id\"), @Result(property=\"usename\" ,column=\"usename\"), @Result(property=\"password\" ,column=\"password\"), // cart为嵌套对象 @Result(property=\"cart.id\",column=\"cid\"), @Result(property=\"cart.money\",column=\"money\"), @Result(property=\"cart.count\",column=\"count\") &#125;) List&lt;TbUser&gt; queryAllByOne1(); //嵌套对象：一对一 //嵌套查询 @Select(\"select * from tb_user\") @Results(&#123; @Result(id=true,property=\"id\",column=\"id\"), @Result(property=\"usename\" ,column=\"usename\"), @Result(property=\"password\" ,column=\"password\"), @Result(property=\"cart\",column=\"cid\", // column 为关联查询提供查询参数 one=@One(select=\"org.qf.dao.TbCartMapper.queryById\",fetchType=FetchType.EAGER)) &#125;) List&lt;TbUser&gt; queryAllByOne2(); //一对多的实现 //嵌套查询 @Select(\"select * from tb_user\") @Results(&#123; @Result(id=true,property=\"id\",column=\"id\"), @Result(property=\"usename\" ,column=\"usename\"), @Result(property=\"password\" ,column=\"password\"), @Result(property=\"orders\",column=\"cid\", // column 为关联查询提供查询参数 many=@Many(fetchType=FetchType.EAGER,select=\"org.qf.dao.TbOrderMapper.queryByUid\")) &#125;) List&lt;TbUser&gt; queryAllByMany1(); //连接查询 @Select(\"select u.*,o.*,o.id odid from tb_user u left join tb_order o on u.id=o.uid\") @ResultMap(\"org.qf.dao.TbUserMapper.rm1\") List&lt;TbUser&gt; queryAllByMany2();&#125; org.qf.dao.TbUserMapper关联查询 @Select(\"select * from cart where cartid=#&#123;cartid&#125;\")cart queryByUid(String cartid); foreachIn查询 / 批量操作 collection：表示传入过来的参数的数据类型。该参数为必选。要做 foreach 的对象，作为入参时，List 对象默认用 list 代替作为键，数组对象有 array 代替作为键，Map 对象没有默认的键。当然在作为入参时可以使用 @Param(“keyName”) 来设置键，设置 keyName 后，list,array 将会失效。 除了入参这种情况外，还有一种作为参数对象的某个字段的时候。举个例子：如果 User 有属性 List ids。入参是 User 对象，那么这个 collection = “ids” 如果 User 有属性 Ids ids;其中 Ids 是个对象，Ids 有个属性 List id;入参是 User 对象，那么 collection = “ids.id”如果传入的是单参数且参数类型是一个 List 的时候，collection 属性值为 list如果传入的是单参数且参数类型是一个 array 数组的时候，collection 的属性值为 array如果传入的参数是多个的时候，我们就需要把它们封装成一个 Map 了，当然单参数也可以封装成 map。item： 循环体中的具体对象。支持属性的点路径访问，如 item.age,item.info.details。具体说明：在 list 和数组中是其中的对象，在 map 中是 value，该参数为必选。（它是每一个元素进行迭代时的别名）index：在 list 和数组中,index 是元素的序号；在 map 中，index 是元素的 key。 foreach标签主要用于构建in条件，他可以在sql中对集合进行迭代。如下： &lt;delete id=\"deleteBatch\"&gt; delete from user where id in &lt;foreach collection=\"array\" item=\"id\" index=\"index\" open=\"(\" close=\")\" separator=\",\"&gt; #&#123;id&#125; &lt;/foreach&gt; &lt;/delete&gt; 我们假如说参数为—- int[] ids = {1,2,3,4,5} —-那么打印之后的SQL如下： delete form user where id in (1,2,3,4,5) 释义： collection ：collection属性的值有三个分别是list、array、map三种，分别对应的参数类型为：List、数组、map集合，我在上面传的参数为数组，所以值为array item ： 表示在迭代过程中每一个元素的别名 index ：表示在迭代过程中每次迭代到的位置（下标） open ：前缀 close ：后缀 separator ：分隔符，表示迭代时每个元素之间以什么分隔 我们通常可以将之用到批量删除、添加等操作中。 @Select(\"&lt;script&gt;\" + \"SELECT IDFA FROM t_xxx WHERE IDFA IN \" + \"&lt;foreach item='item' index='index' collection='strList' open='(' separator=',' close=')'&gt;\" + \"#&#123;item&#125;\" + \"&lt;/foreach&gt;\" + \"&lt;/script&gt;\")@Results(value = &#123; @Result(column = \"user_name\", property = \"username\") &#125;)public List&lt;String&gt; getXxxList(@Param(\"strList\") List&lt;String&gt; strList); Mybatis 使用懒加载后，JSON 序列化错误 为SpringMVC里默认序列化使用的 com.fasterxml.jackson.databind.ObjectMapper 设置其属性 SerializationFeature.FAIL_ON_EMPTY_BEANS 为false。 3.配置json转换器属性SerializationFeature.FAIL_ON_EMPTY_BEANS为false springboot application.yml spring: jackson: serialization: &#123;FAIL_ON_EMPTY_BEANS : false&#125; 或者 闭该查询的懒加载 fetchType=”eager” 2.返回的类加上注解 @JsonIgnoreProperties(value = { “handler” }) 参数获取 有三种方式：1、就是普通写法，在文件中通过arg或param获取2、使用Map集合，在文件中使用#{key}获取3、使用注解@Param，在文件中使用#{名称} 1、arg或param获取 接口对应的方法： int update1(String xh,int id); 映射文件的获取： &lt;!-- update tb_car set xh=#{arg0} where id=#{arg1} --&gt; &lt;update id=&quot;update1&quot; &gt; update tb_car set xh=#{param1} where id=#{param2} &lt;/update&gt;可以选择使用arg获取也可以使用param获取，但是arg从0开始，而param从1开始。 2、Map集合传递多参数 接口对应的方法： //第二种：封装成集合 int update3(Map&lt;String,Object&gt; map);映射文件获取 &lt;!--多参之二：Map集合 --&gt; &lt;update id=&quot;update3&quot; parameterType=&quot;map&quot;&gt; update tb_car set color=#{c} where id=#{id} &lt;/update&gt;3、注解@Param传递多参数 接口对应的方法： int update5(@Param(“xh”) String x,@Param(“id”) int i); 映射文件获取： &lt;update id=&quot;update5&quot; &gt; update tb_car set xh=#{xh} where id=#{id} &lt;/update&gt;","path":"2018/09/18/2561778058/","date":"09-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Shiro 的注解及权限表达式","text":"securityManager：这个属性是必须的。 loginUrl ：没有登录的用户请求需要登录的页面时自动跳转到登录页面，不是必须的属性，不输入地址的话会自动寻找项目web项目的根目录下的”/login.jsp”页面。 successUrl ：登录成功默认跳转页面，不配置则跳转至”/”。如果登陆前点击的一个需要登录的页面，则在登录自动跳转到那个需要登录的页面。不跳转到此。 unauthorizedUrl ：没有权限默认跳转的页面 其权限过滤器及配置释义 anon:例子/admins/**=anon 没有参数，表示可以匿名使用。 authc:例如/admins/user/**=authc表示需要认证(登录)才能使用，没有参数 roles(角色)：例子/admins/user/=roles[admin],参数可以写多个，多个时必须加上引号，并且参数之间用逗号分割，当有多个参数时，例如admins/user/=roles[“admin,guest”],每个参数通过才算通过，相当于hasAllRoles()方法。 perms（权限）：例子/admins/user/=perms[user:add:*],参数可以写多个，多个时必须加上引号，并且参数之间用逗号分割，例如/admins/user/=perms[“user:add:,user:modify:“]，当有多个参数时必须每个参数都通过才通过，想当于isPermitedAll()方法。 rest：例子/admins/user/=rest[user],根据请求的方法，相当于/admins/user/=perms[user:method] ,其中method为post，get，delete等。 port：例子/admins/user/**=port[8081],当请求的url的端口不是8081是跳转到schemal://serverName:8081?queryString,其中schmal是协议http或https等，serverName是你访问的host,8081是url配置里port的端口，queryString 是你访问的url里的？后面的参数。 authcBasic：例如/admins/user/**=authcBasic没有参数表示httpBasic认证 ssl:例子/admins/user/**=ssl没有参数，表示安全的url请求，协议为https user:例如/admins/user/**=user没有参数表示必须存在用户，当登入操作时不做检查 Shiro的认证注解处理是有内定的处理顺序的，如果有个多个注解的话，前面的通过了会继续检查后面的，若不通过则直接返回，处理顺序依次为（与实际声明顺序无关）： RequiresRolesRequiresPermissionsRequiresAuthenticationRequiresUserRequiresGuest @RequiresRoles(value={“admin”, “user”}, logical= Logical.AND)：表示当前 Subject 需要角色 admin 和 user简写形式 @RequiresRoles({“admin”, “user”})@RequiresPermissions (value={“user:a”, “user:b”}, logical= Logical.OR)：表示当前 Subject 需要权限 user:a 或 user:b。@RequiresAuthentication：表示当前Subject已经通过login 进行了身份验证；即 Subject.isAuthenticated() 返回 true@RequiresUser：表示当前 Subject 已经身份验证或者通过记住我登录的。@RequiresGuest：表示当前Subject没有身份验证或通过记住我登录过，即是游客身份。坑：Subject==null 时才行 注解可用于Service层和Controller层，用于Service层会干扰事务控制不推荐。","path":"2018/09/11/2728496134/","date":"09-11","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Java 配置类与 XML","text":"","path":"2018/09/07/1615584056/","date":"09-07","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Java 变量第二个字母大写的问题","text":"在Java开发中，命名规范一直备受关注，驼峰命名法各种命名规范常被开发中使用，在此不再赘述。本文主要记录一下当命名中第二个字母大写遇到的麻烦。 当第一个字母为小写，生成的getter和setter方法get和set后面的第一个字母为小写，后面的为大写。若此时通过反射调用set方法为此entity实例属性设置值或通过get方法取此entity实例的属性值时需注意，传方法名容易错误的将名称写成getATest或setATest（因为其他正常的命名方式是第一个字母大写），此时会报没有此方法的错误。 实体类中不要定义第一个、第二个都是大写字母的属性。 原因：Java Bean 内部处理中的方法 public static String decapitalize(String name) &#123; // 空值处理 if (name == null || name.length() == 0) &#123; return name; &#125; // 长度大于1 且前两个字母都为大写时返回原字符串 if (name.length() &gt; 1 &amp;&amp; Character.isUpperCase(name.charAt(1)) &amp;&amp; Character.isUpperCase(name.charAt(0)))&#123; return name; &#125; // 其他情况原字符串首字母小写后返回 char chars[] = name.toCharArray(); chars[0] = Character.toLowerCase(chars[0]); return new String(chars);&#125; 输入 输出 AA AA Aa aa //输出有问题 aA AA //输出有问题 aa aa","path":"2018/09/07/546886075/","date":"09-07","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"StringBuilder().append() 方法真的比 + 更快吗","text":"先说结论： 在 Java 7 之后 Java 对String进行了优化改造当未用 ; 结束并使用 + 拼接的语句速度不但不比 append() 慢，甚至还要略快一点。 对于初学Java的人来说，在学习String的时候，肯定有无数个人和我们讲过，”尽量不要使用+拼接字符串，效率不好，应该使用append，你自己循环拼接个十万次自己瞧瞧就知道了“，然后像下面那样给我们演示了一下，用+和用StringBuilder的append拼接个十万次，输出一下各自消耗的时间，差距非常大，让我们立刻深信不疑，+拼接就是个垃圾，除了平时方便测试代码，否则都不要去用了，并且当有初学者使用+拼接时，也会毫不犹豫地去高谈阔论地教育一番。 public class Test &#123; public static void main(String[] args)&#123; String str = \"\"; long start = System.currentTimeMillis(); for(int i=0; i&lt;100000; i++) str += \"a\"; long end = System.currentTimeMillis(); System.out.println(end - start); StringBuilder sb = new StringBuilder(); start = System.currentTimeMillis(); for(int i=0; i&lt;100000; i++) sb.append(\"a\"); str = sb.toString(); end = System.currentTimeMillis(); System.out.println(end - start); &#125;&#125; 上面的方框是+循环拼接，下面的方框是append循环拼接。可以看到循环中+拼接会创建一个StringBuilder，除此之外和直接使用StringBuilder没有两样，但问题是每次循环都会new一个StringBuilder，也就是说效率就差在这里了。 （在刚学Java7的时候，我从别人那里得到一个很搞笑的解释，”+拼接底层实际上是使用了StringBuilder，所以效率很低，因此我们应该在任何时候都使用StringBuffer来拼接字符串“，噗，真不知道这种混乱的逻辑是怎么产生的，StringBuffer是线程安全的怎么可能比StringBuilder效率高，233333） 对于此处的str = str + “a”，编译器会处理为new StringBuilder().append(str).append(“a”)，不管一次性+几个字符串，只要+拼接全部在一条语句中，就只会new一次，循环中+拼接被断成了十万条语句，那自然就会new十万次，当然就慢得多了。 可以看到，对于有String类型变量参与的情况（String变量+”字面量” 或者 String变量+String变量），只要+拼接没有断，那就会一直调用append，一旦另起一条语句，马上就会new一个StringBuilder。从结果来看，字符串字面量的拼接是不会使用new的。 Java中+拼接字符串并不是人们口中所说的那样臭名昭著，人们口中所说的效率低下指的是在循环中的+拼接，只是不知道从哪天开始完全变了味。如果你能保证在一条语句中把字符串或者字符串变量全部拼接完而不断开，那+拼接根本没有任何缺点，编译器还会有一些优化，如果拼接的全是字符串字面量，那效果更好，它们直接就变成了一个完整的字符串。并且+书写简洁方便，可读性强。直接用StringBuilder的append也没有问题，只是不要append()和+混合使用。","path":"2018/09/07/2218955800/","date":"09-07","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Java 中 Arrays 工具类的陷阱","text":"数组工具类Arrays的特性容易导致的问题 数组用使用Array.asList()方法转为List时，数组内必须是对象类型，基本类型会抛出异常 通过Array.asList()获得的List集合被修改时，原数组也会同步修改。 Array.sort()从大到小排序的实现方法 一般情况下我们都会遇到将数组从大到小排序，但是Java系统的Arrays.sort()函数是将数组从小到大排序这个时候，我们就需要重写compare方法来实现从大到小。 需要注意的是，arr只能是Integer、Double之类的包装类，不能使用基本类型 自定义排序器，实现Comparator接口中的compare方法 排序器实例化 向传入Arrays排序器和要排序的数组 class Mycomparator implements Comparator&lt;Integer&gt; &#123; @Override public int compare(Integer o1, Integer o2) &#123; if (o1 &gt; o2) // 默认是o1 &lt; o2时返回-1， 以下同理 return -1; if (o1 &lt; o2) return 1; return 0; &#125; &#125; Comparator&lt;Integer&gt; comparer = new Mycomparator(); // 实例化一个Comparator对象 Arrays.sort(arrsExmple, comparer); 初始化 类型名[] 数组名 = new 类型名[数组长度] （声明和初始化一起进行） 类型名[] 数组名 = {数据1, 数据2, 数据3, ……, 数据n}（声明和初始化一起进行） 类型名[] 数组名 = new 类型名[]{数据1, 数据2, 数据3, ……, 数据n}（声明和初始化一起进行）","path":"2018/09/06/3285476338/","date":"09-06","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"优雅地使用枚举","text":"枚举的定义枚举类型是Java 5中新增特性的一部分，它是一种特殊的数据类型，之所以特殊是因为它既是一种类(class)类型却又比类类型多了些特殊的约束，但是这些约束的存在也造就了枚举类型的简洁性、安全性以及便捷性。 回忆一下下面的程序，这是在没有枚举类型时定义常量常见的方式 public class DayDemo &#123; public static final int MONDAY =1; public static final int TUESDAY=2; public static final int WEDNESDAY=3; public static final int THURSDAY=4; public static final int FRIDAY=5; public static final int SATURDAY=6; public static final int SUNDAY=7;&#125; 上述的常量定义常量的方式称为int枚举模式，这样的定义方式并没有什么错，但它存在许多不足，如在类型安全和使用方便性上并没有多少好处，如果存在定义int值相同的变量，混淆的几率还是很大的，编译器也不会提出任何警告，因此这种方式在枚举出现后并不提倡，现在我们利用枚举类型来重新定义上述的常量，同时也感受一把枚举定义的方式，如下定义周一到周日的常量 //枚举类型，使用关键字enumenum Day &#123; MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY&#125; 也可以直接定义为内部类 public class DayTime &#123; enum Day &#123; MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY &#125;&#125; 枚举的常见方法name()：返回此枚举常量的名称，在其枚举声明中对其进行声明。类型是String toString()：返回此枚举常量的名称，在其枚举声明中对其进行声明。类型是String (该方法可被重写) valueOf(Class enumType, String name)：根据枚举类的Class对象和枚举名称返回枚举常量 所以Day.valueOf(&quot;MONDAY&quot;)和Day.MONDAY 是相同的。 枚举的键值使用方法通过定义枚举中的私有属性和重载构造方法来实现 通过只提供getter来获取常量值 enum Day &#123; MONDAY(1), TUESDAY(2), WEDNESDAY(3), THURSDAY(4), FRIDAY(5), SATURDAY(6), SUNDAY(7); private int dayNumber; Day(int dayNumber) &#123; this.dayNumber = dayNumber; &#125; // 可选提供getter public int getDayNumber() &#123; return dayNumber; &#125;&#125; 使用： // 获取常量Day.MONDAY// 获取常量值Day.MONDAY.getDayNumber() 一般定义常量有三种方式，使用接口，使用类和使用枚举。这里推荐使用枚举的方式来定义常量。","path":"2018/09/04/3950067579/","date":"09-04","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"跟上Java8 Lambda","text":"使用Lambda表达式，我们可以很简洁地传递代码（通常是匿名函数）。 结构 Lambda表达式主要分为三部分：参数列表，箭头，Lambda 主体 语法 (parameters) -&gt; expression(parameters) -&gt; { statements; }如果表达式只有一行，用第一种，多行用第二种。 Java8中，标注了@FunctionalInterface，表明这个接口将是一个函数式接口，它里面只能有一个抽象方法。 常用的函数式接口 JDK已经为我们提供了很多常用的函数式接口： Predicate：java.util.function.Predicate接口定义了一个名叫test的抽象方法，它接受泛型T对象，并返回一个boolean。在需要表示一个涉及类型T的布尔表达式时可以使用。 Consumer：java.util.function.Consumer定义了一个名叫accept的抽象方法，它接受泛型T的对象，没有返回（void）。如果需要访问类型T的对象，并对其执行某些操作，就可以使用这个接口。 Supplier：java.util.function.Supplier不接受对象，返回一个泛型对象T。在需要new一个对象实例时可以使用。 Function：java.util.function.Function&lt;T, R&gt;接口定义了一个叫作apply的方法，它接受一个泛型T的对象，并返回一个泛型R的对象。如果需要定义一个Lambda，将输入对象的信息映射到输出，就可以使用这个接口。 原始类型特化 我们知道，泛型只能绑定到引用类型的对象。因此，在使用泛型绑定基本类型的时候，Java会为我们自动装箱和拆箱，但这是会消耗性能的。如果输入和输出都是基本类型时，Java8为我们提供了新的函数式接口，以避免自动装箱拆箱。 简单列举一部分： Predicate：IntPredicate, LongPredicate, DoublePredicate Consumer：IntConsumer,LongConsumer, DoubleConsumer Supplier：BooleanSupplier, IntSupplier, LongSupplier, DoubleSupplier Function：IntFunction,LongToDoubleFunction,ToLongFunction 从命名可以轻易看出从什么类型转成什么类型，可以在java.util.function包下查看所有接口。 使用局部变量 在使用lambda时，主体代码块内允许使用的外部变量。但是，不允许改变外部变量。这些变量应该声明为final或者事实上是final的（即之后代码中不会改变） 方法引用 方法引用主要有三类： 指向静态方法的方法引用Lambda: (args) -&gt; ClassName.staticMethod(args)方法引用：ClassName :: staticMethod指向任意类型实例方法的方法引用Lambda: (arg0, rest) -&gt; arg0.instanceMethod(rest)方法引用：ClassName :: instanceMethod(arg0 是 ClassName 类型的)指向现有对象的实例方法的方法引用Lambda: (args) -&gt; expr.instanceMethod(args)方法引用：expr :: intanceMethod除此之外，还有构造函数引用：ClassName :: new比如用Map来将构造函数映射到字符串值： static Map&lt;String, Function&lt;Integer, Fruit&gt;&gt; map = new HashMap&lt;&gt;(); static { map.put(&quot;apple&quot;, Apple::new); map.put(&quot;orange&quot;, Orange::new); // etc... } public static Fruit giveMeFruit(String fruit, Integer weight) { return map.get(fruit.toLowerCase()).apply(weight); }复合 Lambda 表达式 Comparator、Predicate和Function等函数式接口都有几个可以用来结Lambda表达式的默认方法。 比较器复合 普通排序comparing()Comparator c = Comparator.comparing(Apple::getWeight); 逆序reversed()inventory.sort(comparing(Apple::getWeight).reversed()); 比较器链thenComparing()inventory.sort(comparing(Apple::getWeight).reversed() .thenComparing(Apple::getCountry)); 谓词复合 3个方法增强已有的Predicate接口： and：与 or：或 negate：非 请注意，and和or方法是按照在表达式链中的位置，从左向右确定优先级的。因此，a.or(b).and(c)可以看作(a || b) &amp;&amp; c。 函数复合 Function接口有andThen和compose两个默认方法，它们都会返回Function的一个实例。 举个例子：有2个函数，一个加1，一个乘2 Function&lt;Integer, Integer&gt; f = x -&gt; x + 1; // f(x)=x+1Function&lt;Integer, Integer&gt; g = x -&gt; x * 2; // g(x)=2x andThen()Function&lt;Integer, Integer&gt; h = f.andThen(g); // g(f(x))int result = h.apply(1); // 4 compose()Function&lt;Integer, Integer&gt; h = f.compose(g); // f(g(x))int result = h.apply(1); // 3 什么是λ表达式 λ表达式本质上是一个匿名方法。让我们来看下面这个例子： public int add(int x, int y) { return x + y; }转成λ表达式后是这个样子： (int x, int y) -&gt; x + y;参数类型也可以省略，Java编译器会根据上下文推断出来： (x, y) -&gt; x + y; //返回两数之和或者 (x, y) -&gt; { return x + y; } //显式指明返回值可见λ表达式有三部分组成：参数列表，箭头（-&gt;），以及一个表达式或语句块。 下面这个例子里的λ表达式没有参数，也没有返回值（相当于一个方法接受0个参数，返回void，其实就是Runnable里run方法的一个实现）： () -&gt; { System.out.println(&quot;Hello Lambda!&quot;); }如果只有一个参数且可以被Java推断出类型，那么参数列表的括号也可以省略： c -&gt; { return c.size(); } λ表达式的类型（它是Object吗？） λ表达式可以被当做是一个Object（注意措辞）。λ表达式的类型，叫做“目标类型（target type）”。λ表达式的目标类型是“函数接口（functional interface）”，这是Java8新引入的概念。它的定义是：一个接口，如果只有一个显式声明的抽象方法，那么它就是一个函数接口。一般用@FunctionalInterface标注出来（也可以不标）。举例如下： @FunctionalInterface public interface Runnable { void run(); } public interface Callable&lt;V&gt; { V call() throws Exception; } public interface ActionListener { void actionPerformed(ActionEvent e); } public interface Comparator&lt;T&gt; { int compare(T o1, T o2); boolean equals(Object obj); }注意最后这个Comparator接口。它里面声明了两个方法，貌似不符合函数接口的定义，但它的确是函数接口。这是因为equals方法是Object的，所有的接口都会声明Object的public方法——虽然大多是隐式的。所以，Comparator显式的声明了equals不影响它依然是个函数接口。 你可以用一个λ表达式为一个函数接口赋值： Runnable r1 = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);};然后再赋值给一个Object： Object obj = r1;但却不能这样干： Object obj = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);}; // ERROR! Object is not a functional interface!必须显式的转型成一个函数接口才可以： Object o = (Runnable) () -&gt; { System.out.println(&quot;hi&quot;); }; // correct一个λ表达式只有在转型成一个函数接口后才能被当做Object使用。所以下面这句也不能编译： System.out.println( () -&gt; {} ); //错误! 目标类型不明必须先转型: System.out.println( (Runnable)() -&gt; {} ); // 正确假设你自己写了一个函数接口，长的跟Runnable一模一样： @FunctionalInterface public interface MyRunnable { public void run(); }那么 Runnable r1 = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);}; MyRunnable2 r2 = () -&gt; {System.out.println(&quot;Hello Lambda!&quot;);};都是正确的写法。这说明一个λ表达式可以有多个目标类型（函数接口），只要函数匹配成功即可。但需注意一个λ表达式必须至少有一个目标类型。 JDK预定义了很多函数接口以避免用户重复定义。最典型的是Function： @FunctionalInterface public interface Function&lt;T, R&gt; { R apply(T t); }这个接口代表一个函数，接受一个T类型的参数，并返回一个R类型的返回值。 另一个预定义函数接口叫做Consumer，跟Function的唯一不同是它没有返回值。 @FunctionalInterface public interface Consumer&lt;T&gt; { void accept(T t); }还有一个Predicate，用来判断某项条件是否满足。经常用来进行筛滤操作： @FunctionalInterface public interface Predicate&lt;T&gt; { boolean test(T t); }综上所述，一个λ表达式其实就是定义了一个匿名方法，只不过这个方法必须符合至少一个函数接口。 λ表达式的使用 3.1 λ表达式用在何处 λ表达式主要用于替换以前广泛使用的内部匿名类，各种回调，比如事件响应器、传入Thread类的Runnable等。看下面的例子： Thread oldSchool = new Thread( new Runnable () { @Override public void run() { System.out.println(&quot;This is from an anonymous class.&quot;); } } ); Thread gaoDuanDaQiShangDangCi = new Thread( () -&gt; { System.out.println(&quot;This is from an anonymous method (lambda exp).&quot;); } );注意第二个线程里的λ表达式，你并不需要显式地把它转成一个Runnable，因为Java能根据上下文自动推断出来：一个Thread的构造函数接受一个Runnable参数，而传入的λ表达式正好符合其run()函数，所以Java编译器推断它为Runnable。 从形式上看，λ表达式只是为你节省了几行代码。但将λ表达式引入Java的动机并不仅仅为此。Java8有一个短期目标和一个长期目标。短期目标是：配合“集合类批处理操作”的内部迭代和并行处理（下面将要讲到）；长期目标是将Java向函数式编程语言这个方向引导（并不是要完全变成一门函数式编程语言，只是让它有更多的函数式编程语言的特性），也正是由于这个原因，Oracle并没有简单地使用内部类去实现λ表达式，而是使用了一种更动态、更灵活、易于将来扩展和改变的策略（invokedynamic）。 3.2 λ表达式与集合类批处理操作（或者叫块操作） 上文提到了集合类的批处理操作。这是Java8的另一个重要特性，它与λ表达式的配合使用乃是Java8的最主要特性。集合类的批处理操作API的目的是实现集合类的“内部迭代”，并期望充分利用现代多核CPU进行并行计算。Java8之前集合类的迭代（Iteration）都是外部的，即客户代码。而内部迭代意味着改由Java类库来进行迭代，而不是客户代码。例如： for(Object o: list) { // 外部迭代 System.out.println(o); }可以写成： list.forEach(o -&gt; {System.out.println(o);}); //forEach函数实现内部迭代集合类（包括List）现在都有一个forEach方法，对元素进行迭代（遍历），所以我们不需要再写for循环了。forEach方法接受一个函数接口Consumer做参数，所以可以使用λ表达式。 这种内部迭代方法广泛存在于各种语言，如C++的STL算法库、python、ruby、scala等。 Java8为集合类引入了另一个重要概念：流（stream）。一个流通常以一个集合类实例为其数据源，然后在其上定义各种操作。流的API设计使用了管道（pipelines）模式。对流的一次操作会返回另一个流。如同IO的API或者StringBuffer的append方法那样，从而多个不同的操作可以在一个语句里串起来。看下面的例子： List&lt;Shape&gt; shapes = ... shapes.stream() .filter(s -&gt; s.getColor() == BLUE) .forEach(s -&gt; s.setColor(RED));首先调用stream方法，以集合类对象shapes里面的元素为数据源，生成一个流。然后在这个流上调用filter方法，挑出蓝色的，返回另一个流。最后调用forEach方法将这些蓝色的物体喷成红色。（forEach方法不再返回流，而是一个终端方法，类似于StringBuffer在调用若干append之后的那个toString） filter方法的参数是Predicate类型，forEach方法的参数是Consumer类型，它们都是函数接口，所以可以使用λ表达式。 还有一个方法叫parallelStream()，顾名思义它和stream()一样，只不过指明要并行处理，以期充分利用现代CPU的多核特性。 shapes.parallelStream(); // 或shapes.stream().parallel()来看更多的例子。下面是典型的大数据处理方法，Filter-Map-Reduce： //给出一个String类型的数组，找出其中所有不重复的素数 public void distinctPrimary(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); List&lt;Integer&gt; r = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .distinct() .collect(Collectors.toList()); System.out.println(&quot;distinctPrimary result is: &quot; + r); }第一步：传入一系列String（假设都是合法的数字），转成一个List，然后调用stream()方法生成流。 第二步：调用流的map方法把每个元素由String转成Integer，得到一个新的流。map方法接受一个Function类型的参数，上面介绍了，Function是个函数接口，所以这里用λ表达式。 第三步：调用流的filter方法，过滤那些不是素数的数字，并得到一个新流。filter方法接受一个Predicate类型的参数，上面介绍了，Predicate是个函数接口，所以这里用λ表达式。 第四步：调用流的distinct方法，去掉重复，并得到一个新流。这本质上是另一个filter操作。 第五步：用collect方法将最终结果收集到一个List里面去。collect方法接受一个Collector类型的参数，这个参数指明如何收集最终结果。在这个例子中，结果简单地收集到一个List中。我们也可以用Collectors.toMap(e-&gt;e, e-&gt;e)把结果收集到一个Map中，它的意思是：把结果收到一个Map，用这些素数自身既作为键又作为值。toMap方法接受两个Function类型的参数，分别用以生成键和值，Function是个函数接口，所以这里都用λ表达式。 你可能会觉得在这个例子里，List l被迭代了好多次，map，filter，distinct都分别是一次循环，效率会不好。实际并非如此。这些返回另一个Stream的方法都是“懒（lazy）”的，而最后返回最终结果的collect方法则是“急（eager）”的。在遇到eager方法之前，lazy的方法不会执行。 当遇到eager方法时，前面的lazy方法才会被依次执行。而且是管道贯通式执行。这意味着每一个元素依次通过这些管道。例如有个元素“3”，首先它被map成整数型3；然后通过filter，发现是素数，被保留下来；又通过distinct，如果已经有一个3了，那么就直接丢弃，如果还没有则保留。这样，3个操作其实只经过了一次循环。 除collect外其它的eager操作还有forEach，toArray，reduce等。 下面来看一下也许是最常用的收集器方法，groupingBy： //给出一个String类型的数组，找出其中各个素数，并统计其出现次数 public void primaryOccurrence(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); Map&lt;Integer, Integer&gt; r = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .collect( Collectors.groupingBy(p-&gt;p, Collectors.summingInt(p-&gt;1)) ); System.out.println(&quot;primaryOccurrence result is: &quot; + r); }注意这一行： Collectors.groupingBy(p-&gt;p, Collectors.summingInt(p-&gt;1))它的意思是：把结果收集到一个Map中，用统计到的各个素数自身作为键，其出现次数作为值。 下面是一个reduce的例子： //给出一个String类型的数组，求其中所有不重复素数的和 public void distinctPrimarySum(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); int sum = l.stream() .map(e -&gt; new Integer(e)) .filter(e -&gt; Primes.isPrime(e)) .distinct() .reduce(0, (x,y) -&gt; x+y); // equivalent to .sum() System.out.println(&quot;distinctPrimarySum result is: &quot; + sum); }reduce方法用来产生单一的一个最终结果。流有很多预定义的reduce操作，如sum()，max()，min()等。 再举个现实世界里的栗子比如： // 统计年龄在25-35岁的男女人数、比例 public void boysAndGirls(List&lt;Person&gt; persons) { Map&lt;Integer, Integer&gt; result = persons.parallelStream().filter(p -&gt; p.getAge()&gt;=25 &amp;&amp; p.getAge()&lt;=35). collect( Collectors.groupingBy(p-&gt;p.getSex(), Collectors.summingInt(p-&gt;1)) ); System.out.print(&quot;boysAndGirls result is &quot; + result); System.out.println(&quot;, ratio (male : female) is &quot; + (float)result.get(Person.MALE)/result.get(Person.FEMALE)); }3.3 λ表达式的更多用法 // 嵌套的λ表达式 Callable&lt;Runnable&gt; c1 = () -&gt; () -&gt; { System.out.println(&quot;Nested lambda&quot;); }; c1.call().run(); // 用在条件表达式中 Callable&lt;Integer&gt; c2 = true ? (() -&gt; 42) : (() -&gt; 24); System.out.println(c2.call()); // 定义一个递归函数，注意须用this限定 protected UnaryOperator&lt;Integer&gt; factorial = i -&gt; i == 0 ? 1 : i * this.factorial.apply( i - 1 ); ... System.out.println(factorial.apply(3));在Java中，随声明随调用的方式是不行的，比如下面这样，声明了一个λ表达式(x, y) -&gt; x + y，同时企图通过传入实参(2, 3)来调用它： int five = ( (x, y) -&gt; x + y ) (2, 3); // ERROR! try to call a lambda in-place这在C++中是可以的，但Java中不行。Java的λ表达式只能用作赋值、传参、返回值等。 其它相关概念 4.1 捕获（Capture） 捕获的概念在于解决在λ表达式中我们可以使用哪些外部变量（即除了它自己的参数和内部定义的本地变量）的问题。 答案是：与内部类非常相似，但有不同点。不同点在于内部类总是持有一个其外部类对象的引用。而λ表达式呢，除非在它内部用到了其外部类（包围类）对象的方法或者成员，否则它就不持有这个对象的引用。 在Java8以前，如果要在内部类访问外部对象的一个本地变量，那么这个变量必须声明为final才行。在Java8中，这种限制被去掉了，代之以一个新的概念，“effectively final”。它的意思是你可以声明为final，也可以不声明final但是按照final来用，也就是一次赋值永不改变。换句话说，保证它加上final前缀后不会出编译错误。 在Java8中，内部类和λ表达式都可以访问effectively final的本地变量。λ表达式的例子如下： ... int tmp1 = 1; //包围类的成员变量 static int tmp2 = 2; //包围类的静态成员变量 public void testCapture() { int tmp3 = 3; //没有声明为final，但是effectively final的本地变量 final int tmp4 = 4; //声明为final的本地变量 int tmp5 = 5; //普通本地变量 Function&lt;Integer, Integer&gt; f1 = i -&gt; i + tmp1; Function&lt;Integer, Integer&gt; f2 = i -&gt; i + tmp2; Function&lt;Integer, Integer&gt; f3 = i -&gt; i + tmp3; Function&lt;Integer, Integer&gt; f4 = i -&gt; i + tmp4; Function&lt;Integer, Integer&gt; f5 = i -&gt; { tmp5 += i; // 编译错！对tmp5赋值导致它不是effectively final的 return tmp5; }; ... tmp5 = 9; // 编译错！对tmp5赋值导致它不是effectively final的 } ...Java要求本地变量final或者effectively final的原因是多线程并发问题。内部类、λ表达式都有可能在不同的线程中执行，允许多个线程同时修改一个本地变量不符合Java的设计理念。 4.2 方法引用（Method reference） 任何一个λ表达式都可以代表某个函数接口的唯一方法的匿名描述符。我们也可以使用某个类的某个具体方法来代表这个描述符，叫做方法引用。例如： Integer::parseInt //静态方法引用 System.out::print //实例方法引用 Person::new //构造器引用下面是一组例子，教你使用方法引用代替λ表达式： //c1 与 c2 是一样的（静态方法引用） Comparator&lt;Integer&gt; c2 = (x, y) -&gt; Integer.compare(x, y); Comparator&lt;Integer&gt; c1 = Integer::compare; //下面两句是一样的（实例方法引用1） persons.forEach(e -&gt; System.out.println(e)); persons.forEach(System.out::println); //下面两句是一样的（实例方法引用2） persons.forEach(person -&gt; person.eat()); persons.forEach(Person::eat); //下面两句是一样的（构造器引用） strList.stream().map(s -&gt; new Integer(s)); strList.stream().map(Integer::new);使用方法引用，你的程序会变得更短些。现在distinctPrimarySum方法可以改写如下： public void distinctPrimarySum(String... numbers) { List&lt;String&gt; l = Arrays.asList(numbers); int sum = l.stream().map(Integer::new).filter(Primes::isPrime).distinct().sum(); System.out.println(&quot;distinctPrimarySum result is: &quot; + sum); }还有一些其它的方法引用: super::toString //引用某个对象的父类方法 String[]::new //引用一个数组的构造器4.3 默认方法（Default method） Java8中，接口声明里可以有方法实现了，叫做默认方法。在此之前，接口里的方法全部是抽象方法。 public interface MyInterf { String m1(); default String m2() { return &quot;Hello default method!&quot;; } }这实际上混淆了接口和抽象类，但一个类仍然可以实现多个接口，而只能继承一个抽象类。 这么做的原因是：由于Collection库需要为批处理操作添加新的方法，如forEach()，stream()等，但是不能修改现有的Collection接口——如果那样做的话所有的实现类都要进行修改，包括很多客户自制的实现类。所以只好使用这种妥协的办法。 如此一来，我们就面临一种类似多继承的问题。如果类Sub继承了两个接口，Base1和Base2，而这两个接口恰好具有完全相同的两个默认方法，那么就会产生冲突。这时Sub类就必须通过重载来显式指明自己要使用哪一个接口的实现（或者提供自己的实现）： public class Sub implements Base1, Base2 { public void hello() { Base1.super.hello(); //使用Base1的实现 } }除了默认方法，Java8的接口也可以有静态方法的实现： public interface MyInterf { String m1(); default String m2() { return &quot;Hello default method!&quot;; } static String m3() { return &quot;Hello static method in Interface!&quot;; } }4.4 生成器函数（Generator function） 有时候一个流的数据源不一定是一个已存在的集合对象，也可能是个“生成器函数”。一个生成器函数会产生一系列元素，供给一个流。Stream.generate(Supplier s)就是一个生成器函数。其中参数Supplier是一个函数接口，里面有唯一的抽象方法 get()。 下面这个例子生成并打印5个随机数： Stream.generate(Math::random).limit(5).forEach(System.out::println);注意这个limit(5)，如果没有这个调用，那么这条语句会永远地执行下去。也就是说这个生成器是无穷的。这种调用叫做终结操作，或者短路（short-circuiting）操作。","path":"2018/09/03/2921176476/","date":"09-03","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"跟上Java8 流中的数据","text":"流的构成当我们使用一个流的时候，通常包括三个基本步骤：获取一个数据源（source）→ 数据转换→执行操作获取想要的结果，每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道， 有多种方式生成 Stream Source：从 Collection 和数组Collection.stream()Collection.parallelStream()Arrays.stream(T array) or Stream.of()从 BufferedReaderjava.io.BufferedReader.lines()静态工厂java.util.stream.IntStream.range()java.nio.file.Files.walk()自己构建java.util.Spliterator其它Random.ints()BitSet.stream()Pattern.splitAsStream(java.lang.CharSequence)JarFile.stream()流的操作类型分为两种：Intermediate：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。Terminal：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。在对于一个 Stream 进行多次转换操作 (Intermediate 操作)，每次都对 Stream 的每个元素进行转换，而且是执行多次，这样时间复杂度就是 N（转换次数）个 for 循环里把所有操作都做掉的总和吗？其实不是这样的，转换操作都是 lazy 的，多个转换操作只会在 Terminal 操作的时候融合起来，一次循环完成。我们可以这样简单的理解，Stream 里有个操作函数的集合，每次转换操作就是把转换函数放入这个集合中，在 Terminal 操作的时候循环 Stream 对应的集合，然后对每个元素执行所有的函数。还有一种操作被称为 short-circuiting。用以指：对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。当操作一个无限大的 Stream，而又希望在有限时间内完成操作，则在管道内拥有一个 short-circuiting 操作是必要非充分条件。 需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：IntStream、LongStream、DoubleStream。当然我们也可以用 Stream、Stream &gt;、Stream，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。Java 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。 流的操作接下来，当把一个数据结构包装成 Stream 后，就要开始对里面的元素进行各类操作了。常见的操作可以归类如下。Intermediate：map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unorderedTerminal：forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iteratorShort-circuiting：anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit Stream 的特性可以归纳为：不是数据结构它没有内部存储，它只是用操作管道从 source（数据结构、数组、generator function、IO channel）抓取数据。它也绝不修改自己所封装的底层数据结构的数据。例如 Stream 的 filter 操作会产生一个不包含被过滤元素的新 Stream，而不是从 source 删除那些元素。所有 Stream 的操作必须以 lambda 表达式为参数不支持索引访问你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。不过请参阅下一项。很容易生成数组或者 List惰性化很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。Intermediate 操作永远是惰性化的。并行能力当一个 Stream 是并行化的，就不需要再写多线程代码，所有对它的操作会自动并行进行的。可以是无限的集合有固定大小，Stream 则不必。limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。 Optional 的注意事项 调用 isPresent() 方法时调用 get() 方法时Optional 类型作为类/实例属性时Optional 类型作为方法参数时isPresent() 与 obj != null 无任何区别, 我们的生活依然在步步惊心. 而没有 isPresent() 作铺垫的 get() 调用在 IntelliJ IDEA 中会收到告警。调用 Optional.get() 前不事先用 isPresent() 检查值是否可用. 假如 Optional 不包含一个值, get() 将会抛出一个异常！把 Optional 类型用作属性或是方法参数在 IntelliJ IDEA 中更是强力不推荐的！使用任何像 Optional 的类型作为字段或方法参数都是不可取的. Optional 只设计为类库方法的, 可明确表示可能无值情况下的返回类型. Optional 类型不可被序列化, 用作字段类型会出问题的！！！ 所以 Optional 中我们真正可依赖的应该是除了 isPresent() 和 get() 的其他方法: //按照使用频率排序如下public Optional map(Function&lt;? super T, ? extends U&gt; mapper)public T orElse(T other)public T orElseGet(Supplier&lt;? extends T&gt; other)public void ifPresent(Consumer&lt;? super T&gt; consumer)public Optional filter(Predicate&lt;? super T&gt; predicate)public Optional flatMap(Function&lt;? super T, Optional&gt; mapper)public T orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier) Optional 的三种构造方式:Optional.of(obj), Optional.ofNullable(obj) 和明确的 Optional.empty() Optional.of(obj): 它要求传入的 obj 不能是 null 值的, 否则还没开始进入角色就倒在了 NullPointerException 异常上了.Optional.ofNullable(obj): 它以一种智能的, 宽容的方式来构造一个 Optional 实例. 来者不拒, 传 null 进到就得到 Optional.empty(), 非 null 就调用 Optional.of(obj).那是不是我们只要用 Optional.ofNullable(obj) 一劳永逸, 以不变应二变的方式来构造 Optional 实例就行了呢? 那也未必, 否则 Optional.of(obj) 何必如此暴露呢, 私有则可? Optional.ofNullable(obj).isPresent()可以用来对集合进行快速判空。 JAVA并行流的性能“陷阱”从java8开始，并行编程变得很容易，通过并行流（parallelStream），可以很轻松的实现多线程并行处理。但是，这里面有个性能“陷阱”，如果不注意，使用并行流的效果反而更差，这个陷阱是什么呢？ 这个陷阱就是，并行流默认都是用同一个默认的ForkJoinPool，这个ForkJoinPool的线程数和CPU的核心数相同。如果是计算密集型的操作，直接使用是没有问题的，因为这个ForkJoinPool会将所有的CPU打满，系统资源是没有浪费的，但是，如果其中还有IO操作或等待操作，这个默认的ForkJoinPool只能消耗一部分CPU，而另外的并行流因为获取不到该ForkJoinPool的使用权，性能将大大降低。可见，默认的ForkJoinPool必须只能处理计算密集型的任务。 那么，对应非计算密集型的任务，改怎么处理呢？ 这就需要我们使用自己创建的ForkJoinPool来执行任务，下面给出实例代码： ForkJoinPool forkJoinPool = new ForkJoinPool(8); forkJoinPool.submit(()-&gt;&#123; tasks.parallelStream().forEach(t-&gt;&#123; try &#123; String gdsstatus=transactionService.GetTransInfo(url, t.getTask_id()); checkStatus(t.getTask_id(),t.getTask_status(),gdsstatus); &#125; catch (Exception e) &#123; System.out.println(\"EXCEPTION OCCOR IN TASK:\"+t.getTask_id()); e.printStackTrace(); &#125; System.out.println(\"NO:\"+count.getAndIncrement()+\" is done\"); &#125;);&#125;);","path":"2018/09/03/3512719846/","date":"09-03","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"跟上Java8 时间的魔术","text":"1、创建 根据年、月、日、时、分、秒、纳秒等创建LocalDateTime eg：LocalTime zero = LocalTime.of(0, 0, 0); // 00:00:00LocalTime mid = LocalTime.parse(“12:00:00”); // 12:00:00LocalTime now = LocalTime.now(); // 23:11:08.006 all methodLocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute)LocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute, int second)LocalDateTime of(int year, Month month, int dayOfMonth, int hour, int minute, int second, int nanoOfSecond)LocalDateTime of(int year, int month, int dayOfMonth, int hour, int minute)LocalDateTime of(int year, int month, int dayOfMonth, int hour, int minute, int second)LocalDateTime of(int year, int month, int dayOfMonth, int hour, int minute, int second, int nanoOfSecond)LocalDateTime of(LocalDate date, LocalTime time) 2、LocalDatetime 的所有方法： eg：// 取当前日期：LocalDate today = LocalDate.now(); // -&gt; 2014-12-24// 根据年月日取日期：LocalDate crischristmas = LocalDate.of(2014, 12, 25); // -&gt; 2014-12-25// 根据字符串取：LocalDate endOfFeb = LocalDate.parse(“2014-02-28”); // 严格按照ISO yyyy-MM-dd验证，02写成2都不行，当然也有一个重载方法允许自己定义格式LocalDate.parse(“2014-02-29”); // 无效日期无法通过：DateTimeParseException: Invalid date// 取本月第1天：LocalDate firstDayOfThisMonth = today.with(TemporalAdjusters.firstDayOfMonth()); // 2017-03-01// 取本月第2天：LocalDate secondDayOfThisMonth = today.withDayOfMonth(2); // 2017-03-02// 取本月最后一天，再也不用计算是28，29，30还是31：LocalDate lastDayOfThisMonth = today.with(TemporalAdjusters.lastDayOfMonth()); // 2017-12-31// 取下一天：LocalDate firstDayOf2015 = lastDayOfThisMonth.plusDays(1); // 变成了2018-01-01// 取2017年1月第一个周一，用Calendar要死掉很多脑细胞：LocalDate firstMondayOf2015 = LocalDate.parse(“2017-01-01”).with(TemporalAdjusters.firstInMonth(DayOfWeek.MONDAY)); // 2017-01-02 all method: adjustInto 调整指定的Temporal和当前LocalDateTime对 atOffset 结合LocalDateTime和ZoneOffset创建一个 atZone 结合LocalDateTime和指定时区创建一个ZonedD compareTo 比较两个LocalDateTime format 格式化LocalDateTime生成一个字符串 from 转换TemporalAccessor为LocalDateTi get 得到LocalDateTime的指定字段的值 getDayOfMonth 得到LocalDateTime是月的第几天 getDayOfWeek 得到LocalDateTime是星期几 getDayOfYear 得到LocalDateTime是年的第几天 getHour 得到LocalDateTime的小时 getLong 得到LocalDateTime指定字段的值 getMinute 得到LocalDateTime的分钟 getMonth 得到LocalDateTime的月份 getMonthValue 得到LocalDateTime的月份，从1到12 getNano 得到LocalDateTime的纳秒数 getSecond 得到LocalDateTime的秒数 getYear 得到LocalDateTime的年份 isAfter 判断LocalDateTime是否在指定LocalDateT isBefore 判断LocalDateTime是否在指定LocalDateT isEqual 判断两个LocalDateTime是否相等 isSupported 判断LocalDateTime是否支持指定时间字段或单元 minus 返回LocalDateTime减去指定数量的时间得到的值 minusDays 返回LocalDateTime减去指定天数得到的值 minusHours 返回LocalDateTime减去指定小时数得到的值 minusMinutes 返回LocalDateTime减去指定分钟数得到的值 minusMonths 返回LocalDateTime减去指定月数得到的值 minusNanos 返回LocalDateTime减去指定纳秒数得到的值 minusSeconds 返回LocalDateTime减去指定秒数得到的值 minusWeeks 返回LocalDateTime减去指定星期数得到的值 minusYears 返回LocalDateTime减去指定年数得到的值 now 返回指定时钟的当前LocalDateTime of 根据年、月、日、时、分、秒、纳秒等创建LocalDateTi ofEpochSecond 根据秒数(从1970-01-0100:00:00开始)创建L ofInstant 根据Instant和ZoneId创建LocalDateTim parse 解析字符串得到LocalDateTime plus 返回LocalDateTime加上指定数量的时间得到的值 plusDays 返回LocalDateTime加上指定天数得到的值 plusHours 返回LocalDateTime加上指定小时数得到的值 plusMinutes 返回LocalDateTime加上指定分钟数得到的值 plusMonths 返回LocalDateTime加上指定月数得到的值 plusNanos 返回LocalDateTime加上指定纳秒数得到的值 plusSeconds 返回LocalDateTime加上指定秒数得到的值 plusWeeks 返回LocalDateTime加上指定星期数得到的值 plusYears 返回LocalDateTime加上指定年数得到的值 query 查询LocalDateTime range 返回指定时间字段的范围 toLocalDate 返回LocalDateTime的LocalDate部分 toLocalTime 返回LocalDateTime的LocalTime部分 toString 返回LocalDateTime的字符串表示 truncatedTo 返回LocalDateTime截取到指定时间单位的拷贝 until 计算LocalDateTime和另一个LocalDateTi with 返回LocalDateTime指定字段更改为新值后的拷贝 withDayOfMonth 返回LocalDateTime月的第几天更改为新值后的拷贝 withDayOfYear 返回LocalDateTime年的第几天更改为新值后的拷贝 withHour 返回LocalDateTime的小时数更改为新值后的拷贝 withMinute 返回LocalDateTime的分钟数更改为新值后的拷贝 withMonth 返回LocalDateTime的月份更改为新值后的拷贝 withNano 返回LocalDateTime的纳秒数更改为新值后的拷贝 withSecond 返回LocalDateTime的秒数更改为新值后的拷贝 withYear 返回LocalDateTime年份更改为新值后的拷贝 3、对应的SQL的类型 SQL -&gt; Java date -&gt; LocalDatetime -&gt; LocalTimetimestamp -&gt; LocalDateTime 4、根据上面的方法自定义的Util类 public class DateTimeUtils &#123; public static final DateTimeFormatter TIME_FORMATTER = DateTimeFormatter.ofPattern(\"HHmmss\");public static final DateTimeFormatter MONTH_FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMM\");public static final DateTimeFormatter SHORT_DATE_FORMATTER = DateTimeFormatter.ofPattern(\"yyMMdd\");public static final DateTimeFormatter SHORT_DATETIME_FORMATTER = DateTimeFormatter.ofPattern(\"yyMMddHHmmss\");public static final DateTimeFormatter DATETIME_FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\");public static final DateTimeFormatter DATE_FORMATTER = DateTimeFormatter.ofPattern(\"yyyyMMdd\"); /** * 返回当前的日期 * @return */ public static LocalDate getCurrentLocalDate() &#123; return LocalDate.now(); &#125; /** * 返回当前时间 * @return */ public static LocalTime getCurrentLocalTime() &#123; return LocalTime.now(); &#125; /** * 返回当前日期时间 * @return */ public static LocalDateTime getCurrentLocalDateTime() &#123; return LocalDateTime.now(); &#125; /** * yyyyMMdd * * @return */ public static String getCurrentDateStr() &#123; return LocalDate.now().format(DATE_FORMATTER); &#125; /** * yyMMdd * * @return */ public static String getCurrentShortDateStr() &#123; return LocalDate.now().format(SHORT_DATE_FORMATTER); &#125; public static String getCurrentMonthStr() &#123; return LocalDate.now().format(MONTH_FORMATTER); &#125; /** * yyyyMMddHHmmss * @return */ public static String getCurrentDateTimeStr() &#123; return LocalDateTime.now().format(DATETIME_FORMATTER); &#125; /** * yyMMddHHmmss * @return */ public static String getCurrentShortDateTimeStr() &#123; return LocalDateTime.now().format(SHORT_DATETIME_FORMATTER); &#125; /** * HHmmss * @return */ public static String getCurrentTimeStr() &#123; return LocalTime.now().format(TIME_FORMATTER); &#125; public static String getCurrentDateStr(String pattern) &#123; return LocalDate.now().format(DateTimeFormatter.ofPattern(pattern)); &#125; public static String getCurrentDateTimeStr(String pattern) &#123; return LocalDateTime.now().format(DateTimeFormatter.ofPattern(pattern)); &#125; public static String getCurrentTimeStr(String pattern) &#123; return LocalTime.now().format(DateTimeFormatter.ofPattern(pattern)); &#125; public static LocalDate parseLocalDate(String dateStr, String pattern) &#123; return LocalDate.parse(dateStr, DateTimeFormatter.ofPattern(pattern)); &#125; public static LocalDateTime parseLocalDateTime(String dateTimeStr, String pattern) &#123; return LocalDateTime.parse(dateTimeStr, DateTimeFormatter.ofPattern(pattern)); &#125; public static LocalTime parseLocalTime(String timeStr, String pattern) &#123; return LocalTime.parse(timeStr, DateTimeFormatter.ofPattern(pattern)); &#125; public static String formatLocalDate(LocalDate date, String pattern) &#123; return date.format(DateTimeFormatter.ofPattern(pattern)); &#125; public static String formatLocalDateTime(LocalDateTime datetime, String pattern) &#123; return datetime.format(DateTimeFormatter.ofPattern(pattern)); &#125; public static String formatLocalTime(LocalTime time, String pattern) &#123; return time.format(DateTimeFormatter.ofPattern(pattern)); &#125; public static LocalDate parseLocalDate(String dateStr) &#123; return LocalDate.parse(dateStr, DATE_FORMATTER); &#125; public static LocalDateTime parseLocalDateTime(String dateTimeStr) &#123; return LocalDateTime.parse(dateTimeStr, DATETIME_FORMATTER); &#125; public static LocalTime parseLocalTime(String timeStr) &#123; return LocalTime.parse(timeStr, TIME_FORMATTER); &#125; public static String formatLocalDate(LocalDate date) &#123; return date.format(DATE_FORMATTER); &#125; public static String formatLocalDateTime(LocalDateTime datetime) &#123; return datetime.format(DATETIME_FORMATTER); &#125; public static String formatLocalTime(LocalTime time) &#123; return time.format(TIME_FORMATTER); &#125; /** * 日期相隔天数 * @param startDateInclusive * @param endDateExclusive * @return */ public static int periodDays(LocalDate startDateInclusive, LocalDate endDateExclusive) &#123; return Period.between(startDateInclusive, endDateExclusive).getDays(); &#125; /** * 日期相隔小时 * @param startInclusive * @param endExclusive * @return */ public static long durationHours(Temporal startInclusive, Temporal endExclusive) &#123; return Duration.between(startInclusive, endExclusive).toHours(); &#125; /** * 日期相隔分钟 * @param startInclusive * @param endExclusive * @return */ public static long durationMinutes(Temporal startInclusive, Temporal endExclusive) &#123; return Duration.between(startInclusive, endExclusive).toMinutes(); &#125; /** * 日期相隔毫秒数 * @param startInclusive * @param endExclusive * @return */ public static long durationMillis(Temporal startInclusive, Temporal endExclusive) &#123; return Duration.between(startInclusive, endExclusive).toMillis(); &#125; /** * 是否当天 * @param date * @return */ public static boolean isToday(LocalDate date) &#123; return getCurrentLocalDate().equals(date); &#125; public static Long toEpochMilli(LocalDateTime dateTime) &#123; return dateTime.atZone(ZoneId.systemDefault()).toInstant().toEpochMilli(); &#125;&#125; Date与LocalDate的互转 Date转LocalDate： Date date = new Date();LocalDate localDate = date.toInstant().atZone(ZoneId.systemDefault()).toLocalDate(); LocalDate 转 Date: LocalDateTime localDateTime = LocalDateTime.now();Date date = Date.from(localDateTime.toInstant(ZoneOffset.UTC)) Timestamp与LocalDate的互转 Long timestamp = LocalDateTime.now().toInstant(ZoneOffset.of(“+8”)).toEpochMilli();LocalDateTime time2 =LocalDateTime.ofEpochSecond(timestamp/1000,0,ZoneOffset.ofHours(8));","path":"2018/09/01/3165008964/","date":"09-01","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"SpringBoot 中的 Json 格式化配置","text":"springboot 针对jackson是自动化配置的，如果需要修改，有两种方式： 方式一：通过application.yml配置属性说明： spring.jackson.date-format指定日期格式，比如yyyy-MM-dd HH:mm:ss，或者具体的格式化类的全限定名。 spring.jackson.deserialization是否开启Jackson的反序列化。 spring.jackson.generator是否开启json的generators。 spring.jackson.joda-date-time-format指定Joda date/time的格式，比如(yyyy-MM-dd HH:mm:ss)。 如果没有配置的话，dateformat会作为backup。 spring.jackson.locale指定json使用的Locale。 spring.jackson.mapper是否开启Jackson通用的特性。 spring.jackson.parser是否开启jackson的parser特性。 spring.jackson.property-naming-strategy指定PropertyNamingStrategy(CAMEL_CASE_TO_LOWER_CASE_WITH_UNDERSCORES)或者指定PropertyNamingStrategy子类的全限定类名。 spring.jackson.serialization是否开启jackson的序列化。 spring.jackson.serialization-inclusion指定序列化时属性的inclusion方式，具体查看JsonInclude.Include枚举。 spring.jackson.time-zone指定日期格式化时区，比如America/Los_Angeles或者GMT+10。 spring: jackson: #日期格式化 date-format: yyyy-MM-dd HH:mm:ss serialization: #格式化输出 indent_output: true #忽略无法转换的对象 fail_on_empty_beans: false #设置空如何序列化 defaultPropertyInclusion: NON_EMPTY deserialization: #允许对象忽略json中不存在的属性 fail_on_unknown_properties: false parser: #允许出现特殊字符和转义符 allow_unquoted_control_chars: true #允许出现单引号 allow_single_quotes: true 方式二：使用重新注入ObjectMapper在配置bean中使用下面的配置 @Bean@Primary@ConditionalOnMissingBean(ObjectMapper.class)public ObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) &#123; ObjectMapper objectMapper = builder.createXmlMapper(false).build(); // 通过该方法对mapper对象进行设置，所有序列化的对象都将按改规则进行系列化 // Include.Include.ALWAYS 默认 // Include.NON_DEFAULT 属性为默认值不序列化 // Include.NON_EMPTY 属性为 空（\"\"） 或者为 NULL 都不序列化，则返回的json是没有这个字段的。这样对移动端会更省流量 // Include.NON_NULL 属性为NULL 不序列化 objectMapper.setSerializationInclusion(JsonInclude.Include.NON_EMPTY); objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); // 允许出现特殊字符和转义符 objectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true); // 允许出现单引号 objectMapper.configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true); // 字段保留，将null值转为\"\" objectMapper.getSerializerProvider().setNullValueSerializer(new JsonSerializer&lt;Object&gt;() &#123; @Override public void serialize(Object o, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException &#123; jsonGenerator.writeString(\"\"); &#125; &#125;); return objectMapper; &#125;","path":"2018/09/01/1499471298/","date":"09-01","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"Java-Jwt 工具详解","text":"JWT是什么？JWTs是JSON对象的编码表示。JSON对象由零或多个名称/值对组成，其中名称为字符串，值为任意JSON值。 JWT有助于在clear(例如在URL中)发送这样的信息，可以被信任为不可读(即加密的)、不可修改的(即签名)和URL – safe(即Base64编码的)。 JWT的定义: JWT是一种用于双方之间传递安全信息的简洁的、URL安全的表述性声明规范。 JWT作为一个开放的标准（RFC 7519），定义了一种简洁的，自包含的方法用于通信双方之间以Json对象的形式安全的传递信息。 因为数字签名的存在，这些信息是可信的，JWT可以使用HMAC算法或者是RSA的公私秘钥对进行签名。 JWT特点： 简洁(Compact): 可以通过URL，POST参数或者在HTTP header发送，因为数据量小，传输速度也很快 自包含(Self-contained)：负载中包含了所有用户所需要的信息，避免了多次查询数据库 JWT构成JWT主要包含三个部分之间用英语句号’.’隔开Header 头部Payload 负载Signature 签名注意,顺序是 header.payload.signature JWT的负载（Payload） 负载（Payload）为JWT的第二部分。JWT的标准所定义了一下几个基本字段：iss: 该JWT的签发者sub: 该JWT的使用者aud: 该JWT的接收者exp(expires): Unix时间戳 过期时间iat(issued at): Unix时间戳 签发时间 Java-Jwt中特别定义Payload nbf(not before)：Unix时间戳 生效时间jti：JwtID JWT的唯一标识kid： 返回KeyID Jwt使用三部曲添加依赖 &lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.4.0&lt;/version&gt;&lt;/dependency&gt; 生成Jwt 创建加密算法实例 HMAC256 表示加密算法 参数为加密密钥 Algorithm algorithm = Algorithm.HMAC256(\"securityKey\"); 设置Jwt负载通过withClaim 或 with 相应熟悉来设置头负载和负载 JWT.create().withClaim(\"key\", \"value\") 签名通过sign方法进行签名，需要传入加密算法实例 JWT.create().withClaim(\"key\", \"value\").sign(algorithm);// 或 JWT.create().withClaim(\"key\", \"value\").sign(Algorithm.HMAC256(\"securityKey\")); 校验Jwt 创建加密算法实例 HMAC256 表示加密算法 参数为加密密钥 Algorithm algorithm = Algorithm.HMAC256(\"securityKey\"); 创建校验器实例通过传入加密算法实例来创建校验器实例 JWTVerifier jwtVerifier = JWT.require(algorithm).build(); 在调用build()方法前可添加指定校验参数 如withSubject()方法，当sub属性值不为”user”时将抛出异常InvalidClaimException JWTVerifier jwtVerifier = JWT.require(algorithm).withSubject(\"user\").build(); 需要特别注意关于调整校验签名时间的几个方法 acceptLeeway()、acceptExpiresAt()、acceptNotBefore()、acceptIssuedAt()参数为Long类型参数，且必须是正整数，表示调整时间（单位/秒） acceptLeeway() nbf、iat 和 exp 延迟时间（单位/秒） acceptExpiresAt() exp 延迟时间（单位/秒） acceptNotBefore() nbf 延迟时间（单位/秒） acceptIssuedAt() iat 延迟时间（单位/秒） 校验签名 jwtVerifier.verify() 校验器实例方法返回解码后的结果 如果签名内容失效则会抛出SignatureVerificationException异常 当头部信息中包含iat、exp、nbf等属性时，verify()将自动进行校验。不包含的属性不进行校验。 如JWT时间失效，则会抛出TokenExpiredException异常 异常的父类为JWTVerificationException，可用于JWT失效处理。 DecodedJWT decodedJWT = jwtVerifier.verify(\"JWTString\");// 或jwtVerifier.verify(\"JWTString\"); 解码Jwt首先在调用校验方法时即可返回解码后类型为DecodedJWT的解码结果 DecodedJWT decodedJWT = jwtVerifier.verify(\"JWTString\"); 也可以使用decode()方法进行解码 DecodedJWT decodedJWT = JWT.decode(JwtResoult); 之后便可调用decodedJWT的get方法获取负载的相关内容 Claim （声明，断言的意思）中的asXXX()方法 asBoolean(): 返回 Boolean 值,如果不能转换则返回null。asInt(): 返回 Int 值,如果不能转换则返回null。asDouble(): 返回 Double 值,如果不能转换则返回null。asLong(): 返回 Long 值，如果不能转换则返回null。asString(): 返回 String值，如果不能转换则返回null。asDate(): 返回 Date值，如果不能转换则返回null。 必须是一个数字日期 (Unix 系统时间戳)。 注意，JWT标准指定所有的数字日期值必须以秒为单位。 自定义类型和集合: 要获得作为集合的声明，您需要提供要转换的内容的类类型 as(class): 返回指定类型的对象。 对于集合，应该使用asArray和asList方法。asMap(): 返回被转换为 Map&lt;String, Object&gt; 的集合asArray(class): 返回被转换为 Class [] 的数组，如果转换失败则返回null。asList(class): 返回被转换为 List 的集合，如果转换失败则返回null。 由于Java-Jwt默认使用Jackson来处理负载中的Json。所以未进行配置的Jackson可能会由于转义字符的问题而产生下面的异常。 no String-argument constructor/factory method to deserialize from String value 解决办法是使用asString()转换为字符串再使用Json工具进行转换或者配置Jackson的以下配置 允许出现特殊字符和转义符：configure(Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true); 允许出现单引号：configure(Feature.ALLOW_SINGLE_QUOTES, true);","path":"2018/09/01/3864825553/","date":"09-01","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"认证 Authentication 和授权 Authorization 的区别","text":"认证 (authentication) 基本上等于登陆，解决你是谁？的问题 授权 (authorization) 访问受保护资源的检查，解决你能干什么？的问题","path":"2018/08/29/552068435/","date":"08-29","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"SpringSecurity 中的注解使用详解","text":"启用注解模式在SpringSecurity配置类上添加@EnableGlobalMethodSecurity注解 用于启用SpringSecurity注解模式。默认SpringSecurity关闭全局注解模式 有三种注解模式，通过注解中的参数进行调配，分别是 secured JSR-250 prePost securedEnabled 注解模式启用方式： @EnableGlobalMethodSecurity(securedEnabled=ture) @Secured 可用注解： JSR-250 注解模式启用方式： @EnableGlobalMethodSecurity(jsr250Enabled=ture) RolesAllowed表示访问对应方法时所应该具有的角色。 其可以标注在类上，也可以标注在方法上，当标注在类上时表示其中所有方法的执行都需要对应的角色， 当标注在方法上表示执行该方法时所需要的角色，当方法和类上都使用了@RolesAllowed进行标注，则方法上的@RolesAllowed将覆盖类上的@RolesAllowed， 即方法上的@RolesAllowed将对当前方法起作用。@RolesAllowed的值是由角色名称组成的数组。 PermitAll表示允许所有的角色进行访问，也就是说不进行权限控制。 @PermitAll可以标注在方法上也可以标注在类上，当标注在方法上时则只对对应方法不进行权限控制，而标注在类上时表示对类里面所有的方法都不进行权限控制。 （1）当@PermitAll标注在类上，而@RolesAllowed标注在方法上时则按照@RolesAllowed将覆盖@PermitAll，即需要@RolesAllowed对应的角色才能访问。 （2）当@RolesAllowed标注在类上，而@PermitAll标注在方法上时则对应的方法也是不进行权限控制的。 （3）当在方法上同时使用了@PermitAll和@RolesAllowed时先定义的将发生作用，而都定义在类上时则是反过来的，即后定义的将发生作用（这个没多大的实际意义，实际应用中不会有这样的定义）。 DenyAll是和PermitAll相反的，表示无论什么角色都不能访问。@DenyAll只能定义在方法上。 你可能会有疑问使用@DenyAll标注的方法无论拥有什么权限都不能访问，那还定义它干啥呢？ 使用@DenyAll定义的方法只是在我们的权限控制中不能访问，脱离了权限控制还是可以访问的。 可用注解： prePostEnabled 注解模式启用方式：@EnableGlobalMethodSecurity(prePostEnabled=ture) 可用注解： @PreAuthorize 在方法调用之前,基于表达式的计算结果来限制对方法的访问 @PostAuthorize 允许方法调用,但是如果表达式计算结果为false,将抛出一个安全性异常 @PostFilter 允许方法调用,但必须按照表达式来过滤方法的结果 @PreFilter 允许方法调用,但必须在进入方法之前过滤输入值 Spring Security中定义了四个支持使用表达式的注解，分别是@PreAuthorize、@PostAuthorize、@PreFilter和@PostFilter。其中前两者可以用来在方法调用前或者调用后进行权限检查，后两者可以用来对集合类型的参数或者返回值进行过滤。 spring Security4种方法安全性的区别使用@Secured注解方法，这是spring自带的注解方法。@Secured（””）内部的字符串不具有SpEL特性，只能是具体的权限。 使用@JSR-250 @RelosAllowed注解的方法。作用和使用方法与@Secured一样，不同在于它不是spring框架的，所以可以做到和spring框架的解耦。 使用Spring方法调用前和调用后注解方法。这些方法支持SpEL。匹配一个或多个明确声明的切点方法。 Spring Security 支持的所有SpEL表达式如下： 安全表达式 计算结果 authentication() 用户认证对象 denyAll() 结果始终为false hasAnyRole(list of roles) 如果用户被授权指定的任意权限，结果为true hasRole(role) 如果用户被授予了指定的权限，结果 为true hasIpAddress(IP Adress) 用户地址 isAnonymous() 是否为匿名用户 isAuthenticated() 不是匿名用户 isFullyAuthenticated() 不是匿名也不是remember-me认证 isRemberMe() remember-me认证 permitAll() 始终true principal() 用户主要信息对象 Oauth2 安全表达式 计算结果 oauth2.hasScope() 用户授权 oauth2.hasAnyScope() 用户有任何一个授权 oauth2.hasScopeMatching() 用户授权，正则匹配 oauth2.hasAnyScopeMatching() 用户有任何一个授权，正则匹配 oauth2.clientHasRole() 客户端有任何一个角色 oauth2.clientHasAnyRole() 客户端角色 autoApprove 在调用链中设置为 true 可以跳过认证，默认为 true AuthorizationEndpoint 根据用户认证获得授权码，有下面两个方法： /oauth/authorize - GET /oauth/authorize - POST TokenEndpoint 客户端根据授权码获取 token /oauth/token - GET /oauth/token - POST CheckTokenEndpoint 可以用于远程解码令牌 /oauth/check_token WhitelabelApprovalEndpoint 显示授权服务器的确认页。 /oauth/confirm_access WhitelabelErrorEndpoint 显示授权服务器的错误页 /oauth/error 在官方的示例中，通过下面代码直接指定了视图： registry.addViewController(“/oauth/confirm_access”).setViewName(“authorize”);如果想跳过这个认证确认的过程，设置autoApprove 为true。","path":"2018/08/28/3993534631/","date":"08-28","excerpt":"","tags":[{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://yihuishou.github.io/tags/SpringSecurity/"}]},{"title":"Vue-Router 看这一篇就够了","text":"","path":"2018/08/20/3328494696/","date":"08-20","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"LocalStorage SessionStorage Cookie 的区别及用法","text":"webstoragewebstorage是本地存储，存储在客户端，包括localStorage和sessionStorage。 localStoragelocalStorage生命周期是永久，这意味着除非用户显示在浏览器提供的UI上清除localStorage信息，否则这些信息将永远存在。存放数据大小为一般为5MB,而且它仅在客户端（即浏览器）中保存，不参与和服务器的通信。sessionStoragesessionStorage仅在当前会话下有效，关闭页面或浏览器后被清除。存放数据大小为一般为5MB,而且它仅在客户端（即浏览器）中保存，不参与和服务器的通信。源生接口可以接受，亦可再次封装来对Object和Array有更好的支持。 localStorage的优势 1、localStorage拓展了cookie的4K限制 2、localStorage会可以将第一次请求的数据直接存储到本地，这个相当于一个5M大小的针对于前端页面的数据库，相比于cookie可以节约带宽，但是这个却是只有在高版本的浏览器中才支持的 localStorage的局限 1、浏览器的大小不统一，并且在IE8以上的IE版本才支持localStorage这个属性 2、目前所有的浏览器中都会把localStorage的值类型限定为string类型，这个在对我们日常比较常见的JSON对象类型需要一些转换 3、localStorage在浏览器的隐私模式下面是不可读取的 4、localStorage本质上是对字符串的读取，如果存储内容多的话会消耗内存空间，会导致页面变卡 5、localStorage不能被爬虫抓取到 localStorage与sessionStorage的唯一一点区别就是localStorage属于永久性存储，而sessionStorage属于当会话结束的时候，sessionStorage中的键值对会被清空 localStorage和sessionStorage使用时使用相同的API： localStorage.setItem(“key”,”value”);//以“key”为名称存储一个值“value” localStorage.getItem(“key”);//获取名称为“key”的值 localStorage.removeItem(“key”);//删除名称为“key”的信息。 localStorage.clear();​//清空localStorage中所有信息 作用域不同不同浏览器无法共享localStorage或sessionStorage中的信息。相同浏览器的不同页面间可以共享相同的 localStorage（页面属于相同域名和端口），但是不同页面或标签页间无法共享sessionStorage的信息。这里需要注意的是，页面及标 签页仅指顶级窗口，如果一个标签页包含多个iframe标签且他们属于同源页面，那么他们之间是可以共享sessionStorage的。 Cookie生命期为只在设置的cookie过期时间之前一直有效，即使窗口或浏览器关闭。 存放数据大小为4K左右 。有个数限制（各浏览器不同），一般不能超过20个。与服务器端通信：每次都会携带在HTTP头中，如果使用cookie保存过多数据会带来性能问题。而且源生的Cookie接口不友好，推荐使用js-cookie库来代替 cookie的优点：具有极高的扩展性和可用性 1.通过良好的编程，控制保存在cookie中的session对象的大小。2.通过加密和安全传输技术，减少cookie被破解的可能性。3.只有在cookie中存放不敏感的数据，即使被盗取也不会有很大的损失。4.控制cookie的生命期，使之不会永远有效。这样的话偷盗者很可能拿到的就 是一个过期的cookie。cookie的缺点： 1.cookie的长度和数量的限制。每个domain最多只能有20条cookie，每个cookie长度不能超过4KB。否则会被截掉。2.安全性问题。如果cookie被人拦掉了，那个人就可以获取到所有session信息。加密的话也不起什么作用。3.有些状态不可能保存在客户端。例如，为了防止重复提交表单，我们需要在服务端保存一个计数器。若吧计数器保存在客户端，则起不到什么作用。 js-cookie的用法 1、引入js-cookie.js1.直接引用cdn2.本地加载：&lt;script src=&quot;js.cookie.js&quot;&gt;&lt;/script&gt;3.模块化: npm i js-cookie import Cookies from ‘js-cookie’2、js-cookie.js常用的API和方法a、设置cookieCookies.set(‘name’, ‘value’, { expires: 7, path: ‘’ });//7天过期Cookies.set(‘name’, { foo: ‘bar’ });//设置一个jsonb、读取cookieCookies.get(‘name’);//获取cookie读取所有的cookieCookies.get();c、删除cookie删除当前页面的cookieCookies.remove(‘name’);删除cookie时必须是同一个路径。","path":"2018/08/20/2562261201/","date":"08-20","excerpt":"","tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://yihuishou.github.io/tags/JavaScript/"}]},{"title":"浏览器获取 Token 中的 Payload","text":"定义window.btoa(str) 从 String 对象中创建一个 base-64 编码的 ASCII 字符串，其中字符串中的每个字符都被视为一个二进制数据字节。 window.atob(basee64str) 对用base-64编码过的字符串进行解码。 示例： // base64 编码let encodedData = window.btoa(\"Hello, world\")// base64 解码let decodedData = window.atob(encodedData) 对于Unicode编码报：字符越界问题的解决办法封装方法示例： function utf8_to_base64( str ) &#123; return window.btoa(unescape(encodeURIComponent( str )))&#125;function base64_to_utf8( str ) &#123; return decodeURIComponent(escape(window.atob( str )))&#125;","path":"2018/08/20/958986415/","date":"08-20","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"Vuex 看这一篇就够了","text":"什么是VuexVuex 是一个专为 Vue.js 应用程序开发的状态管理模式。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。 简单来说就是用一个中央状态的仓库state来管理Vue各个组件的状态的工具。 Vuex解决了什么问题由于Vue的状态参数传递由父组件传递到子组件，子组件不能直接修改父组件的状态，需要通过$emit提交事件的方式来通知父组件更新状态。 这就导致多层嵌套组件和平行组件之前的通信变得非常复杂，而Vuex通过统一的中心状态仓库解决了这个问题。 Vuex的使用挂载 Vuex下面是store/index.js index.js为固定的名称，这样可以在使用import语句时直接这样使用import store from &#39;./store/&#39; store目录名则是为了在main.js中实例化Vue时可以使用缩写。 例如下面的main.js中挂载Vuex实例 new Vue(&#123; el: &apos;#app&apos;, store, &lt;!-- 等效于 store:store --&gt;&#125;) store/index.js 中配置Vuex import Vue from 'vue'import Vuex from 'vuex'Vue.use(vuex)export default new Vuex.Store(&#123; modules: &#123; &#125;, state: &#123; &#125;, mutations: &#123; &#125;, actions: &#123; &#125;, getters&#125;) 状态 state通过this.$store.state来获取在Store实例中state属性定义的状态信息 例如获取 count 的值： this.$store.state.count 通常用于组件的computed属性来更新页面上的信息,例如下面 &lt;tempale&gt;&lt;div&gt;&#123;&#123;count&#125;&#125;&lt;div&gt;&lt;temaple/&gt;&lt;script&gt;export default&#123;&lt;!-- 省略部分代码 --&gt;computed: &#123; count() &#123; return this.$store.state.count &#125; &#125;&#125;&lt;script/&gt; 计算状态 getter如果想通过获取的仓库中的某些状态来计算出一个新的状态，则应该使用getter计算状态。 通过 this.$store.getters来获取在Store实例中getters属性定义的状态计算属性 例如获取通过状态计算得到的 calculateCount 的值： &lt;tempale&gt;&lt;div&gt;&#123;&#123;calculateCount&#125;&#125;&lt;div&gt;&lt;temaple/&gt;&lt;script&gt;export default&#123;computed: &#123; calculateCount () &#123; return this.$store.getters.calculateCount &#125;&#125;&lt;!-- 下面是没有使用getter的代码computed: &#123; calculateCount () &#123; return this.$store.state.count.filter(count =&gt; count.done).length &#125; &#125;&#125; --&gt;&lt;script/&gt; 下面是定义在getters中的状态计算属性calculateCount 每一个定义的 getters 可以接受两个参数 state 和 getters export default new Vuex.Store(&#123;&lt;!-- 省略部分代码 --&gt; getters: &#123; calculateCount: (state, getters) =&gt; &#123; return state.count.filter(count =&gt; count.done) &#125; &#125;&#125;) 变化 mutationstate 和 getter 只能获取store中的状态和计算状态，要想改变store中的state就需要使用mutation。 通过 this.$store.commit来更改stroe中的state commit命令有两种提交方式: 1.外置声明提交 声明第一个参数为mutation类型名称，第二个参数为向mutation中传入的参数对象来进行提交(也可以使用变量，通常使用对象) this.$store.commit(&#39;mutation类型名称&#39;,{amount:100}) 2.内置声明提交 使用一个必须包含type属性的对象来进行提交，其他参数也可以包含在该对象中 this.$store.commit({type:mutation类型名称,amount:100}) 下面是定义在mutations中的类型为mutations的变化 export default new Vuex.Store(&#123;&lt;!-- 省略部分代码 --&gt; mutations: &#123; increment: (state, parms) =&gt; &#123; state.count + parms.amount &#125; &#125;&#125;) mutations 需要注意的事情 最好初始化相关的state 替换或追加属性最好使用ES6的...对象展开符 例如： state.obj = &#123; ...state.obj, newProp: 123 &#125; 使用常量来定义mutations类型名称，便于更改和维护，尤其是在大项项目中。 例如： 定义在 mutation-types.js 中的mutations类型常量export const SOME_MUTATION = &#39;SOME_MUTATION&#39; import Vuex from 'vuex'import &#123; SOME_MUTATION &#125; from './mutation-types'export default new Vuex.Store(&#123;&lt;!-- 省略部分代码 --&gt; mutations: &#123; SOME_MUTATION: (state, parms) =&gt; &#123; state.count + parms.amount &#125; &#125;&#125;) 动作 action由于mutation只能执行同步操作，当使用Ajax进行操作的时候就不行了这个时候就该action出场了。action没有只能执行同步操作的限制。 定义一个名为increment的action，它会执行类型名为someMutations的mutation。 action的基本流程是： 通过$store.dispath() 触发action 然后再由 action 内执行 commit 来修改state import Vuex from 'vuex'export default new Vuex.Store(&#123;&lt;!-- 省略部分代码 --&gt; actions: &#123; increment : (context) =&gt; &#123; context.commit('someMutations') &#125; &#125;&#125;) 定义的action接受一个参数，该参数与 store 实例具有相同方法和属性的 context 对象，这样就可以通过context对象来获取store实例中的内容。例如: context.state 等效于 $store.statecontext.mutations 等效于 $store.mutationscontext.getters 等效于 $store.getterscontext.commit 等效于 $store.commit 由于通常会通过commit提交mutation来修改store的state，可以通过ES6的解构赋值来进行简写。也就是说下面commit的提交： import Vuex from 'vuex'export default new Vuex.Store(&#123;&lt;!-- 省略部分代码 --&gt; actions: &#123; increment : (context) =&gt; &#123; context.commit('someMutations') &#125; &#125;&#125;) 可以被简写为 import Vuex from 'vuex'export default new Vuex.Store(&#123;&lt;!-- 省略部分代码 --&gt; actions: &#123; increment : (&#123;commit&#125;) =&gt; &#123; commit('someMutations') &#125; &#125;&#125;) 通过 this.$store.dispath来触发stroe中的action 和mutation一样，触发action也有两种触发方式： 1.外置声明触发 声明第一个参数为action类型名称，第二个参数为向action中传入的参数对象来进行提交(也可以使用变量，通常使用对象) this.$store.dispath(&#39;action名称&#39;,{amount:100}) 2.内置声明触发 使用一个必须包含type属性的对象来进行提交，其他参数也可以包含在该对象中 this.$store.dispath({type:action名称,amount:100}) 辅助函数Vuex提供了4个辅助函数配合ES6的扩展运算符来实现函数映射。 mapState、mapGetters、mapMutations、mapActions mapState mapState()函数可以接受一个对象或者一个字符串数组来进行映射，它返回一个包含尤其生成的computed属性的对象， 这样就可以不必在computed 中自行定义属性了 对象参数映射： computed: mapState({ count: state =&gt; state.count }) 映射为 computed: { count () { return this.$store.state.count }} 对象字符串参数映射： computed: mapState({ countAlias: ‘count’ }) 映射为 computed: { countAlias () { return this.$store.state.count }} 字符串数组映射,(需要计算属性名与state属性名相同)： computed: mapState([ ‘count’ ]) 映射为 computed: { count () { return this.$store.state.count }} 映射函数： computed: mapState({ countPlusLocalState (state) { return state.count + this.localCount } }) 映射为 computed: { countPlusLocalState () { return state.count + this.localCount }} mapGetters mapMutations mapActions 模块化 model","path":"2018/08/17/3032275019/","date":"08-17","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"Vue 的数据操作总结","text":"数组一）ES 3.0 改变原数组 push:在数组尾开始插入一个或多个元素，并且返回对应长度的数组。 pop:把数组最后一位剪切出来，并且返回。 shift:和pop相反，它是把数组的第一位剪切出来，并且返回。 unshift :在数组前面添加一个或多个元素，和push反过来使用。 reverse:在原数组上进行反转。 splice: 在数组中截取元素，也可以在截取处添加新元素。 sort: 数组排序。按阿斯克码排序。 copyWithin： 在当前数组内部，将制定位置的数组复制到其他位置，会覆盖原数组项，返回当前数组。 不改变原数组 cocat:连接2个数组的方法,返回新数组。 toString : 把数组变成字符串展示出来。 slice:再数组中截取出所需的元素 join： 把数组中的每一位根据你传的参数连接起来，形成一个字符串 split：字符串的方法，按传进来的参数拆成数组，和join相反。 二）ES 5.0 改变原数组 无 不改变原数组 indexOf/lastIndexOf 用于查找数组内指定元素位置，查找到第一个后返回其索引，没有查找到返回-1；indexOf()从头至尾搜索；lastIndexOf()则反向搜索； forEach 从头到尾遍历数组，为每个元素调用指定函数第一个参数：传递的函数该函数调用的参数：数组元素、元素索引、数组本身 map 调用数组的每个元素传递给指定的函数，并返回一个包含返回值的新数组；传递给map()的函数有返回值，map()返回新数组，不会修改调用的数组；如果是稀疏数组，返回的也是相同方式的稀疏数组。 ps: arr.forEach()和arr.map()的区别 arr.forEach()是和for循环一样，是代替for。arr.map()是修改数组其中的数据，并返回新的数据。 arr.forEach() 没有return arr.map() 有return filter 返回数组的一个子集，回调函数用于逻辑判断是否返回，返回true则把当前元素加入到返回数组中，false则不加；新数组只包含返回true的值，索引缺失的不包括，原数组保持不变。 some/every every是“所有”函数的每个回调函数都返回true的时候才会返回true，当遇到false的时候终止执行，返回false；some函数是“存在”有一个回调函数返回true的时候终止执行并返回true，否则返回false； 在空数组上调用every返回true，some返回false。 every()：该方法对数组中的每一项运行给定函数，如果该函数对每一项都返回 true，则返回true。 some()： 该方法对数组中的每一项运行给定函数，如果该函数对任何一项返回 true，则返回true。 reduce/reduceRight 使用指定的函数将数组元素进行组合，生成单个值参数：1、执行化简操作的函数；2、（可选）参数是传递给函数的初始值reduce从索引最小值开始，reduceRight反向 三）ES 6.0 改变原数组 fill 方法用一个固定值填充一个数组中从起始索引到终止索引内的全部元素。不包括终止索引。 不改变原数组 includes 方法用来判断一个数组是否包含一个指定的值，根据情况，如果包含则返回 true，否则返回false。 find/findIndex 返回数组中满足提供的测试函数的第一个元素的值/索引。否则返回 undefined。 from 将伪数组变成数组，就是只要有length的就可以转成数组。 对象","path":"2018/08/15/1649551711/","date":"08-15","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"JVM 调优基本垃圾回收","text":"数据类型 Java虚拟机中，数据类型可以分为两类：基本类型和引用类型。基本类型的变量保存原始值，即：他代表的值就是数值本身；而引用类型的变量保存引用值。“引用值”代表了某个对象的引用，而不是对象本身，对象本身存放在这个引用值所表示的地址的位置。 基本类型包括：byte,short,int,long,char,float,double,Boolean,returnAddress 引用类型包括：类类型，接口类型和数组。 堆与栈 堆和栈是程序运行的关键，很有必要把他们的关系说清楚。 栈是运行时的单位，而堆是存储的单位。 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储的问题，即数据怎么放、放在哪儿。 在Java中一个线程就会相应有一个线程栈与之对应，这点很容易理解，因为不同的线程执行逻辑有所不同，因此需要一个独立的线程栈。而堆则是所有线程共享的。栈因为是运行单位，因此里面存储的信息都是跟当前线程（或程序）相关信息的。包括局部变量、程序运行状态、方法返回值等等；而堆只负责存储对象信息。 为什么要把堆和栈区分出来呢？栈中不是也可以存储数据吗？ 第一，从软件设计的角度看，栈代表了处理逻辑，而堆代表了数据。这样分开，使得处理逻辑更为清晰。分而治之的思想。这种隔离、模块化的思想在软件设计的方方面面都有体现。 第二，堆与栈的分离，使得堆中的内容可以被多个栈共享（也可以理解为多个线程访问同一个对象）。这种共享的收益是很多的。一方面这种共享提供了一种有效的数据交互方式(如：共享内存)，另一方面，堆中的共享常量和缓存可以被所有栈访问，节省了空间。 第三，栈因为运行时的需要，比如保存系统运行的上下文，需要进行地址段的划分。由于栈只能向上增长，因此就会限制住栈存储内容的能力。而堆不同，堆中的对象是可以根据需要动态增长的，因此栈和堆的拆分，使得动态增长成为可能，相应栈中只需记录堆中的一个地址即可。 第四，面向对象就是堆和栈的完美结合。其实，面向对象方式的程序与以前结构化的程序在执行上没有任何区别。但是，面向对象的引入，使得对待问题的思考方式发生了改变，而更接近于自然方式的思考。当我们把对象拆开，你会发现，对象的属性其实就是数据，存放在堆中；而对象的行为（方法），就是运行逻辑，放在栈中。我们在编写对象的时候，其实即编写了数据结构，也编写的处理数据的逻辑。不得不承认，面向对象的设计，确实很美。 在Java中，Main函数就是栈的起始点，也是程序的起始点。 程序要运行总是有一个起点的。同C语言一样，java中的Main就是那个起点。无论什么java程序，找到main就找到了程序执行的入口：） 堆中存什么？栈中存什么？ 堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用。一个对象的大小是不可估计的，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4btye的引用（堆栈分离的好处）。 为什么不把基本类型放堆中呢？因为其占用的空间一般是1~8个字节——需要空间比较少，而且因为是基本类型，所以不会出现动态增长的情况——长度固定，因此栈中存储就够了，如果把他存在堆中是没有什么意义的（还会浪费空间，后面说明）。可以这么说，基本类型和对象的引用都是存放在栈中，而且都是几个字节的一个数，因此在程序运行时，他们的处理方式是统一的。但是基本类型、对象引用和对象本身就有所区别了，因为一个是栈中的数据一个是堆中的数据。最常见的一个问题就是，Java中参数传递时的问题。 Java中的参数传递时传值呢？还是传引用？ 要说明这个问题，先要明确两点： 不要试图与C进行类比，Java中没有指针的概念。 程序运行永远都是在栈中进行的，因而参数传递时，只存在传递基本类型和对象引用的问题。不会直接传对象本身。 明确以上两点后。Java在方法调用传递参数时，因为没有指针，所以它都是进行传值调用（这点可以参考C的传值调用）。因此，很多书里面都说Java是进行传值调用，这点没有问题，而且也简化的C中复杂性。 但是传引用的错觉是如何造成的呢？在运行栈中，基本类型和引用的处理是一样的，都是传值，所以，如果是传引用的方法调用，也同时可以理解为“传引用值”的传值调用，即引用的处理跟基本类型是完全一样的。但是当进入被调用方法时，被传递的这个引用的值，被程序解释（或者查找）到堆中的对象，这个时候才对应到真正的对象。如果此时进行修改，修改的是引用对应的对象，而不是引用本身，即：修改的是堆中的数据。所以这个修改是可以保持的了。 对象，从某种意义上说，是由基本类型组成的。可以把一个对象看作为一棵树，对象的属性如果还是对象，则还是一颗树（即非叶子节点），基本类型则为树的叶子节点。程序参数传递时，被传递的值本身都是不能进行修改的，但是，如果这个值是一个非叶子节点（即一个对象引用），则可以修改这个节点下面的所有内容。 堆和栈中，栈是程序运行最根本的东西。程序运行可以没有堆，但是不能没有栈。而堆是为栈进行数据存储服务，说白了堆就是一块共享的内存。不过，正是因为堆和栈的分离的思想，才使得Java的垃圾回收成为可能。 Java中，栈的大小通过-Xss来设置，当栈中存储数据比较多时，需要适当调大这个值，否则会出现java.lang.StackOverflowError异常。常见的出现这个异常的是无法返回的递归，因为此时栈中保存的信息都是方法返回的记录点。 Java对象的大小 基本数据的类型的大小是固定的，这里就不多说了。对于非基本类型的Java对象，其大小就值得商榷。下面的描述基于32位的Oracle HotSpot JVM。 在Java中，一个空Object对象的大小是8byte，这个大小只是保存堆中一个没有任何属性的对象的大小。看下面语句： Object ob = new Object(); 这样在程序中完成了一个Java对象的生命，但是它所占的空间为：4byte+8byte。4byte是上面部分所说的Java栈中保存引用的所需要的空间。而那8byte则是Java堆中对象的信息。因为所有的Java非基本类型的对象都需要默认继承Object对象，因此不论什么样的Java对象，其大小都必须是大于8byte。 有了Object对象的大小，我们就可以计算其他对象的大小了。 Class NewObject &#123; int count; boolean flag; Object ob; &#125; 其大小为：空对象大小(8byte)+int大小(4byte)+Boolean大小(1byte)+空Object引用的大小(4byte)=17byte。但是因为Java在对对象内存分配时都是以8的整数倍来分，因此大于17byte的最接近8的整数倍的是24，因此此对象的大小为24byte。 这里需要注意一下基本类型的包装类型的大小。因为这种包装类型已经成为对象了，因此需要把他们作为对象来看待。包装类型的大小至少是12byte（声明一个空Object至少需要的空间），而且12byte没有包含任何有效信息，同时，因为Java对象大小是8的整数倍，因此一个基本类型包装类的大小至少是16byte。这个内存占用是很恐怖的，它是使用基本类型的N倍（N&gt;2），有些类型的内存占用更是夸张（随便想下就知道了）。因此，可能的话应尽量少使用包装类。在JDK5.0以后，因为加入了自动类型装换，因此，Java虚拟机会在存储方面进行相应的优化。 引用类型 对象引用类型分为强引用、软引用、弱引用和虚引用。 强引用：就是我们一般声明对象是时虚拟机生成的引用，强引用环境下，垃圾回收时需要严格判断当前对象是否被强引用，如果被强引用，则不会被垃圾回收。 软引用：软引用一般被做为缓存来使用。与强引用的区别是，软引用在垃圾回收时，虚拟机会根据当前系统的剩余内存来决定是否对软引用进行回收。如果剩余内存比较紧张，则虚拟机会回收软引用所引用的空间；如果剩余内存相对富裕，则不会进行回收。换句话说，虚拟机在发生OutOfMemory时，肯定是没有软引用存在的。 弱引用：弱引用与软引用类似，都是作为缓存来使用。但与软引用不同，弱引用在进行垃圾回收时，是一定会被回收掉的，因此其生命周期只存在于一个垃圾回收周期内。 强引用不用说，我们系统一般在使用时都是用的强引用。而“软引用”和“弱引用”比较少见。他们一般被作为缓存使用，而且一般是在内存大小比较受限的情况下做为缓存。因为如果内存足够大的话，可以直接使用强引用作为缓存即可，同时可控性更高。因而，他们常见的是被使用在桌面应用系统的缓存。 下面讲基本的垃圾回收算法。可以从不同的的角度去划分垃圾回收算法。 按照基本回收策略分 引用计数（Reference Counting）: 比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。此算法最致命的是无法处理循环引用的问题。 标记-清除（Mark-Sweep）: 图2 标记-清除策略 此算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。此算法需要暂停整个应用，同时，会产生内存碎片。 复制（Copying）: 图3 复制策略 此算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。此算法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。当然，此算法的缺点也是很明显的，就是需要两倍内存空间。 标记-压缩（Mark-Compact）: 图4 标记-压缩策略 此算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。 按分区对待的方式分 增量收集（Incremental Collecting）：实时垃圾回收算法，即：在应用进行的同时进行垃圾回收。不知道什么原因JDK5.0中的收集器没有使用这种算法的。 分代收集（Generational Collecting）：基于对对象生命周期分析后得出的垃圾回收算法。把对象分为年青代、年老代、持久代，对不同生命周期的对象使用不同的算法（上述方式中的一个）进行回收。现在的垃圾回收器（从J2SE1.2开始）都是使用此算法的。 按系统线程分 串行收集：串行收集使用单线程处理所有垃圾回收工作，因为无需多线程交互，实现容易，而且效率比较高。但是，其局限性也比较明显，即无法使用多处理器的优势，所以此收集适合单处理器机器。当然，此收集器也可以用在小数据量（100M左右）情况下的多处理器机器上。 并行收集：并行收集使用多线程处理垃圾回收工作，因而速度快，效率高。而且理论上CPU数目越多，越能体现出并行收集器的优势。 并发收集：相对于串行收集和并行收集而言，前面两个在进行垃圾回收工作时，需要暂停整个运行环境，而只有垃圾回收程序在运行，因此，系统在垃圾回收时会有明显的暂停，而且暂停时间会因为堆越大而越长。并发收集则是应用程序与垃圾收集并发地进行，应用程序不会暂停。 如何区分垃圾 上面说到的“引用计数”法，通过统计控制生成对象和删除对象时的引用数来判断。垃圾回收程序收集计数为0的对象即可。但是这种方法无法解决循环引用。所以，后来实现的垃圾判断算法中，都是从程序运行的根节点出发，遍历整个对象引用，查找存活的对象。那么在这种方式的实现中，垃圾回收从哪儿开始的呢？即，从哪儿开始查找哪些对象是正在被当前系统使用的。上面分析的堆和栈的区别，其中栈是真正进行程序执行地方，所以要获取哪些对象正在被使用，则需要从Java栈开始。同时，一个栈是与一个线程对应的，因此，如果有多个线程的话，则必须对这些线程对应的所有的栈进行检查。 同时，除了栈外，还有系统运行时的寄存器等，也是存储程序运行数据的。这样，以栈或寄存器中的引用为起点，我们可以找到堆中的对象，又从这些对象找到对堆中其他对象的引用，这种引用逐步扩展，最终以null引用或者基本类型结束，这样就形成了一颗以Java栈中引用所对应的对象为根节点的一颗对象树，如果栈中有多个引用，则最终会形成多颗对象树。在这些对象树上的对象，都是当前系统运行所需要的对象，不能被垃圾回收。而其他剩余对象，则可以视为无法被引用到的对象，可以被当做垃圾进行回收。 因此，垃圾回收的起点是一些根对象（java栈, 静态变量, 寄存器…），而最简单的Java栈就是Java程序执行的main函数。这种回收方式，也是上面提到的“标记-清除”的回收方式。 如何处理碎片 由于不同Java对象存活时间是不一定的，因此，在程序运行一段时间以后，如果不进行内存整理，就会出现零散的内存碎片。碎片最直接的问题就是会导致无法分配大块的内存空间，以及程序运行效率降低。所以，在上面提到的基本垃圾回收算法中，“复制”方式和“标记-整理”方式，都可以解决碎片的问题。 如何解决同时存在的对象创建和对象回收问题 垃圾回收线程是回收内存的，而程序运行线程则是消耗（或分配）内存的，一个回收内存，一个分配内存，从这点看，两者是矛盾的。因此，在现有的垃圾回收方式中，要进行垃圾回收前，一般都需要暂停整个应用（即：暂停内存的分配），然后进行垃圾回收，回收完成后再继续应用。这种实现方式是最直接，而且最有效的解决二者矛盾的方式。 但是这种方式有一个很明显的弊端，就是当堆空间持续增大时，垃圾回收的时间也将会相应的持续增大，对应应用暂停的时间也会相应的增大。一些对相应时间要求很高的应用，比如最大暂停时间要求是几百毫秒，那么当堆空间大于几个G时，就很有可能超过这个限制，在这种情况下，垃圾回收将会成为系统运行的一个瓶颈。为解决这种矛盾，有了并发垃圾回收算法，使用这种算法，垃圾回收线程与程序运行线程同时运行。在这种方式下，解决了暂停的问题，但是因为需要在新生成对象的同时又要回收对象，算法复杂性会大大增加，系统的处理能力也会相应降低，同时，“碎片”问题将会比较难解决。 为什么要分代 分代的垃圾回收策略，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。 在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。 试想，在不进行对象存活时间区分的情况下，每次垃圾回收都是对整个堆空间进行回收，花费时间相对会长，同时，因为每次回收都需要遍历所有存活对象，但实际上，对于生命周期长的对象而言，这种遍历是没有效果的，因为可能进行了很多次遍历，但是他们依旧存在。因此，分代垃圾回收采用分治的思想，进行代的划分，把不同生命周期的对象放在不同代上，不同代上采用最适合它的垃圾回收方式进行回收。 如何分代 如图所示： 虚拟机中的共划分为三个代：年轻代（Young Generation）、年老代（Old Generation）和持久代（Permanent Generation）。其中持久代主要存放的是Java类的类信息，与垃圾收集要收集的Java对象关系不大。年轻代和年老代的划分是对垃圾收集影响比较大的。 年轻代: 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分三个区。一个Eden区，两个Survivor区(一般而言)。大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到Survivor区（两个中的一个），当这个Survivor区满时，此区的存活对象将被复制到另外一个Survivor区，当这个Survivor去也满了的时候，从第一个Survivor区复制过来的并且此时还存活的对象，将被复制“年老区(Tenured)”。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来对象，和从前一个Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。同时，根据程序需要，Survivor区是可以配置为多个的（多于两个），这样可以增加对象在年轻代中的存在时间，减少被放到年老代的可能。 年老代: 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 持久代: 用于存放静态文件，如今Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代大小通过-XX:MaxPermSize=进行设置。 什么情况下触发垃圾回收 由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。 Scavenge GC 一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。 Full GC 对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个对进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。有如下原因可能导致Full GC： · 年老代（Tenured）被写满 · 持久代（Perm）被写满 · System.gc()被显示调用 ·上一次GC之后Heap的各域分配策略动态变化 选择合适的垃圾收集算法 串行收集器 用单线程处理所有垃圾回收工作，因为无需多线程交互，所以效率比较高。但是，也无法使用多处理器的优势，所以此收集器适合单处理器机器。当然，此收集器也可以用在小数据量（100M左右）情况下的多处理器机器上。可以使用-XX:+UseSerialGC打开。 并行收集器 对年轻代进行并行垃圾回收，因此可以减少垃圾回收时间。一般在多线程多处理器机器上使用。使用-XX:+UseParallelGC.打开。并行收集器在J2SE5.0第6更新上引入，在Java SE6.0中进行了增强－－－可以对年老代进行并行收集。如果年老代不使用并发收集的话，默认是使用单线程进行垃圾回收，因此会制约扩展能力。使用-XX:+UseParallelOldGC打开。 使用-XX:ParallelGCThreads=设置并行垃圾回收的线程数。此值可以设置与机器处理器数量相等。 此收集器可以进行如下配置： 最大垃圾回收暂停：指定垃圾回收时的最长暂停时间，通过-XX:MaxGCPauseMillis=指定。为毫秒。如果指定了此值的话，堆大小和垃圾回收相关参数会进行调整以达到指定值。设定此值可能会减少应用的吞吐量。 吞吐量：吞吐量为垃圾回收时间与非垃圾回收时间的比值，通过-XX:GCTimeRatio=来设定，公式为1/（1+N）。例如，-XX:GCTimeRatio=19时，表示5%的时间用于垃圾回收。默认情况为99，即1%的时间用于垃圾回收。 并发收集器 可以保证大部分工作都并发进行（应用不停止），垃圾回收只暂停很少的时间，此收集器适合对响应时间要求比较高的中、大规模应用。使用-XX:+UseConcMarkSweepGC打开。 图10 并发收集器 并发收集器主要减少年老代的暂停时间，他在应用不停止的情况下使用独立的垃圾回收线程，跟踪可达对象。在每个年老代垃圾回收周期中，在收集初期并发收集器会对整个应用进行简短的暂停，在收集中还会再暂停一次。第二次暂停会比第一次稍长，在此过程中多个线程同时进行垃圾回收工作。 并发收集器使用处理器换来短暂的停顿时间。在一个N个处理器的系统上，并发收集部分使用K/N个可用处理器进行回收，一般情况下1&lt;=K&lt;=N/4。 在只有一个处理器的主机上使用并发收集器，设置为incremental mode模式也可获得较短的停顿时间。 浮动垃圾：由于在应用运行的同时进行垃圾回收，所以有些垃圾可能在垃圾回收进行完成时产生，这样就造成了“Floating Garbage”，这些垃圾需要在下次垃圾回收周期时才能回收掉。所以，并发收集器一般需要20%的预留空间用于这些浮动垃圾。 Concurrent Mode Failure：并发收集器在应用运行时进行收集，所以需要保证堆在垃圾回收的这段时间有足够的空间供程序使用，否则，垃圾回收还未完成，堆空间先满了。这种情况下将会发生“并发模式失败”，此时整个应用将会暂停，进行垃圾回收。 启动并发收集器：因为并发收集在应用运行时进行收集，所以必须保证收集完成之前有足够的内存空间供程序使用，否则会出现“Concurrent Mode Failure”。通过设置-XX:CMSInitiatingOccupancyFraction=指定还有多少剩余堆时开始执行并发收集。 小结 串行处理器： –适用情况：数据量比较小（100M左右）；单处理器下并且对响应时间无要求的应用。–缺点：只能用于小型应用 并行处理器： –适用情况：“对吞吐量有高要求”，多CPU、对应用响应时间无要求的中、大型应用。举例：后台处理、科学计算。–缺点：垃圾收集过程中应用响应时间可能加长 并发处理器： –适用情况：“对响应时间有高要求”，多CPU、对应用响应时间有较高要求的中、大型应用。举例：Web服务器/应用服务器、电信交换、集成开发环境。","path":"2018/06/05/167649745/","date":"06-05","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"微服务与单体应用的故事","text":"一个单体应用程序，通俗来说就是应用程序的全部功能被一起打包作为单个单元或应用程序。 这个单元可以是JAR、WAR、EAR，或其他一些归档格式，但其全部集成在一个单一的单元。 例如在线购物网站通常会包括客户、产品、目录、结帐等功能。 另一个例子是如下的movieplex。这样的应用程序通常由节目预订、添加/删除的电影、票房收入、电影起租点和其他功能组成。在单体应用程序的情况下，所有这些功能的实现和打包在一起作为一个应用程序。 Movieplex7就是这样一个典型的Java EE7的示例应用程序和主要特点如下： 图片描述当作为一个WAR打包这个应用程序将是这样的： 图片描述 归档包括形成用户界面的一些网页。实现业务逻辑、持久层、后台支持层等类结构，最后还有数据库连接定义，CDI配置等一些配置文件。 更具体地，WAR的结构如下： 图片描述 在这WAR文件结构中，网页在绿色框内，所有的类都是橙色框内，配置文件是蓝色的框内。这个应用程序有点模块化实现，因为包内所有的类都通过不同的功能井然有序的被组织。网页和配置文件也遵循类似的模式。 单体应用程序的优点 这种类型应用程序有如下的一些优点: 众所周知的：这是当前的典型应用架构。它很容易概念化，所有的代码是在一个地方。现有的大部分工具、应用服务器、框架和脚本都是这种应用程序。IDE友好: 大多数开发环境，像NetBeans、Eclipse、IntelliJ这些开发环境都是针对开发、部署、调试这样的单个应用而设计的。方便单步跟踪代码，因为所有的代码都是在一起的。便于共享: 单个归档文件包含所有功能，便于在团队之间以及不同的部署阶段之间共享。易于测试: 单体应用一旦部署，所有的服务或特性就都可以使用了，这简化了测试过程，因为没有额外的依赖，每项测试都可以在部署完成后立刻开始。容易部署: 非常便于部署，典型来说只需将单个归档文件复制到单个目录下即可。单体应用缺陷 目前为止，单体应用已经很好地服务了我们，未来无疑还会继续发挥重要作用。这里还有像Etsy这样的网站单月访问用户数达到六千万以及15亿页面访问量，也是基于一个大的单体应用构建部署的。他们把单体应用发挥到了极致，他们会每天部署一个庞大的单体应用多达50次。可惜的是，大多数公司不是这样的。 但是，不管如何模块化，单体应用最终都会因为团队壮大、成员变动、应用范围扩展等出现问题。部署和维护任何一个跨越多年、多团队的单体应用程序的代码库就像是充满bug的泥潭。软件就是这么发展的，尤其是当你面临交付压力时。 下面让我们来看看单体应用的一些劣势所在： 不够灵活: 对应用程序做任何细微的修改都需要将整个应用程序重新构建、重新部署。考虑到某些用户案例，只有某个功能的极少部分需要更新，例如：增加/删除电影。这也将导致整个应用程序被重新编译和部署，即使其他部分都没有任何改动。这就意味着开发人员需要等到整个应用程序部署完成后才能看到变化。如果多个开发人员共同开发一个应用程序，那么还要等待其他开发人员完成了各自的开发。这降低了团队的灵活性和功能交付频率。妨碍持续交付: 单体应用可能会比较大，构建和部署时间也相应地比较长，假如任一改动都会导致程序需要被重新编译部署的话，不利于频繁部署，阻碍持续交付。在实际的移动应用开发中，用户总是不停期待最新最cool的功能，这个问题会显得尤为严重。受技术栈限制: 对于这类应用，技术是在开发之前经过慎重评估后选定的，每个团队成员都必须使用相同的开发语言、持久化存储及消息系统，而且要使用类似的工具，无法根据具体的场景做出其它选择。但是这就像在圆孔里装方钉。 MySQL是否是适合的图形存储数据库？是否Java是构建前端互动应用的最合适的语言？它通常不可能在没有放弃或显著重写部分现有应用程序之前改变技术堆栈主线。技术债务: “不坏不修（Not broken，don’t fix）”，这在软件开发中非常常见，单体应用尤其如此。系统设计或写好的代码难以修改，因为应用程序的其它部分可能会以意料之外的方式使用它。随着时间推移、人员更迭，这必然会增加应用程序的技术债务。通常这样的应用程序在历经数年之后，维护和创建代码库的已经是完全不同的团队，这提高了应用程序的技术债务，使得它以后更难被重构。什么是微服务? 而随着业务需求的快速发展变化，敏捷性、灵活性和可扩展性需求不断增长，迫切需要一种更加快速高效的软件交付方式。 进一步认识微服务! 微服务就是一种可以满足这种需求的软件架构风格。单体应用被分解成多个更小的服务，每个服务有自己的归档文件，单独部署，然后共同组成一个应用程序。这里的“微”不是针对代码行数而言，而是说服务的范围限定到单个功能。 我们都一直在使用微服务几年了。 想想一个简单的移动应用程序可以告诉你酒店的收视率，找出你所在目的地的天气，预订酒店，找到到酒店的方向，找到附近的餐厅，等等。这些应用程序有可能使用不同的服务，如Yelp的，谷歌地图，雅虎天气API等来完成这些任务。每个功能都能够有效地运行作为一个独立的服务，并在这个单一的移动应用程序组织在一起。移动应用的爆炸，以及它们不断增长的业务需求的支持也被Forrester的四层综合平台所强调，并且服务也是一个关键组成部分。 让我们看看什么是微服务基于应用的特性。 微服务的特征 让我们看看使用微服务构建的应用程序的特征。 领域驱动设计: 应用程序功能分解可以通过Eric Evans在《领域驱动设计》中明确定义的规则实现，领域驱动设计不是分解应用程序的唯一方法，但肯定是很常用的一种；每个团队负责与一个领域或业务功能相关的全部开发；团队遵循全栈开发方法拥有全系列的开发人员，具备用户界面、业务逻辑和持久化存储等方面的开发技能。单一职责原则: 每个服务应该负责该功能的一个单独的部分，这是SOLID原则之一，Unix工具程序很好地证明这一原则的重要性。明确发布接口: 每个服务都会发布一个定义明确的接口，而且保持不变；服务消费者只关心接口，而对于被消费的服务没有任何运行依赖；服务之间就业务模型、API、负载或其他契约达成一致并使用符合契约的方式进行通信。接口可能会产生新版本，但接口的老版本可以继续使用，且新服务保持后续兼容。不可以通过改变契约破坏兼容性。独立部署、升级、扩展和替换: 每个服务都可以单独部署及重新部署而不影响整个系统。这使得服务很容易升级，例如增加更多的功能点。每个服务都可以沿着《Art of Scalability》一书定义的X轴（水平复制）和Z轴（面向查询的分割，数据分区）进行独立扩展；由于其他服务仅依赖发布的接口，只要发布相同的契约，服务实现甚至是底层技术栈都可以修改。可以异构/采用多种语言: 每个服务的实现细节都与其它服务无关，这使得服务之间能够解耦，团队可以针对每个服务选择最合适的开发语言、持久化存储、工具和方法；一个需要在关系型数据库存储数据的服务可以选择MySQL，另一个需要存储文档的服务可以选择MongoDB。不同的团队可以根据自己的需求选择Java EE、NodeJS、Python、Vert.x或其他对本团队最有效的技术。轻量级通信: 服务通信使用轻量级的通信协议，例如在HTTP上承载的REST。由于REST本质是同步的，可能会有某些潜在的瓶颈。另一个可选机制是使用支持异步消息的发布/订阅机制。任何符合需求的消息协议，例如AMQP、STOMP、MQTT或WebSocket，都可以使用。简单消息实现，例如ActiveMQ，提供了可靠的异步组构尤其适用于这种用途。每个开发团队可以根据服务的具体需求对同步还是异步消息做适宜的选择，当然也可以混用。类似的，不同的服务会选择特别的协议，但是团队创建服务时仍然保有极大的自由度和独立性。Netflix是微服务的一个典型应用，这里有几篇文章介绍他们对微服务的应用。对于他们架构中微服务应用影响的更广泛的介绍在这里netflix.github.io. 微服务的优点 易于开发、理解和维护: 微服务中的代码仅限于业务的某一功能，因此更易于理解。IDE可以很轻松加载小的代码库，且使开发者保持高效。比单体应用启动快: 微服务的范围比单体应用小得多，应此会有较小的打包文件。其结果就是，更快的部署和启动使开发者保持高效。局部修改很容易部署: 每个服务独立于其他服务进行部署。服务的任何局部修改，例如更改底层实现使服务性能获得提升，无需同同其他组进行协调。其结果就是，保持了微服务敏捷性，同时也有利于持续集成和持续交付。可独立扩展: 每个服务可以根据需求给予X轴（克隆）和Z轴（分区）进行独立扩展。对于单体应用而言，这一点很难做到，且扩展必须一起部署。改善故障隔离: 一个应为异常的服务，例如内存溢出或数据库连接没有关闭，仅影响所提供的服务而不是整个应用，增强了故障隔离能力。这个能力使得每次错误不会使整个应用程序宕机，仅仅是其中一小片。不会受限于任何技术栈: 开发者可以自由选择对所开发服务最适合的开发语言和技术栈。即使组织可能受限于某些技术选型时，你也不会因过去的技术决策而导致不利。这同样赋予你用更先进的技术和语言重写这些服务的能力。这也给予了选择技术、工具、和平台的自由。微服务看上去像一枚银弹，可以解决许多软件开发方面的问题。这看上去很美好，但并不易于实现。微服务会极大地增加运维工作量，InfoWorld在一篇文章中明确指出： 使用微服务，一些技术债务势必从开发转到运维，因此，你最好有一个一流的开发运维团队。这是非常关键的，像现在你的一个单体应用被多个微服务所分离，它们必须互相通讯。每个微服务可以是使用不同的平台，栈，持久性存储，因而将具有不同的监控和管理的要求。然后，每个服务可以独立地在X轴和Z轴上扩展。每个服务可以一天内被重新多次部署。 微服务和NoOps 微服务对基础设施提出了一些额外的需求。通常，我们将它们总称为NoOps，本质上讲，就是一组服务，提供一个更好的应用程序部署流程并确保其运行。 服务复制: 每个服务都需要复制，一般使用X轴克隆或Z轴分区。是否每个服务都需要创建逻辑可扩展？例如，Kubernetes提供了基于Replication Controller非常简便的方式来复制服务。服务发现: 可能需要多个服务协作提供一个应用的功能。这需要服务能够发现其他服务。在云环境下尤其棘手，因为其上的服务都是短暂的，很有可能扩展或缩减。服务解析是所有其他服务都需要的基础功能。服务需要向中央注册中心注册，其他服务需要查询注册来解析依赖关系。Netflix Eureka, Etcd, Zookeeper 等都是这一领域的可选方案（更多细节）。服务恢复: 不管测试工作做得多努力，软件故障终会发生。关键问题不是如何避免故障而是如何解决故障，对于微服务这样的分布式服务尤其突出。对于服务很重要的一点是能够自动纠正故障，确保用户体验不受影响。Michael Nygard的书引入了断路器的模式来处理软件的弹性。Netflix’s Hystrix 提供这种设计模式的实现（更多细节）。服务监控: 分布系统最重要的一个方面就是服务监控和日志。这使得我们可以采取任意积极的行动，例如：一个服务消耗了预料外的资源。重构成微服务 微服务并不意味着你可以抛弃现有的程序。在大多数情况下，我们还无法做到抛弃它们。因此，我们要构建一种方法，依据它使用微服务重构现有的应用程序。虽然我们仍需要在某个阶段上引入单体程序，直到它准备好被重构。就像Distributed big balls of mud所强调的: 假如你甚至不能构建一个单体程序，你真的觉得微服务就是你问题的答案？重构可能是微不足道的，但在长期而言，它的好处在Infoworld的文章中已经被显著阐明了: 使用微服务重构一个单体应用可以一次性偿还所有的技术债务。一个整体的功能分解是非常重要的，否则重构就成了一个分布式的单体应用而不是相反的一系列微服务为基础的应用集合。","path":"2018/06/04/1923366184/","date":"06-04","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"分布式事务解决方案","text":"2PC的问题2PC简介说到分布式事务，就会提到2pc。2pc是什么，我这里简要说明一下。网上文章实在太多。就不画图详细阐述了。 2pc涉及到2个阶段，3个操作： 阶段1：“准备提交”。事务协调者向所有参与者发起prepare，所有参与者回答yes/no。 阶段2：“正式提交”。如果所有参与者都回答yes，则向所有参与者发起commit；否则，向所有参与者发起rollback。 因此，要实现2pc，所有参与者，都得实现3个接口：prepare/commit/rollback。 2PC的实现关于2pc，对应的实现层面，也就是XA协议。有一个Atomikos开源库，也实现了这个协议。有兴趣的可以去看一下如何使用。 2PC的问题（1）阶段2，事务协调者挂了，则所有参与者接受不到commit/rollback指令，将处于“悬而不决”状态 （2）阶段2，其中一个参与者超时或者出错，那其他参与者，是commit，还是rollback呢？ 也不能确定 为了解决2pc的问题，又引入3pc。3pc有类似的挂了如何解决的问题，因此还是没能彻底解决问题，此处就不详述了。 TCC为了解决SOA系统中的分布式事务问题，支付宝提出了TCC。2PC通常都是在跨库的DB层面，而TCC本质就是一个应用层面的2PC。 同样，TCC中，每个参与者需要3个操作：Try/Confirm/Cancel，也是2个阶段。 阶段1：”资源预留/资源检查“，也就是事务协调者调用所有参与者的Try操作 阶段2：“一起提交”。如果所有的Try成功，一起执行Confirm。否则，所有的执行Cancel。 TCC是如何解决2PC的问题呢？关键：Try阶段成功之后，Confirm如果失败(不管是协调者挂了，还是某个参与者超时），不断重试！ 同样，Cancel失败了，也是不断重试。这就要求Confirm/Cancel都必须是幂等操作。 下面以1个转账case为例，来说明TCC的过程： 有3个账号A, B, C，通过SOA提供的转账服务操作。A, B同时分别要向C转30, 50元，最后C的账号+80，A, B各减30, 50。 阶段1：A账号锁定30，B账号锁定50，检查C账号的合法性（比如C账号是否违法被冻结，C账号是否已注销。。。）。 所以，对应的“扣钱”的Try操作就是”锁定”，对应的“加钱”的Try操作就是检查账号合法性 阶段2：A, B, C都Try成功，执行Confirm。即A, B减钱，C加钱。如果任意一个失败，不断重试！ 从上面的案例可以看出，Try操作主要是为了“保证业务操作的前置条件都得到满足”，然后在Confirm阶段，因为前置条件都满足了，所以可以不断重试保证成功。 1PC我们知道，在tcc里面，有2个阶段。其中第1个阶段是“锁定资源”，目的是为了保证第2个阶段的提交在业务上不会失败。 而1pc，就是舍弃掉第1个阶段，不做资源锁定，直接进行第2个阶段的提交！如果业务的特性可以允许不需要锁定资源，那就可以省去第1个阶段，直接做第2个阶段。 如果第2个阶段失败呢，有2种策略：策略1，同TCC一样，也是不断重试commit，硬着头皮上；策略2，回滚，也就是事务补偿，做之前操作的反操作。","path":"2018/05/25/1657728748/","date":"05-25","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"永远不一致的分布式系统","text":"在分布式系统中，我想大家都听过很多的专业名词：强一致性，弱一致性，最终一致性，CAP理论，FLP不可能性，Paxos算法，2阶段提交… 我们也听说过很多设计系统的策略：比如BASE，缓存，实时计算/离线计算、异步，重写轻读/重读轻写… 我们也听说过很多的系统衡量指标：性能、可靠性、高可用… 而所有这些，都绕不开一个话题：“一致性”。而本篇，则试图以自己的理解，来探讨一下这个最常见、最基本、也最容易迷糊的、看似是常识却暗含深刻哲理的问题。 因为在我看来，从哲学层面，去看透这个问题，很有利于各种计算机理论的理解。 现实世界的3个例子 皇帝驾崩我们知道在古代，传递信息的交通工具通常是马。当现在皇帝驾崩、新皇登基的时候，这个消息要“马不停蹄”的送往各个州、县。 马从京城到最南边的海南，可能要好几个月。那在这过渡期的几个月里面，有的州县认为旧的皇帝还在执政，有的州县已经收到新皇帝登基的通知。 假如新皇版本了一个新的法令，那意味着在这个时期，旧的州县还在执行旧的法令，新的州县在执行新的法令。 这就是现实世界中的“不一致性“的例子。这个例子反映了一个什么常识性的哲理呢？ 信息的传递需要“时间”。对，是“时间”！！！ 淘宝秒杀第2个例子，你正在写代码，你的同事告诉你淘宝现在有一个促销活动，秒杀免费获取一件大衣。 你收到这个消息，立马打开淘宝网页，等打开，显示活动已结束。 请问：是因为你同事告诉了一个“假的”，“不正确”的消息吗？可以说是，也可以说不是。 这个问题背后，反映了另外一个常识性的哲理： 世界一直是变化的，当你把世界的某1刻的“状态”传给另外一个人、或者另外一个地方的时候，此时世界的“状态”可能已经改变。而对方，收到的就是一个“过时”的消息。 这也就是人们常说的那句话： “人不可能2次踏进同1条河流！！！” 将军问题第3个例子，我想很多人都已经听说过，这个在此处就不再阐述。 对应到计算机里面，一个通俗的描述就是：客户端给服务器发了条消息，网络失败。请问，此时服务器到底是收到了这条消息呢？还是没有收到？ 答案是：不确定！ 这些算法通常以其弹性t作为特征，t表示算法可以应付的错误。很多经典算法问题只有在 n ≥ 3t+1 时才有解 总结上面3个例子，反映了3个基本常识： （1）信息的传播，需要“时间”。有“时间”，就有“延迟”；有“延迟”，就有不一致。 （2）信息所反映的“世界”一直在变，信息在传播，世界在变化。2者是并行发生的，也就意味着信息的“过时”。 （3）传递信息的通道，是不可靠的。 计算机世界 – 随处可见的“不一致性”现在就让我们把上面实现世界的3个例子，对应到计算机世界中： （1）信息的传播需要“时间” 例子1：Kafka中，zk选取出Controller。当旧的Controller挂了，新的Controller被选举出来。 这个过程可能很快，在计算机世界的度量里面，是毫秒、或者微秒级别，但即使再快，也需要“时间”，不是0。 那么在这个极端的时间内，其他的broker们，有的接受到的是旧Controller发来的消息；有的接受的是新Controller发来的消息。 或者说，旧的Controller挂了，其发出去的消息，还在网络上游荡呢，此时，新的Controller上台。 例子2： Kafka中，每个broker都维护了一个全局的Metadata。当topic或者partition变化时，所有broker的这个Metadata都需要更新。 很显然，这个过程也需要“时间”，网络还会超时，失败。最终结果必然是：所有broker维护的Metadata，是不一致的。 （2）信息所反映的“世界”在变化 例子：拿Kafka为例，客户端询问集群中的1个broker，我要发消息的(topic,partition)对应的机器列表是多少？broker回答：机器列表是（b1,b2,b3)。 这个结果是正确的，当前是正确的！但就在客户端拿到这个正确的消息，正要选择b1往外发送的时候，这个时候，b1挂了，即“世界”变了。此时发送失败。 （3）2将军问题。 这个在计算机科学中，反复提及，此处就不再详述。 终极结论上面说了现实世界的例子，也说了计算机世界对应的例子，最终是想说明一个什么道理呢？ 理论上，世界不存在“强一致性” 信息的传输需要时间，世界本身也一直在变化。从微观粒度去看，不管计算机的计算时间有多么短：毫秒，微妙，纳秒，时间总是可以细分到一个更细粒度。 在这个更细粒度来看，世界永远是不一致的！！！ 那我们通常说的“强一致性”，是怎么得来的呢？ 其实是从观察者的角度！！！ 就拿单机版的Mysql转账，一个账号扣钱、一个账号加钱来说，必定存在一个短暂的时间窗口：在这个时间窗口内，1个账号的钱减了，但另1个账号的钱，没有加上。 只不过这个时间窗口很短，并且对外屏蔽了这个内部的”不一致性“，让客户端看来，是一致的。所以，在这里，客户端看到的是”强一致性“，但从内部来看，你可以认为是”最终一致性“。 这还只是单机版，如果换成集群，网络时延很大，这个问题就会放大，客户端可能就会明显感知到”不一致性“的存在。 再拿转账举个反向例子： 假如跨行转账的时间是2个小时，对于系统来说，这是“最终一致性” 但对于客户，假设这个客户很忙，好几天才查询一次账户，对于他来说，他看到的永远都是一致的，就是“强一致性”。 世界上不存在100%可靠的系统我们经常会听到某个系统夸耀自己多么多么可靠，多么多么高可用。但从上面的分析，你可以看出，世界上不存在100%可靠的系统。 机器会宕机h，网络会断，不会断也会有延迟。有延迟，就有不一致。 所以你经常会听到，某个系统的可靠性，是几个9。 99%99.9%99.999% 但无论几个9，永远不可能100%。 没有永动机存在说了这么多，就是想阐述一个最最基本的东西：在计算机世界，追求绝对的“一致性”，就好比在物理学中，追求永动机一样。 分布式系统之魅力 通过上面的分析，我们是不是彻底绝望了？我们发现系统中到处都是“坑”，到处都是“漏洞”，到处都是不可靠。那我们还如何设计系统呢？ 而个人认为，分布式系统的魅力就在于：你如何在一个不可靠的、时刻都在变化的网络和硬件环境之上，构建一个相对可靠的软件系统？？ 很显然，因为没有绝对正确答案，才需要各种权衡、妥协。因为各种妥协、折中，才有了CAP理论, 有了BASE原则，有了Paxos… 下面我们就来看看，我们既然没办法彻底解决问题，那面对不一致性，我们经常都会做哪些策略呢？ 重试拿Kafka或者RocketMQ来讲，Metadata的信息不一致，又如何呢？ 多个NameServer的状态，不一致，又如何呢？ 不管这个不一致。客户端拿到Metadata之后，发送失败，重试！！！ 多个局部的不可靠换来整体的可靠 对1个系统来讲，某个局部是可能出问题。但所有局部，同时出问题，这个概率就大大降低了。 比如Kakfa，多备份。一个备份的磁盘是可能挂，但多个备份的磁盘，同时挂，这个概率就低多了。 如果真的同时挂，怎么办呢？ 你就认命吧！！如果老是遇到这种问题，你可以去买彩票了。 层层校验数据不是有可能不一致吗？状态不是有可能随时会过时吗？ 既然没有办法保证全局的、完全的一致，那就在系统的各个局部，多做各种错误校验，以此来修补全局的不一致性。 其他上面只是列举了面对这个随处可见的“不一致性”的一些常见思路，具体到不同的系统，不管是业务系统、还是底层架构，侧重点不一样，会有各式各样的针对特定场景的办法，那就是“八仙过海、各显神通”了。","path":"2018/05/24/1593155822/","date":"05-24","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"技术管理看这一篇就够了","text":"“不确定性”&amp;风险把控作为一个程序员，在其职业生涯发展过程中，随着工作年限的增长，项目经验和技术能力会不断提升。而在这个过程中，都绕不开一个问题：技术管理。 技术管理，说的通俗一点，就是你如何带领一个团队完成一次次的产品迭代，一个个的项目开发。这里面牵涉的东西很多很杂，包括研发、测试、运维、产品、项目管理、数据分析… 不一而足，不同类型的项目、不同的公司文化，在这个事情的做法上都会有差异。 但不管这些差异如何，有一些共同的思维，或者说方法论，是相通的。而从本序列开始，我将分享一下自己在这方面的一些经验和思考。 在我看来，技术管理首先就是要应对”不确定性“问题。就人的认知来讲，做任何事情，你的思路都是从一个”朦胧“到逐步”清晰“的过程，项目的进展也是一个从思路、到方案、到落地的一个逐步细化过程。 这个过程中，不可避免的存在各种”灰度“，或者说”不确定性“。而管理，就是要提前防范这里面的各种”不确定性“，并采取对应措施，让整个团队、整个项目最终经过重重干扰，到达终点。 那都有哪些”不确定性“呢？下面是我的一些总结归纳： 需求的不确定性做产品或者做项目时，产品经理或者大老板，或者其他相关人员，都会有很多“想法”。 有些想法很成熟，逻辑严密，很有系统性；而有些想法还欠火候，需要进一步细化；还有些想法，纯粹是头脑风暴，想想而已… 而由于各种外部条件，比如工期的约束，绩效的追逐，老大的压力…很可能在一个想法没有完全想清楚的情况下，就开始了实施。 这就是一个重大的“不确定性”。遇到这种情况，作为技术的leader，需要去和产品经理、和相关业务方、上级老大等，进行广泛的沟通，最终在这个事情上，要达成“共识”：到底哪些东西清晰的，我们可以开做；哪些还需要进一步思考，细化… 技术的不确定性在做一个新项目时，你可能会遇到技术选型的问题，团队中成员都没有掌握过的某个框架，或者某个开源库，某个对接的第3方开放API等等… 对于这种情况，必须在项目早期，做尽可能多的调研、测试。引入的技术框架，什么特性可以支持，什么特效支持不了；技术选型，不同方案的优缺点… 尤其是一些关键的技术细节，如果在前期不调研做实，等到中后期，才发现某个feature支持不了，或者有问题，可能将对整个的技术架构和项目进度，产生严重影响。 人员的不确定性系统耦合性高，一个关键模块的开发人员的突然离职，新来成员对项目不熟悉，然后慢慢摸熟，上路，等最后项目完工，离预定工期已经差了一大截。 对于这种情况，一个应对策略就是：不要把项目最核心的东西，让一个人去开发维护，别人都插手不了。要分摊风险，在技术的架构设计层面，保证整个系统耦合性不要太高，根据团队成员的水平，每个人都可以cover一块东西。这样某个人离职，有相应的人可以补上。 组织的不确定性公司越大，业务越复杂，部门越多。随便做一个项目，都可能跟好几个业务部门打交道。这些部门可能还在异地，平时只能即时通信，或者远程电话沟通。 对于这种情况，前期必须要做尽可能多的沟通，调研对方提供的业务能力，哪些目前有，哪些目前在开发中，哪些还没有… 在充分沟通的基础上，跟对方敲定排期表，不定期的同步进度，Push对方，保证对方的进度和自己在一个节奏上。 历史遗留问题一般当你进入一个公司，除了创业型公司，很少会一上来就做一个新项目。首先都是会接手前人留下的老项目，在此基础上进行迭代升级。 运气好呢，老项目技术架构很清晰，文档清楚，业务清楚，还有熟悉的其他同事 运气不好呢，遗留项目欠了很多技术债，之前的开发人员也走了，业务很多不熟悉。 对于这种情况，你就需要对项目进行完整的梳理了：从产品到技术，找各个接口人聊，可能经过了两三个月，你才对整个系统有了一个全局的把控。 最后上面列举了带团队做项目的过程中，遇到的几个常见的“不确定性”问题，真正做的过程中，不同项目又会有差别。 这里主要想强调的是：要有这种“风险把控”的意识，有了这种意识，你在项目早期，自然会去努力的想各种各样的“不确定性”，然后早做打算，未雨绸缪。 塑造团队中的影响力刚入职场时，大家都很青涩，能力也都差不多。然后几年之后，有的人升成了leader，负责更大的事情；有的人还在原地踏步，没有多大提升。 影响一个人职业生涯的因素有很多，有公司业务问题，有运气问题，有跟的人/团队是不是靠谱的问题，有个人和领导性格是否合拍的问题。这些问题呢，很多超出了一个技术人的掌控范围。 而本文呢，想从最底层谈谈，作为一个技术人，如何务实的一点点塑造你自己的影响力。而这个事情里面，没有运气成分，是任何一个人，只要你用心做，都可以做到的。 关键时候要能顶的上在一个组织开展业务的过程中，必然会有一些比较“关键”的point： 某个bug困扰了团队1个星期，也没有人搞定； 某个成员离职，他负责的模块没有人接手； 某个用户反映的问题，像牛皮癣一样，总是时不时发生，没办法根治； 某个需求发生工期延误，到了快上线的时候，上不了；……如此种种，有的人的解决办法是“能避开就避开”，有的人解决办法是主动迎上，“死磕”，不解决誓不罢休…… 打工思维，还是老板思维你是打工思维，安排的事干完了，其他一概不管。只管好自己那一亩3分地，技术搞完了，产品、运营、业务发展，一概不关心。产品体验好不好，业务发展前景如何，与你无关。 你是老板思维，你会想这个产品的价值究竟在哪？ 这个产品有什么问题，如何改进？ 团队的协作流程又什么问题，如何改进？ 技术架构有什么问题，如何改进？ 某些用户投诉一直没解决，如何处理？…… 空杯心态术业有专攻。再牛叉的人，他也只是在某个领域很厉害，换个领域，他可能什么都不懂。 技术、产品、运营、测试、运维。。每个领域都有自己的门道。再细化一点，单说技术：前端、后端、架构、算法、数据。。每个子领域也都有自己很深的门道。 说这，是想说明，任何时候，你需要意识到自己的“无知”。只有意识到自己是“无知的”，是有“局限的”，你才可能不断去吸收别人的意见，不断去改进自己的工作方法，提升自己的专业能力、视野。 不然就会一直呆在自己的舒适区里面，刚愎自用。自认为知道的很多，其实很少。 持续改进世界上从来没有做到100分的事情。产品也好，业务流程也好，技术架构也好，项目管理也好，运营也好。。只要你想“鸡蛋挑骨头”，总是可以挑出要改进的地方。 说这，是想说明，你得有“批判性”思考的习惯。不要觉得“差不多”就可以了，要追求极致，其实有很多事情要做。 大家从小到大都在考试，都知道这样一个道理：从不及格到60分，很容易；从60分做到80分，难一点；从80分做到95分，很难；从95分到100分，每增加1分，难上加难。 做事情跟考试一样，有的人选择做很多事情，但每个事情都只及格；有的人选择做一个事情，不断往100分靠近。 建言献策接着上面一个问题，如果你有“批判性思考”的能力，你能看到一个组织存在的各种问题，并想出应对的解放办法。 然后多和同事、和领导沟通这些事情，无论对于个人成长，还是组织，都是一个正向作用。 最后说了这么多，最后我们换位思考一下： 如果你看到公司某个同事，他关键时候顶的上，他做事追求极致，他思考总是很全面，他对业务的了解总是比其他技术人员要多，他总是很虚心的接受改进，他总是时不时给公司提出自己的建议。。你会如何看待？ 技术的价值模型作为一个程序员，特别是有技术追求的程序员，最经常关注的就是：技术有多么牛，多么复杂，多么酷炫。。可当被问到你做的东西，有什么“价值”时，往往却很难说清楚。 在这里，我想抛出这样一个终极问题：技术的价值到底是什么？ 我们都知道Github上有很多开源项目，那么这些项目的价值大小，是如何衡量的呢？下面有一些考虑因素： 以技术复杂度来衡量？ 以代码行数来衡量？ 以技术的先进与否衡量？ 以是否有创新性衡量？ 我想都不是。在个人看来，衡量这些项目的关键指标是：多少人使用了这个开源项目。 即使这个开源项目代码量很少，功能也很简单，但如果很多组织、很多个人都在用，那它就是有巨大价值的！ 从这个意义上讲，技术所追求的”价值“和产品所追求的”价值“是一样的，殊途同归，最终都是要为“用户”服务。 下面我总结了这样一个4层的价值模型： 第1个层次程序员最熟悉的，经常谈论的：我这个系统有多少多少个业务模块，我这个系统功能多么强大，我这个系统采用了多少多少新技术，我这个系统采用了某个牛叉的算法… 第2个层次追问一下，在你所做的所有工作中，最核心的是采取了哪个措施？最终可能会抽象出1到2个。 再追问一下，这1到2个大的技术改进，有什么价值，通常都会追问到软件的各个非功能性需求： 可重用性：我做了某个jar包，某个组件，某个服务，别人不再需要重复造轮子。 可扩展性：来了一个新的需求，我只需要配置一下，或者做很简单的代码开发，就搞定了，不需要改很多系统。 可维护性：整个系统解耦做的很好，代码也很整洁。要叠加功能，或者找人接手，都比较容易。 高性能：用户体验很好，所有请求都在100ms内返回 高并发：能支持千万到亿的用户并发访问 稳定性：系统时不时出bug，宕机，用户报case，我把这些问题都解决了。还加了监控，出了问题立即会有报警。 高可靠：我做了灾备方案，某个机器宕机，系统不受影响 一致性：我做到了强一致性，极大提高了业务体验 …… 第3个层次我做的系统，为公司带来了什么业务价值： 极大提升了用户体验？因此促进了用户增长？ 提高了用户的活跃度？ 为公司增加了收入？ 降低了公司的研发成本？ 提升了公司的运维效率？ 为公司开辟了一个新的市场？ 第4个层次公司的本质：市场经济下的一个追求利润最大化的组织。 从公司角度来讲，技术也好，产品也好，运营销售也好，最终目的都是要增加公司利润。而增加利润，要么”开源“，要么“节流”。所以你做的任何东西，基本都会被归结到这个层次。 当然，还有一类是“战略性投入”的项目，虽然它本身不直接挣钱，或者挣钱很少，但是为了支撑其他挣大钱的业务而发挥重要作用。 最后技术、产品、运营，殊途同归！","path":"2018/05/24/595384478/","date":"05-24","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"RESTFUL API 中的那些事","text":"POST vs PUTHTTP的POST/PUT方法经常会被弄混，因为这两个方法似乎都可以用来创建或更新一个资源。 但是它们之前的区别是很清楚的： POST方法用来创建一个子资源，如 /api/users，会在users下面创建一个user，如users/1 POST方法是非幂等的，多次执行，将导致多条相同的资源被创建，如 （users/1，users/2 … 而这些用户除了自增长Id外有着完全相同的数据，除非你的系统实现了额外的数据唯一性检查） 而PUT方法用来创建一个URI已知的资源，或对已知资源进行完全替换，比如users/1， 因此除非在创建前你完全知道自己要创建的对象的URI，否则PUT方法无法更新一个已知资源。 PATCH vs PUTPATCH方法是新引入的方法，该方法是对PUT方法的补充，用来对已知资源进行局部更新。 PATCH操作主要用来更新部分资源，而且其是非幂等的。（所谓的幂等就是每次更新后，结果不变） PUT操作主要用来更新全部的资源，而且其是幂等的。 那么PATCH操作的优势是什么呢？因为PATCH操作是用来更新部分资源，所以可以节省网络带宽。 当然，PATCH操作也有其缺点，那就是PATCH操作是非幂等的，也是不安全的。（当执行PATCH操作时，如果资源不存在，则会创建资源而PUT不会） 因此实现PATCH操作语义的应用必须保证当前的PATCH操作是最小粒度，即它的原子性。 在HTTP常用的几个动词里, HEAD, GET, PUT, DELETE 都是安全的,幂等的。 因为对同一资源的任意多次请求, 永远代表同一个语义。 所以任何时候客户端发出去这些动词的时候, 如果服务器没有响应, 或者返回错误代码, 客户端都可以非常安全的再次执行同一操作而不用担心重复操作带来不同的语义及最终结果。 POST, PATCH操作就不是安全的, 因为当客户端向服务器端发出请求后, 服务器没有响应或者返回错误代码, 客户端是不能安全的重复执行操作的。 一定在重新与服务器确认了现在的资源状态下，才能决定下一步的操作。","path":"2018/05/24/1333242850/","date":"05-24","excerpt":"","tags":[{"name":"Restful","slug":"Restful","permalink":"https://yihuishou.github.io/tags/Restful/"}]},{"title":"TeamViewer 在局域网中使用的方法","text":"TeaamViewer 在局域网中使用的方法（非联网） 默认联网状态 菜单选项 修改Lan设置 修改后的Lan设置 最终结果","path":"2018/05/22/1391388246/","date":"05-22","excerpt":"","tags":[{"name":"Windows","slug":"Windows","permalink":"https://yihuishou.github.io/tags/Windows/"}]},{"title":"Mysql 的索引应用","text":"索引 数据库的索引就像一本书的目录，能够加快数据库的查询速度。 MYSQL索引有四种PRIMARY、INDEX、UNIQUE、FULLTEXT， 其中PRIMARY、INDEX、UNIQUE是一类，FULLTEXT是一类。 这四种都是单列索引，也就是他们都是作用于单一列，所以也称单列索引；但是所以一个索引也可以作用于多个列上，称为组合索引或复合索引。 单列索引新建一张测试表 CREATE TABLE T_USER( ID INT NOT NULL,USERNAME VARCHAR(16) NOT NULL); （1）PRIMARY：主键索引。索引列唯一且不能为空；一张表只能有一个主键索引（主键索引通常在建表时就被指定） CREATE TABLE T_USER(ID INT NOT NULL,USERNAME VARCHAR(16) NOT NULL,PRIMARY KEY(ID)) （2）NORMAL：普通索引。索引列没有任何限制； 建表时指定： CREATE TABLE T_USER(ID INT NOT NULL,USERNAME VARCHAR(16) NOT NULL,INDEX USERNAME_INDEX(USERNAME(16))) //给列USERNAME建普通索引USERNAME_INDEX ALTER语句指定： ALTER TABLE T_USER ADD INDEX U_INDEX (USERNAME) //给列USERNAME建普通索引 U_INDEX 删除索引： DROP INDEX U_INDEX ON t_user //删除表t_user中的索引U_INDEX （3）UNIQUE：唯一索引。索引列的值必须是唯一的，但允许有空； 建表时指定： CREATE TABLE t_user(ID INT NOT NULL,USERNAME VARCHAR(16) NOT NULL,UNIQUE U_INDEX(USERNAME)) //给列USERNAME添加唯一索引T_USER ALTER语句指定 ALTER TABLE t_user ADD UNIQUE u_index(USERNAME) //给列T_USER添加唯一索引u_index 删除索引： DROP INDEX U_INDEX ON t_user （4）FULLTEXT：全文搜索的索引。FULLTEXT 用于搜索很长一篇文章的时候，效果最好。用在比较短的文本，如果就一两行字的，普通的 INDEX 也可以。索引的新建和删除和上面一致，这里不再列举… 组合索引（复合索引） 新建一张表 CREATE TABLE T_USER(ID INT NOT NULL,USERNAME VARCHAR(16) NOT NULL,CITY VARCHAR(10),PHONE VARCHAR(10),PRIMARY KEY(ID) ) 组合索引就是把多个列加入到统一个索引中，如新建的表T_USER，我们给USERNAME+CITY+PHONE创建一个组合索引 ALTER TABLE t_user ADD INDEX name_city_phone(USERNAME,CITY,PHONE) //组合普通索引 ALTER TABLE t_user ADD UNIQUE name_city_phone(USERNAME,CITY,PHONE) //组合唯一索引 这样的组合索引，其实相当于分别建立了（USERANME,CITY,PHONE USERNAME,CITY USERNAME,PHONE）三个索引。 为什么没有（CITY,PHONE）索引呢？这是因为MYSQL组合查询“最左前缀”的结果。简单的理解就是只从最左边开始组合。 并不是查询语句包含这三列就会用到该组合索引： 以下的查询语句才会用到创建的组合索引 SELECT * FROM t_user where USERNAME=\"parry\" and CITY=\"广州\" and PHONE=\"180\"SELECT * FROM t_user where USERNAME=\"parry\" and CITY=\"广州\"SELECT * FROM t_user where USERNAME=\"parry\" and PHONE=\"180\" 以下的查询语句是不会用到创建的组合索引 SELECT * FROM t_user where CITY=\"广州\" and PHONE=\"180\"SELECT * FROM t_user where CITY=\"广州\"SELECT * FROM t_user where PHONE=\"180\" 索引不足之处（1）索引提高了查询的速度，但是降低了INSERT、UPDATE、DELETE的速度，因为在插入、修改、删除数据时，还要同时操作一下索引文件； （2）建立索引未见会占用一定的磁盘空间。 索引的使用注意事项（1）只要列中包含NULL值将不会被包含在索引中，组合索引只要有一列含有NULL值，那么这一列对于组合索引就是无效的所以我们在设计数据库的时候最好不要让字段的默认值为NULL; （2）使用短索引 如果可能应该给索引指定一个长度，例如：一个VARCHAR(255)的列，但真实储存的数据只有20位的话，在创建索引时应指定索引的长度为20，而不是默认不写。如下： ALTER TABLE t_user add INDEX U_INDEX(USERNAME(16)) 优于 ALTER TABLE t_user add INDEX U_INDEX(USERNAME) 使用短索引不仅能够提高查询速度，而且能节省磁盘操作以及I/O操作。 （3）索引列排序 Mysql在查询的时候只会使用一个索引，因此如果where子句已经使用了索引的话，那么order by中的列是不会使用索引的所以order by尽量不要包含多个列的排序，如果非要多列排序，最好使用组合索引。 （4）Like 语句 一般情况下不是鼓励使用like,如果非使用，那么需要注意 like”%aaa%”不会使用索引；但like“aaa%”会使用索引。 （5）不要使用 NOT IN 和 &lt;&gt; 操作 索引方式 HASH 和 BTREE 的比较（1）HASH 用于对等比较，如 &quot;=&quot; 和 &quot;&lt;=&gt;&quot; （2）BTREE BTREE索引看名字就知道索引以树形结构存储，通常用在像 &quot;=，&gt;，&gt;=，&lt;，&lt;=、BETWEEN、Like&quot; 等操作符查询效率较高；我们通用的就是BTREE索引方式，因为这是Mysql默认的。 索引的优缺点为什么要创建索引呢？这是因为，创建索引可以大大提高系统的性能。 第一、通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 第二、可以大大加快 数据的检索速度，这也是创建索引的最主要的原因。 第三、可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 第四、在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 第五、通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 也许会有人要问：增加索引有如此多的优点，为什么不对表中的每一个列创建一个索引呢？这种想法固然有其合理性，然而也有其片面性。虽然，索引有许多优点， 但是，为表中的每一个列都增加索引，是非常不明智的。 这是因为，增加索引也有许多不利的一个方面: 第一、创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 第二、索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间。如果要建立聚簇索引，那么需要的空间就会更大。 第三、当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 什么样的字段适合创建索引索引是建立在数据库表中的某些列的上面。因此，在创建索引的时候，应该仔细考虑在哪些列上可以创建索引，在哪些列上不能创建索引。 一般来说，应该在这些列上创建索引，例如： 第一、在经常需要搜索的列上，可以加快搜索的速度； 第二、在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 第三、在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； 第四、在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； 第五、在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 第六、在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 建立索引，一般按照select的where条件来建立，比如： select的条件是where f1 and f2，那么如果我们在字段f1或字段f2上建立历索引是没有用的，只有在字段f1和f2上同时建立索引才有用等。 什么样的字段不适合创建索引同样，对于有些列不应该创建索引。一般来说，不应该创建索引的的这些列具有下列特点： 第一，对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 第二，对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比 例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 第三，对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值相当少。 第四，当修改性能远远大于检索性能时，不应创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应创建索引。 创建索引的方法: 1、创建索引，例如 create index &lt;索引的名字&gt; on table_name (列的列表); 2、修改表，例如 alter table table_name add index[索引的名字] (列的列表); 3、创建表的时候指定索引，例如create table table_name ( […], INDEX [索引的名字] (列的列表) ); 查看表中索引的方法: show index from table_name; 查看索引 索引的类型及创建例子: 1.PRIMARY KEY （主键索引） MySQL&gt; alter table table_name add primary key ( column ) 2.UNIQUE 或 UNIQUE KEY (唯一索引) mysql&gt; alter table table_name add unique (column) 3.FULLTEXT (全文索引) mysql&gt; alter table table_name add fulltext (column ) 4.INDEX (普通索引) mysql&gt; alter table table_name add index index_name ( column ) 5.多列索引 (聚簇索引) mysql&gt; alter table table_name add index index_name ( column1, column2, column3 ) 修改表中的索引： alter table tablename drop primary key,add primary key(fileda,filedb)","path":"2018/05/18/2602311916/","date":"05-18","excerpt":"","tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://yihuishou.github.io/tags/Mysql/"}]},{"title":"CSS 中 link 与 @import 的区别","text":"看到淘宝网页中这样写使用的是import,而很多网站都是使用link，当然还有一些页面比较简单，流量很大的网站，是直接将CSS写在html代码中的？ 他们有什么区别？css用import还是link好?从经典论坛和另外一个网站大概了解了一下 看到淘宝网页中大部分是这样写的 &lt;style type=\"text/css\" media=\"screen\"&gt;@import url(\"http://www.taobao.com/home/css/global/v2.0.css?t=20070518.css\");&lt;/style&gt; 而很多网站，比如大前端使用的都是link &lt;link rel=\"stylesheet\" rev=\"stylesheet\" href=\"default.css\" type=\"text/css\" media=\"all\" /&gt; 而像google 百度 163等网站他们都是直接写在网页中 当然使用链接link和导入import的好处就是易于维护，但当网速比较慢的时候，会出现加载中断的情况，导致页面排版错误 他俩的作用相同唯一的不同是服务对象不一样 @import 为CSS服务link是为当前的页服务 @import会优先执行。 外部引用CSS中 link与@import的区别 这两天刚写完XHTML加载CSS的几种方式，其中外部引用CSS分为两种方式link和@import。 本质上，这两种方式都是为了加载CSS文件，但还是存在着细微的差别。 差别1：老祖宗的差别。link属于XHTML标签，而@import完全是CSS提供的一种方式。 link标签除了可以加载CSS外，还可以做很多其它的事情，比如定义RSS，定义rel连接属性等，@import就只能加载CSS了。 差别2：加载顺序的差别。当一个页面被加载的时候（就是被浏览者浏览的时候），link引用的CSS会同时被加载，而@import引用的CSS 会等到页面全部被下载完再被加载。所以有时候浏览@import加载CSS的页面时开始会没有样式（就是闪烁），网速慢的时候还挺明显。 差别3：兼容性的差别。由于@import是CSS2.1提出的所以老的浏览器不支持，@import只有在IE5以上的才能识别，而link标签无此问题。 差别4：使用dom控制样式时的差别。当使用javascript控制dom去改变样式的时候，只能使用link标签，因为@import不是dom可以控制的。 不要使用 css @import, 因为用这种方式加载css相当于把css放在了html底部。 我们确实要避免使用css @import， 但原因却不是什么相当于放在了页面底部，而是这样做会导致css无法并行下载，因为使用@import引用的文件只有在引用它的那个css文件被下载、解析之后，浏览器才会知道还有另外一个css需要下载，这时才去下载，然后下载后开始解析、构建render tree等一系列操作。 浏览器在页面所有css下载并解析完成后才会开始渲染页面，因此css @import引起的css解析延迟会加长页面留白期。 所以，要尽量避免使用css @import而尽量采用link标签的方式引入。 两者都是外部引用CSS的方式，但是存在一定的区别： 区别1：link是XHTML标签，除了加载CSS外，还可以定义RSS等其他事务；@import属于CSS范畴，只能加载CSS。 区别2：link引用CSS时，在页面载入时同时加载；@import需要页面网页完全载入以后加载。 区别3：link是XHTML标签，无兼容问题；@import是在CSS2.1提出的，低版本的浏览器不支持。 区别4：ink支持使用Javascript控制DOM去改变样式；而@import不支持。","path":"2018/05/18/450415382/","date":"05-18","excerpt":"","tags":[{"name":"大前端","slug":"大前端","permalink":"https://yihuishou.github.io/tags/大前端/"}]},{"title":"优雅地使用注解","text":"使用注解创建自定义注解","path":"2018/05/18/793018311/","date":"05-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"前端规范 JS","text":"前端代码规范 —- javascript 本文档的目标是使 JavaScript 代码风格保持一致，容易被理解和被维护。 可以修改开发工具的配置文件并设置格式化快捷键来统一代码风格 基本命名规范1、变量、函数名以驼峰式命名，应为名词，具体含义 let newNamefunction getName() &#123;&#125; 2、常量全部大写字母，用_连接 const THEME_SKIN = 'theme-skin' 3、函数名以动词开始 function getName() &#123;&#125; // 获取function setName() &#123;&#125; // 设置function doName() &#123;&#125; // 执行function submitName() &#123;&#125; // 提交function editName() &#123;&#125; // 编辑 4、返回类型是布尔类型，一般以is开头 let isEnable = falsefunction isCheckName() &#123;&#125; 5、变量和函数命名，不要担心长度，合乎逻辑重要。 6、class以名词命名，首字母大写 7、文件名、目录名称命名方式 用 - 连接 注释1、单行注释 &nbsp; 必须独占一行。// 后跟一个空格，缩进与下一行被注释说明的代码一致。// 2、多行注释 &nbsp; 避免使用 /…/ 这样的多行注释。有多行注释内容时，使用多个单行注释。// 3、文档化注释 &nbsp; 为了便于代码阅读和维护，以下内容必须包含以 /*…/ 形式的块注释中。 4、关于函数JSDoc注释 适用.vue文件 (wacth、methods、computed) JSDoc官方文档http://usejsdoc.org/ 演示一下jsdoc的标准写法： /** * 解释这个function的作用，可以把处理的思路写下来 * @param &#123;Array&#125; param1 - 参数param1的解释 * @param &#123;Object&#125; param2 - 参数param2的解释 * @param &#123;number&#125; param3 - 参数param3的解释 * @return &#123;string&#125; 对返回值的解释，如果没有返回值，则不需要添加这一项 */function jsdocExample(param1, param2, param3) &#123; // ... return ''&#125; 代码风格缩进 使用4个空格(不要使用Tab) 忽略分号(不加) 空格 1、 [强制] 二元运算符两侧必须有一个空格，一元运算符与操作对象之间不允许有空格。 var a = !arr.length;a++;a = b + c; 2、[强制] 用作代码块起始的左花括号 { 前必须有一个空格。 // goodif(condition) &#123;&#125;while(condition) &#123;&#125;function funcName() &#123;&#125;// badif(condition)&#123;&#125;while (condition)&#123;&#125;function funcName()&#123;&#125; 3、[强制] if / else / for / while / function / switch / do / try / catch / finally 关键字后，必须有一个空格。 // goodif (condition) &#123;&#125;while (condition) &#123;&#125;(function () &#123;&#125;)();// badif(condition) &#123;&#125;while(condition) &#123;&#125;(function() &#123;&#125;)(); 4、[强制] 在对象创建时，属性中的 : 之后必须有空格，: 之前不允许有空格。 // goodvar obj = &#123; a: 1, b: 2, c: 3,&#125;;// badvar obj = &#123; a : 1, b:2, c :3&#125;; 5、[强制] 函数声明、具名函数表达式、函数调用中，函数名和 ( 之间不允许有空格。 // goodfunction funcName() &#123;&#125;var funcName = function funcName() &#123;&#125;;funcName();// badfunction funcName () &#123;&#125;var funcName = function funcName () &#123;&#125;;funcName (); 6、[强制] , 前不允许有空格 // goodcallFunc(a, b)// badcallFunc(a , b) 7、[强制] 在函数调用、函数声明、括号表达式、属性访问、if / for / while / switch / catch 等语句中，() 和 [] 内紧贴括号部分不允许有空格。 // goodcallFunc(param1, param2, param3);save(this.list[this.indexes[i]]);needIncream &amp;&amp; (variable += increament);if (num &gt; list.length) &#123;&#125;while (len--) &#123;&#125;// badcallFunc( param1, param2, param3 );save( this.list[ this.indexes[ i ] ] );needIncreament &amp;&amp; ( variable += increament );if ( num &gt; list.length ) &#123;&#125;while ( len-- ) &#123;&#125; 基于eslint-plugin-standard修改eslint规则git钩子会强制验证eslint规则，通过后才能提交。后期新项目会在初始化的时候执行git钩子安装命令(必须执行) eslint 提供 —fix 命令可以修复大部分的error 和warn // add your custom rules here 0 忽略 1 warn 2 error rules: &#123; 'valid-jsdoc': [1, &#123; requireReturn: false, &#125;], 'require-jsdoc': [1, &#123; require: &#123; FunctionDeclaration: true, MethodDefinition: true, ClassDeclaration: true, &#125;, &#125;], // 插件验证.vue文件中的jsdoc '@sweetui/sweet-mobile-sdk/object-literal-jsdoc/obj-doc': [1, &#123; ignoreMethods, &#125;], // 缩进4空格 禁用2 'indent': [1, 4], // 禁止条件表达式中出现赋值操作符 'no-cond-assign': 2, // 允许console语句 'no-console': 1, // 允许 debugger 'no-debugger': 1, // var声明 'no-var': 2, // 禁止 function 定义中出现重名参数 'no-dupe-args': 2, // 禁止重复的函数声明 'no-func-assign': 2, // 忽略分号; 'semi': [1, \"never\"], // 使用 === 和 !== 'eqeqeq': [2, 'allow-null'], // warn alert、 'no-alert': 1, // 禁用 eval() 'no-eval': 2, // 禁用 with 语句 'no-with': 2, // 要求或禁止使用严格模式指令 'strict': 2, // 要求或禁止 var 声明中的初始化(初值) 'init-declarations': 2, // 不允许 catch 子句的参数与外层作用域中的变量同名 'no-catch-shadow': 0, // 禁止删除变量 'no-delete-var': 2, // 不允许标签与变量同名 'no-label-var': 2, // 禁用特定的全局变量 'no-restricted-globals': 2, // 禁止 var 声明 与外层作用域的变量同名 'no-shadow': 0, // 禁止覆盖受限制的标识符 'no-shadow-restricted-names': 2, // 禁用未声明的变量，除非它们在 /*global */ 注释中被提到 'no-undef': 2, // 禁止将变量初始化为 undefined 'no-undef-init': 2, // 禁止将 undefined 作为标识符 'no-undefined': 2, // 禁止出现未使用过的变量 'no-unused-vars': [1, &#123;'vars': 'all', 'args': 'none'&#125;], // 不允许在变量定义之前使用它们 'no-use-before-define': 1, // 强制一行的最大长度 'max-len': [1, 160], // 文件末尾强制换行 'eol-last': 0, // 强制使用单引号 'quotes': [2, 'single'], // 禁止修改 const 声明的变量 'no-const-assign': 2, // 禁止标识符中有悬空下划线_bar，这里忽略 'no-underscore-dangle': 0, // 禁用行尾空格 'no-trailing-spaces': 2, // 禁用不必要的嵌套块 'no-lone-blocks': 2, // 强制在 JSX 属性中一致地使用双引号或单引号 'jsx-quotes': 0, // 函数定义时括号前面要不要有空格 'space-before-function-paren': [1, `never`], //对象字面量项尾不能有逗号 这里忽略 'comma-dangle': [0, 'always'], // 在对象字面量属性中实现键和值之间的一致间隔 &#123;key: value&#125; 'key-spacing': [1, &#123;'mode': 'strict'&#125;], // 允许对象所有键和值在同一行上 'object-property-newline': [0, &#123;'allowMultiplePropertiesPerLine': true&#125;], // promise reject 参数设置为 * 任意类型 'prefer-promise-reject-errors': [0, &#123;'allowEmptyReject': true&#125;] &#125;,","path":"2018/05/18/2028463303/","date":"05-18","excerpt":"","tags":[{"name":"大前端","slug":"大前端","permalink":"https://yihuishou.github.io/tags/大前端/"}]},{"title":"前端规范 CSS","text":"前端代码规范 —- css 本文档的目标是使 css 代码风格保持一致，容易被理解和被维护。 样式属性顺序以Positioning Model &gt; Box Model &gt; Typographic &gt; Visual 的顺序书写，提高代码的可读性。 Positioning Model 布局方式、位置，相关属性包括：position, top, z-index, display, float等 Box Model 盒模型，相关属性包括：width, height, padding, margin，border,overflow Typographic 文本排版，相关属性包括：font, line-height, text-align Visual 视觉外观，相关属性包括：color, background, list-style, transform, animation CSS选择器命名规则 一律小写,使用” - “横线来命名css,不要使用 “ _ “ 下划线 尽量不用缩写 去掉小数点前面的0： 0.9rem =&gt; .9rem 使用简写：margin： 0 1rem 3rem id采用驼峰式命名(不要乱用id) css/less中，层级嵌套最好不超过3层 less中的变量、函数、混合、placeholder采用驼峰式命名 Css性能优化慎重选择高消耗的样式高消耗属性在绘制前需要浏览器进行大量计算： box-shadows border-radius transparency transforms CSS filters（性能杀手） 避免过分重排当发生重排的时候，浏览器需要重新计算布局位置与大小，更多详情。 常见的重排元素: width height padding margin display border-width position top left right bottom font-size float text-align overflow-y font-weight overflow font-family line-height vertical-align clear white-space min-height 正确使用 Display 的属性Display 属性会影响页面的渲染，请合理使用。 display: inline后不应该再使用 width、height、margin、padding 以及 float； display: inline-block 后不应该再使用 float； display: block 后不应该再使用 vertical-align； display: table-* 后不应该再使用 margin 或者 float； 不滥用 FloatFloat在渲染时计算量比较大，尽量减少使用。 动画性能优化动画的实现原理，是利用了人眼的“视觉暂留”现象，在短时间内连续播放数幅静止的画面，使肉眼因视觉残象产生错觉，而误以为画面在“动”。 动画的基本概念： 帧：在动画过程中，每一幅静止画面即为一“帧”; 帧率：即每秒钟播放的静止画面的数量，单位是fps(Frame per second); 帧时长：即每一幅静止画面的停留时间，单位一般是ms(毫秒); 跳帧(掉帧/丢帧)：在帧率固定的动画中，某一帧的时长远高于平均帧时长，导致其后续数帧被挤压而丢失的现象。 一般浏览器的渲染刷新频率是 60 fps，所以在网页当中，帧率如果达到 50-60 fps 的动画将会相当流畅，让人感到舒适。 如果使用基于 javaScript 的动画，尽量使用 requestAnimationFrame. 避免使用 setTimeout, setInterval. 避免通过类似 jQuery animate()-style 改变每帧的样式，使用 CSS 声明动画会得到更好的浏览器优化。 使用 translate 取代 absolute 定位就会得到更好的 fps，动画会更顺滑。 多利用硬件能力，如通过 3D 变形开启 GPU 加速一般在 Chrome 中，3D或透视变换（perspective transform）CSS属性和对 opacity 进行 CSS 动画会创建新的图层，在硬件加速渲染通道的优化下，GPU 完成 3D 变形等操作后，将图层进行复合操作（Compesite Layers），从而避免触发浏览器大面积重绘和重排。 注：3D 变形会消耗更多的内存和功耗。 使用 translate3d 右移 500px 的动画流畅度要明显优于直接使用 left： .ball-1 &#123; transition: -webkit-transform .5s ease; -webkit-transform: translate3d(0, 0, 0);&#125;.ball-1.slidein&#123; -webkit-transform: translate3d(500px, 0, 0);&#125;.ball-2 &#123; transition: left .5s ease; left：0;&#125;.ball-2.slidein &#123; left：500px;&#125; 提升 CSS 选择器性能CSS 选择器对性能的影响源于浏览器匹配选择器和文档元素时所消耗的时间，所以优化选择器的原则是应尽量避免使用消耗更多匹配时间的选择器。而在这之前我们需要了解 CSS 选择器匹配的机制， 如子选择器规则： #header &gt; a &#123;font-weight:blod;&#125; 我们中的大多数人都是从左到右的阅读习惯，会习惯性的设定浏览器也是从左到右的方式进行匹配规则，推测这条规则的开销并不高。 我们会假设浏览器以这样的方式工作：寻找 id 为 header 的元素，然后将样式规则应用到直系子元素中的 a 元素上。我们知道文档中只有一个 id 为 header 的元素，并且它只有几个 a 元素的子节点，所以这个 CSS 选择器应该相当高效。 事实上，却恰恰相反，CSS 选择器是从右到左进行规则匹配。了解这个机制后，例子中看似高效的选择器在实际中的匹配开销是很高的，浏览器必须遍历页面中所有的 a 元素并且确定其父元素的 id 是否为 header 。 如果把例子的子选择器改为后代选择器则会开销更多，在遍历页面中所有 a 元素后还需向其上级遍历直到根节点。 #header a &#123;font-weight:blod;&#125; 理解了CSS选择器从右到左匹配的机制后，明白只要当前选择符的左边还有其他选择符，样式系统就会继续向左移动，直到找到和规则匹配的选择符，或者因为不匹配而退出。我们把最右边选择符称之为关键选择器。——更多详情 1、避免使用通用选择器 /* Not recommended */.content * &#123;color: red;&#125; 浏览器匹配文档中所有的元素后分别向上逐级匹配 class 为 content 的元素，直到文档的根节点。因此其匹配开销是非常大的，所以应避免使用关键选择器是通配选择器的情况。 2、避免使用标签或 class 选择器限制 id 选择器 /* Not recommended */button#backButton &#123;…&#125;/* Recommended */#newMenuIcon &#123;…&#125; 3、避免使用标签限制 class 选择器 /* Not recommended */treecell.indented &#123;…&#125;/* Recommended */.treecell-indented &#123;…&#125;/* Much to recommended */.hierarchy-deep &#123;…&#125; 4、避免使用多层标签选择器。使用 class 选择器替换，减少css查找 /* Not recommended */treeitem[mailfolder=\"true\"] &gt; treerow &gt; treecell &#123;…&#125;/* Recommended */.treecell-mailfolder &#123;…&#125; 5、避免使用子选择器 /* Not recommended */treehead treerow treecell &#123;…&#125;/* Recommended */treehead &gt; treerow &gt; treecell &#123;…&#125;/* Much to recommended */.treecell-header &#123;…&#125; 6、使用继承 /* Not recommended */#bookmarkMenuItem &gt; .menu-left &#123; list-style-image: url(blah) &#125;/* Recommended */#bookmarkMenuItem &#123; list-style-image: url(blah) &#125; 统一语义理解和命名 布局 语义 命名 文档 doc 头部 head 主体 body 尾部 foot 主栏 main 侧栏 side 盒容器 wrap/box 模块 、元件 语义 命名 导航 nav 面包屑 crumb 菜单 menu 选项卡 tab 标题区 head/title 内容区 body/content 列表 list 表格 table 表单 form 热点 hot 排行 top 登录 login 标志 logo 广告 advertise 搜索 search 幻灯 slide 提示 tips 帮助 help 新闻 news 下载 download 注册 regist 投票 vote 版权 vcopyright/cprt 结果 result 标题 title 按钮 button/btn 输入 input 状态 语义 命名 选中 selected 当前 current 显示 show 隐藏 hide 打开 open 关闭 close 出错 error 不可用 disabled","path":"2018/05/18/717841595/","date":"05-18","excerpt":"","tags":[{"name":"大前端","slug":"大前端","permalink":"https://yihuishou.github.io/tags/大前端/"}]},{"title":"RPG Maker MV 状态触发事件以及开关","text":"利用YEP插件自动触发被动状态 在人物备注里添加： &lt;状态ID : 触发事件ID&gt; 一般很难找到开关的编辑，其实开关编辑在敌群、地图事件、以及公共事件中的条件分支中都可进行编辑 开关相关与一个全局布尔变量","path":"2018/05/15/410376202/","date":"05-15","excerpt":"","tags":[{"name":"RPG Maker MV","slug":"RPG-Maker-MV","permalink":"https://yihuishou.github.io/tags/RPG-Maker-MV/"}]},{"title":"WinRar 常用自解压路径及命令","text":"自解压路径在使用winrar打包时，需要将文件复制到系统根目录，但是为了保证兼容性，需要使用系统变量，在网上查了下，得到以下资料，发于此以备后用。 WINRAR 的帮助文件中没有对自解压路径和系统的环境变量之进行说明，所以，很多人只知道，其自解压路径可以智能定位到系统的 Program Files 目录 而不知道它其实还可以智能定位到系统的任何地方： %SystemDrive%操作系统所在的分区号。如 C: %SystemRoot%操作系统根目录。如 C:\\WINDOWS %windir%操作系统根目录。如 C:\\WINDOWS %ALLUSERSPROFILE%相当于 C:\\Documents and Settings\\All Users %APPDATA%相当于 C:\\Documents and Settings\\用户目录\\Application Data %ProgramFiles%相当于 C:\\Program Files%CommonProgramFiles%或者 C:\\Program Files\\Common Files %HOMEDRIVE%操作系统所在的分区号。如：C:%HOMEPATH%相当于 \\Documents and Settings\\用户目录 %USERPROFILE%相当于 C:\\Documents and Settings\\用户目录 有了上面这些变量值，我们就好办了，几乎可以向系统的任何地方拷贝文件了。 比如： 字体目录 %WINDIR%\\FONTS 帮助目录 %WINDIR%\\Help 输入法目录 %WINDIR%\\IME 桌面 %USERPROFILE%\\桌面 右键菜单“发送到” %USERPROFILE%\\SendTo 收藏夹 %USERPROFILE%\\Favorites 快速启动 %APPDATA%\\Microsoft\\Internet Explorer\\Quick Launch 「开始」菜单 %USERPROFILE%\\「开始」菜单 当前系统盘符 %systemdrive% 或 %HOMEDRIVE% C:\\ 当前系统目录 %systemroot% 或 %Windir% C:\\WINDOWS 当前用户文件夹 %UserProfile% 或 %HOMEPATH% C:\\Documents and Settings\\Administrator 所有用户文件夹 %AllUsersProfile% C:\\Documents and Settings\\All Users 临时文件夹1 %temp% C:\\Documents and Settings\\Administrator\\Local Settings\\Temp 临时文件夹2 %SystemRoot%\\TEMP C:\\WINDOWS\\Temp 程序文件夹 %ProgramFiles% C:\\Program Files 还有： %WINDIR%\\SYSTEM32\\config %ProgramFiles%\\Adobe %CommonProgramFiles%\\Macromedia ……等等。所以，用好系统的环境变量， WINRAR 的自解压功能就如虎添翼了。 自解压命令Title设置自解压的窗口标题。 Title=标题 Delete在解压到目标文件夹之前删除指定的文件，允许数个 Delete 命令。 Delete=文件名 License当运行自解压文件时显示指定的作为软件许可协议文本。用户既可以接受它并继续解压或者拒绝它并退出。（可以使用 HTML ）License=许可协议对话框标题{许可协议文本 1许可协议文本 2…} Overwrite如果[n]为 0，在覆盖文件之前用户将会被先询问。这是 覆盖 命令的默认动作，可以不需要指定。如果[n]不存在或是等于[1]，文件将在没有确认的状况下全部覆盖。如果[n]等于[2]，所有已存在的文件将不会被覆盖。 Overwrite=n Silent开始解压时不显示开始对话框。参数 可以是 1 或 2。如果 参数 是 1，开始解压对话框会完全隐藏，包含进程指示和文件名。如果 参数 是 2，则跳过开始解压的确认，但用户仍然可以看到压缩文件的解压进程。 Silent=参数 Path设置默认的目标路径。路径的绝对使用起始点在不更改的情况下为&lt;驱动器号&gt;:，如果 &lt;路径&gt; 只包含了名称，它将会被附加到“Program Files”文件夹下，如果你希望关闭如此的作用，请从“.\\”字符开始定义起始 &lt;路径&gt;。 Path=路径 Presetup自解压在解压之前将试着运行 &lt;程序&gt;，在运行 &lt;程序&gt; 之前必须先指定目标文件夹。你可以使用此命令，比如说，当安装新版本于旧版本上面时，用以删除先前的程序版本。如果程序名包含空格，它必须包含在引号之内。 Presetup=程序 SavePath 这个命令允许自解压程序在注册表中存储用户输入的目标路径，并在自解压文件下一次运行时恢复相同的 Path。原来的 Path命令内容被放在输入目标路径区域的列表下拉菜单中，所以用户可以在以前输入的和原始路径中选择。当安装新版本或更新一些软件到同样的目录时，这个功能可能很便利。它允许只改变一次目标路径，而不需要每次都输入。 SavePath 命令只能和 Path 命令一起使用一次。 Setup在成功解压之后自解压将会试着运行 &lt;程序&gt;。在运行 &lt;程序&gt; 之前，包含已解压文件的文件夹将会设为当前文件夹Setup=程序注意 1) 如果你在使用自解压运行 InstallShield setup.exe 有问题的话，请试着运行 “setup.exe /SMS” 来代替简洁的 “setup.exe”。此开关允许自解压检测安装程序的退出。2) 全部在自解压命令行所指定的参数都会从 Setup=&lt;程序&gt; 命令提交给程序，自解压它自己则只认得 -s 开关，也就是强制缄默安装模式而不显示开始对话框。 TempMode此命令强制自解压创建一个临时目录，将全部文件解压至此，然后开始运行 Setup 命令所指定的程序，并在完成 Setup 程序之后将临时目录中的内容全部清除。当运行这些操作时，自解压会自动设置为 缄默模式。如果 TempMode 命令存在的话，叙述中将有 Setup 命令且不得使用 path 命令。 TempMode 命令可以有字符串参数的选项，在解压之前可用以定义问题和问题的标题。这样的例子，仅在当用户选择了“是” 按钮时才会开始解压。a)TempModeb)TempMode=问题叙述,窗口标题文本 Text它在自解压模块的输出窗口添加指定纯文本或HTML字符串。当自解压模块第一次遇到 Text 命令，在添加&lt;字符串&gt;前，它重设这个窗口默认内容。其后的命令追加&lt;字符串&gt;到已经存在的文本后。依赖于使用的语法，这个命令可以一次添加一个或者数个字符串。 对于纯文本的过程中，为了使字符串和对话框匹配，自解压模块将合并和重新格式化指定的字符串。所以如果你希望重新产生一个新的段落，你需要在它前面放一个空的字符串。（可以使用 HTML ）a)Text=字符串b)Text{字符串 1字符串 2…} shortcut解压时创建快捷方式 shortcut=目标类型,文件路径,目标文件夹,描述,快捷方式名目标类型 是一个一个字符宽的区域，可以有下列值：D 在桌面创建快捷方式S 在开始菜单创建快捷方式P 在开始菜单/程序中创建快捷方式T 在启动菜单中","path":"2018/05/15/1954507039/","date":"05-15","excerpt":"","tags":[{"name":"Windows","slug":"Windows","permalink":"https://yihuishou.github.io/tags/Windows/"}]},{"title":"TinyPNG PS 本地插件安装步骤","text":"你懂的： 点我注意：由于导入注册表的脚本中关于 PhotoShop 的安装路径不一定相同 在导入之前一定要检查该路径是否正确 工具在PhotoShop中的位置： 本工具只能处理PNG图像，压缩JPG图像请使用官网在线工具","path":"2018/05/02/3826197500/","date":"05-02","excerpt":"","tags":[{"name":"Photoshop","slug":"Photoshop","permalink":"https://yihuishou.github.io/tags/Photoshop/"}]},{"title":"IDEA 性能调校","text":"修改idea.exe.vmoptions和idea64.exe.vmoptions配置文件 对 IntelliJ IDEA 内存进行微调，都可以大大提升 IDE 性能。当然，内存分配越多，执行效果就越好。 但是，你也会发现， IDE 之外许多其他应用程序也需要消耗内存，所以，大家的目标应该是在提高性能和内存消耗之间找到一个平衡。 笔者认为，在大多数情况下，把 Xmx 值设置在 2G 和 3G 之间是最佳的。 平衡配置： -Xms2g-Xmx2g-XX:ReservedCodeCacheSize=1024m-XX:+UseCompressedOops 复杂优化配置： -server-Xms2g-Xmx2g-XX:NewRatio=3-Xss16m-XX:+UseConcMarkSweepGC-XX:+CMSParallelRemarkEnabled-XX:ConcGCThreads=4 -XX:ReservedCodeCacheSize=240m-XX:+AlwaysPreTouch-XX:+TieredCompilation-XX:+UseCompressedOops-XX:SoftRefLRUPolicyMSPerMB=50-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-Djsse.enableSNIExtension=false-ea","path":"2018/05/02/2824090707/","date":"05-02","excerpt":"","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yihuishou.github.io/tags/IDEA/"}]},{"title":"PS 快速将多张图片导入到同一图片中","text":"启动Phsotoshop后，通过点击菜单栏上的“文件”，并点击“脚本”，在弹出的菜单中选择“将文件载入堆栈” 在弹出的界面“载入图层”，点击“浏览”按钮，选择要加入的图片。在此处选择文件的时候，可以输入快捷键”Ctrl+A”可把当前文件夹中的内容全部选中，然后点击“确定”","path":"2018/04/27/2001433166/","date":"04-27","excerpt":"","tags":[{"name":"Photoshop","slug":"Photoshop","permalink":"https://yihuishou.github.io/tags/Photoshop/"}]},{"title":"PL/SQL Developer 连接远程数据库","text":"最简单的连接方式数据库链接地址用： IP/数据库名 的方式 示例: 复杂的连接方式在PLSQL Developer\\instantclient_客户端版本\\network\\admin的目录下 建立tnsnames.ora文件 tnsnames.ora文件内容： 显示的连接名 =(DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 远程主机IP )(PORT = 端口号)) ) (CONNECT_DATA = (SERVICE_NAME = 数据库名 ) )) 示例： RemoteLink =(DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1 )(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = ORCL ) )) 配置环境变量 我的电脑选属性-&gt;高级-&gt;环境变量-&gt;系统变量 下 新增两个变量： 变量 值 TNS_ADMIN PLSQL Developer安装目录\\instantclient_客户端版本\\network\\admin NLS_LANG SIMPLIFIED CHINESE_CHINA.ZHS16GBK","path":"2018/04/24/2553779906/","date":"04-24","excerpt":"","tags":[{"name":"Oracle","slug":"Oracle","permalink":"https://yihuishou.github.io/tags/Oracle/"}]},{"title":"Swagger 注解说明","text":"@Api@Api：用在请求的类上，说明该类的作用 tags=”说明该类的作用” value=”该参数没什么意义，所以不需要配置” 示例： @Api(tags=\"APP用户注册Controller\") @ApiOperation@ApiOperation：”用在请求的方法上，说明方法的作用” value=”说明方法的作用” notes=”方法的备注说明” 示例： @ApiOperation(value=\"用户注册\",notes=\"手机号、密码都是必输项，年龄随边填，但必须是数字\") @ApiImplicitParams@ApiImplicitParams：用在请求的方法上，包含一组参数说明 @ApiImplicitParam：用在 @ApiImplicitParams 注解中，指定一个请求参数的配置信息 name：参数名 value：参数的汉字说明、解释 required：参数是否必须传 paramType：参数放在哪个地方 · header –&gt; 请求参数的获取：@RequestHeader · query –&gt; 请求参数的获取：@RequestParam · path（用于restful接口）–&gt; 请求参数的获取：@PathVariable · body（不常用） · form（不常用） dataType：参数类型，默认String，其它值dataType=”Integer” defaultValue：参数的默认值 示列： @ApiImplicitParams(&#123; @ApiImplicitParam(name=\"mobile\",value=\"手机号\",required=true,paramType=\"form\"), @ApiImplicitParam(name=\"password\",value=\"密码\",required=true,paramType=\"form\"), @ApiImplicitParam(name=\"age\",value=\"年龄\",required=true,paramType=\"form\",dataType=\"Integer\")&#125;) @ApiResponses@ApiResponses：用于请求的方法上，表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如”请求参数没填好” response：抛出异常的类 示例： @ApiOperation(value = \"select1请求\",notes = \"多个参数，多种的查询参数类型\")@ApiResponses(&#123; @ApiResponse(code=400,message=\"请求参数没填好\"), @ApiResponse(code=404,message=\"请求路径没有或页面跳转路径不对\")&#125;) @ApiModel@ApiModel：用于响应类上，表示一个返回响应数据的信息 （这种一般用在post创建的时候，使用@RequestBody这样的场景， 请求参数无法使用@ApiImplicitParam注解进行描述的时候） @ApiModelProperty：用在属性上，描述响应类的属性 示例: import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import java.io.Serializable;@ApiModel(description= \"返回响应数据\")public class RestMessage implements Serializable&#123; @ApiModelProperty(value = \"是否成功\") private boolean success=true; @ApiModelProperty(value = \"返回对象\") private Object data; @ApiModelProperty(value = \"错误编号\") private Integer errCode; @ApiModelProperty(value = \"错误信息\") private String message; /* getter/setter */&#125;","path":"2018/04/23/432974338/","date":"04-23","excerpt":"","tags":[{"name":"Swagger","slug":"Swagger","permalink":"https://yihuishou.github.io/tags/Swagger/"}]},{"title":"SpringBoot Restful API 的问题","text":"Restful 风格接口调用资源的方式一般都是Crud操作 添加 @PostMapping 删除 @DeleteMapping 修改 @PutMapping 查询 @GetMapping SpringBoot 在使用 @DeleteMapping @PutMapping 时要注意这两个参数问题 不能直接使用表单提交和URL提交 只能使用URL/形式配合@PathVariable 来使用 @PathVariable (“xxx”)， xxx 如果与参数名完全相同则可省略在参数前直接添加@PathVariable 即可 在方法参数中 需要添加 @RequestBody 注解才能解析 Json 作为参数 对于只有值没有属性的参数，前端不应使用 Json 传递，使用 路径传递","path":"2018/04/18/878159451/","date":"04-18","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"解决 SpringCloud Fegin 无法传递参数的问题","text":"在看教程的时候发现，平时使用springMVC习惯不加注解。会在springCloud中引起大麻烦 基于微服务的四大基本原则： 基于AFK拆分原则 无状态服务 前后分离 基于Restful API接口 其中由于是基于Restful 接口，所以不指定@RequestMapping的提交方式是不行的 并且交给SpingMVC自动推断属性名也是不行的 @RequestParam（value=”xxx”） （省略写法 @RequestParam（”xxx”））是必须的 以前写controller层的时候都是默认带上 @RequestParam 的， 今天发现不加 @RequestParam 也能接收到参数 如果要@RequestParam为一个int型的数据传值，假如前端并未输入，那么将会为int型的数据赋值为null。显然，这是不允许的，直接报错。可以通过required=false或者true来要求@RequestParam配置的前端参数是否一定要传 下面我们来区分一下加与不加的区别 这里有两种写法 @RequestMapping(\"/list\") public String test(@RequestParam Long parentId) &#123; &#125; ``` ``` java @RequestMapping(\"/list\") public String test(Long parentId) &#123; &#125; ``` 第一种 必须带有参数,也就是说你直接输入 localhost:8080/list 会报错 不会执行方法 只能输入 localhost:8080/list?parentId=? 才能执行相应的方法第二种 可带参数也可不带参数 就是说你输入 localhost:8080/list 以及 localhost:8080/list?parentId=? 方法都能执行当然你也可以设置 @RequestParam 里面的required为false(默认为true 代表必须带参数) 这样就跟第二种是一样的了如下:``` java @RequestMapping(\"/list\") public String test(@RequestParam(required=false) Long parentId) &#123; ..... &#125; 当然你还可以设置里面的defaultValue的属性如下: @RequestMapping(\"/list\") public String test(@RequestParam(defaultValue=\"0\") Long parentId) { ..... } 这样在地址里面也可以不带参数，如果带了参数会接收，不带参数会默认为0 里面还有一个value属性也讲一下， 前面所有的方法 传入的参数必须为parentId 才能接收到值 但是如果你加了value属性 @RequestMapping(\"/list\") public String test(@RequestParam(value=\"id\") Long parentId) { .. } 这样会用id 代替parentId 也就是说你地址里面传入的参数名称为id localhost:8080/list?id＝？ 这种","path":"2018/04/13/3733447055/","date":"04-13","excerpt":"","tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://yihuishou.github.io/tags/SpringCloud/"}]},{"title":"解决 Mysql 错误：1045","text":"在命令行输入mysql -u root –p，输入密码，或通过工具连接数据库时，经常出现下面的错误信息，详细该错误信息很多人在使用MySQL时都遇到过。 ERROR 1045 (28000): Access denied for user ‘root’@’localhost’ (using password: YES) 通常从网上都能找到解决方案： ** 1.停止服务：停止MySQL服务； windows net stop mysql linux service mysqld stop 2.跳过验证：修改MySQL安装目录下的my.ini配置文件，使登录时跳过权限检查； 到mysql根目录找到mysql配置文件 vim my.ini #在my.ini，mysqld下添加一行，使其登录时跳过权限检查 skip_grant_tables 3.修改密码：启动MySQL服务，登录MySQL，此时提示输入密码，输入任意密码回车即可进入MySQL。 #登录mysqlmysql -u root -p 然后通过SQL语句修改root用户的密码； #将数据库切换至mysql库mysql&gt; USE mysql;#修改密码mysql&gt; UPDATE user SET password=PASSWORD(‘newpasswd’)WHERE user=’root’;#刷新MySQL权限相关的表mysql&gt; flush privileges;mysql&gt; exit; 4.重启服务：将my.ini文件中加入的跳过权限语句删除或加#号注释。重启服务，使用修改后的密码登录即可。 本地改数据库授权mysql -uroot -p use mysql; select host,user from user where user=’root’; 如果上面查询到有信息,但host为localhost或其他值，就需要根据实际需求来更新表信息update user set host=’%’ where user=’root’ # 如果想任何的IP地址都可以使用root用户来远程登陆（注意如果上面的查询语句，查询出来有多条，就需要做一些处理，比如多加一个条件如 where user=’root’ and host=’localhost’或先删除其他人记录只保存一条user=’root’的记录） 远程授权GRANT ALL PRIVILEGES ON . TO ‘root’@’%’ IDENTIFIED BY ‘password’ WITH GRANT OPTION; grant all privileges on 库名.表名 to &#39;用户名&#39;@&#39;IP地址&#39; identified by &#39;密码&#39; with grant option;","path":"2018/04/08/870412291/","date":"04-08","excerpt":"","tags":[{"name":"Mysql","slug":"Mysql","permalink":"https://yihuishou.github.io/tags/Mysql/"}]},{"title":"BAT 出身的人就很厉害吗？","text":"不知道什么时候，出现了一种对于BAT的盲目崇拜，可能是成功学吧，也有可能是玄学，或是什么无法被命名的学说，BAT与成功划上了等号，似乎只要是BAT出来的，就代表成功了一大半。为此我深表痛苦，感叹到在历史的长河中，重复了无数次的教训，咋就没人吸取呢？ 于是因为“梦想”也因为“现实”，我开始接触了些BAT出身的“大牛们”，其中运营和产品居多，当我提到一些比较“刁钻”的问题时，我发现他们有着高度统一的发言方式，比如我在BAT某某产品线的时候，负责的领域，销售额达到多少多少，注册用户达到多少多少，所以现在这个公司做这种模式，是没任何问题的，想当年我在BAT里怎么怎么样。 突然让我想起了个我年幼时期的场景，那年东北大下岗，我一个叔叔在当年挤破脑袋都进不去的大厂里负责销售，干了20多年被下岗了，找到一个当年比较知名的防盗门品牌应聘，99年地方负责人看到这个履历都吓傻了，好烟好酒的伺候着，希望我这个叔叔能给他们地方带来优秀的业绩，我这个叔儿也跟大爷一样，带着官僚气息，到处的去跑属于上个时代产物的“供销社”关系，形式当然是“签单”被赊账，半年后，他被开除了，没过多久雇佣他的那家公司也倒闭了，知道这个故事的时候，这个叔叔正在酒桌上，一边吃着涮肚一边大骂老板，说我卖了这么多门，不就是被人欠点钱么！ 当年的我，觉得错都在老板，因为我不认识他，而这个叔叔给我买了两本十万个为什么，所以我打心里，觉得这个叔叔是对的。可是现如今，我有了截然不同的思考方式，看待这个问题的时候，发生了极大的转变。 我们现在所处的社会每天都发生的剧烈的变化，经验主义变的越来越不靠谱，对于分工协作的要求也越来越高，公司越大，职能岗位分的越细，很多时候在一个庞大的流水线里，我们扮演的都是其中一颗渺小的螺丝钉，无论是那些我见过的BAT产品和运营，还是我这个叔叔，公司运作的劳动结果，永远是一群人共同努力的见证，而并非一个人的功劳，但在这个时代里，每个人都扮演着全能自恋的自己，认为那些成绩都是因为“我”才得以实现，忽略了共同协作的过程中，其他个体或整体协作所带来的价值。也忽略了站在巨人的肩膀上与巨人脚下的区别。 于是，前仆后继的BAT系的流水线工人，投身于创业的浪潮里，一波接着一波，刷着数据，刷着媒体，刷着出身的迷之自信，鼓吹着让大家信服他当年，伟大且成功的故事，甚至有人把创业比作要会讲故事，哈哈哈哈哈，想想就是66666，当然我也没法子说他们是错的，谁叫我没有广义上的成功光环呢,。 最后，我只想通过几个问题来总结几条逻辑 1.BAT出身的人，真的就代表着成功么？ 答：“没有任何一条理论与数据可以支撑这个逻辑”。 2.BAT创业成功的几率一定很高么？ 答：“中国的媒体对于成功的定义标准是不确定的，而且经常被偷换概念，但如果以上市敲钟作为衡量标准的话，这个几率挺低的。如果以BAT内竞淘汰的团队比例来说，跟市场上不知名公司出身的成功几率也是差不多的，” 转自知乎","path":"2018/04/08/4119657311/","date":"04-08","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"开发中的独孤九剑","text":"九剑真髓 九剑其实不是一般概念中的剑法招式，而是一套武学理论，所以风清扬会说要看悟性，因为这不是动作有多难，难到做不出来，而是脑袋想不想得到，基本上用禅宗顿悟的模式就比较容易理解。九剑到底是什么？根据风清扬说的原文推测，他应该是把人能做的动作，全部拆解，透过分析对手的目前姿势，他能做的动作有哪些？对手哪个部位、哪条肌肉有动作徵兆，推算他下一步只可能是什么招式？这就是风清杨一再强调的“料敌机先”，也就是九剑的真正精髓。 只攻不守 令狐冲道：“是。”闭上眼睛，将这一晚所学大要，默默存想了一遍，突然睁开眼来，道：“太师叔，徒孙尚有一事未明，何以这种种变化，尽是进手招数，只攻不守？”风清扬道：“独孤九剑，有进无退！招招都是进攻，攻敌之不得不守，自己当然不用守了。 要旨在于「悟性」 风清扬道：“你倒也不可妄自菲薄，独孤前辈是绝顶聪明之人，学他的剑法，要旨是在一个‘悟’字，决不在死记硬记。等到通晓了这九剑的剑意，则无所施而不可，无所不出，无所不入，便是将全部变化尽数忘记，也不相干，临敌之际，更是忘记得越干净彻底，越不受原来剑法的拘束。 总诀：「归妹趋无妄，无妄趋同人，同人趋大有。甲转丙，丙转庚，庚转癸。子丑之交，辰巳之交，午未之 交。风雷是一变，山泽是一变，水火是一变。乾坤相激，震兑相激，离巽相激。三增而成五，五增而成九……」 九剑与开发 剑术在于料敌先机和破招，这与开发解决问题也是异曲同工之妙。 大丈夫行事，爱怎样便怎样，行云流水，任意所至。","path":"2018/03/21/2644766663/","date":"03-21","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"IDEA 导出 Jar 包执行报错","text":"到处Jar包找不到找不到主清单属性的错误解决方法SpringBoot的解决方案补全pom配置文件 &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 导出一般的Jar包解决方案确保MANIFEST.MF文件在 src/main/resources/META_INF/而不是 src/main/java/META_INF/","path":"2018/03/05/928293067/","date":"03-05","excerpt":"","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yihuishou.github.io/tags/IDEA/"}]},{"title":"三大定律","text":"墨菲定律 任何事都没有表面看起来那么简单 所有的事都会比你预计的时间长 会出错的事总会出错（前提是无限长的时间和概率不为0） 如果你担心某种情况发生，那么它就更有可能发生 帕金森定律 只要还有时间，工作就会不断扩展，直到用完所有的时间。 工作会自动占满一个人所有可用的时间。如果一个人给自己安排了充裕的时间去完成一项工作，他就会放慢节奏或者增加其他项目以便用掉所有的时间。 工作膨胀出来的复杂性会使工作显得很重要，在这种时间弹性很大的环境中工作并不会感到轻松。相反会因为工作的拖沓、膨胀而苦闷、劳累，从而精疲力竭。 彼德原理 一个人，无论你有多大的聪明才智，也无论你如何努力进取，总会有一个你胜任不了的职位在等待着你，并且你一定会达到那个位置。","path":"2018/01/24/3889357332/","date":"01-24","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"关于医疗用药","text":"一波流感Gank之后~ 咱发现医疗用的药也是很主要的 以下记录了一些用来对抗病毒感冒的特效药（细菌性感冒就算了，随便用点抗生素就搞定了） 一代神药 奥司他韦 专治甲乙型流感 且具有预防特性 广谱病毒克星 病毒灵 （盐酸吗啉胍） 专治亚洲A型流感 金刚烷胺 盐酸金刚乙胺 肌肉性抗炎药 扶她林 氯雷他定 氢溴酸右美沙芬 愈创木酚磺酸钾口服液 盐酸氨溴索口服溶液 对乙酰氨基酚 阿司匹林","path":"2018/01/22/2822032196/","date":"01-22","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"JDK 字符串截取的坑","text":"记述一个由JDK1.6升级到1.8的坑 String str = \"abc\";String [] chars = str.split(\"\");// JDK 7及以下版本结果 : [\"\",\"a\",\"b\",\"c\"]// JDK 8版本: [\"a\",\"b\",\"c\"] 进行字符串拆分的时候一定要注意JDK的版本","path":"2018/01/18/3575145262/","date":"01-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"好用的 VsCode 插件","text":"好用的插件记录了一些收集的插件 主题插件 Theme-TinaciousDesign OneDark-Pro Brackets Light Pro 代码插件 Auto Close Tag Auto Rename Tag 功能插件 Debugger for Chrome HTML Snippets JavaScript (ES6) snippets Path Intellisense Project Manager Prettify JSON vscode-Hexo HTML CSS Support 主题插件 Beautify Material Icon Theme NPM插件 Node.js Modules Intellisense npm npm Intellisense NPM Smart Importer Vue专属插件 Vetur Vue 2 Snippets Vue Snippets(vue-ls) iviewui-snippets","path":"2018/01/02/209983386/","date":"01-02","excerpt":"","tags":[{"name":"VsCode","slug":"VsCode","permalink":"https://yihuishou.github.io/tags/VsCode/"}]},{"title":"重建 Windows 图标缓存","text":"通常用于解决系统文件或文件夹图标的错乱问题 用以下脚本建立.bat文件并执行即可 rem 关闭explorer.exetaskkill /f /im explorer.exeattrib -h -i %userprofile%\\AppData\\Local\\IconCache.dbdel %userprofile%\\AppData\\Local\\IconCache.db /arem 打开explorerstart explorer.exe","path":"2017/12/27/1367914797/","date":"12-27","excerpt":"","tags":[{"name":"Windows","slug":"Windows","permalink":"https://yihuishou.github.io/tags/Windows/"}]},{"title":"解决 Vue 用 Webpack 打包空白的问题","text":"打包时提示错误信息: Tip: built files are meant to be served over an HTTP server. Opening index.html over file:// won&#39;t work. 解决：更改config/index.js中的参数assetsPublicPath:&#39;/&#39; 为 assetsPublicPath:&#39;./&#39; 强制使用相对路径时，则应改为 assetsPublicPath:&#39;&#39; 使用了Vue-Router时则应在Router中配置项目基准路径 export default new Router(&#123; mode : 'history', base: '/xxx/', // xxx 为访问的项目名 ... &#125;","path":"2017/12/26/2494496423/","date":"12-26","excerpt":"","tags":[{"name":"Vue","slug":"Vue","permalink":"https://yihuishou.github.io/tags/Vue/"}]},{"title":"用文件特征码来检测文件类型","text":"现有一文件，其扩展名未知或标记错误。假设它是一个正常的、非空的文件，且将扩展名更正后可以正常使用，那么，如何判断它是哪种类型的文件？在后缀未知，或者后缀被修改的文件，依然通过文件头来判断该文件究竟是什么文件类型。我们可以使用一个文本编辑工具如UltraEdit打开文件（16进制模式下），然后看文件头是什么字符，以下是常见文件类型的文件头字符(16进制)，希望对你有帮助：JPEG (jpg)，文件头：FFD8FFPNG (png)，文件头：89504E47GIF (gif)，文件头：47494638TIFF (tif)，文件头：49492A00Windows Bitmap (bmp)，文件头：424DCAD (dwg)，文件头：41433130Adobe Photoshop (psd)，文件头：38425053Rich Text Format (rtf)，文件头：7B5C727466XML (xml)，文件头：3C3F786D6CHTML (html)，文件头：68746D6C3EEmail [thorough only] (eml)，文件头：44656C69766572792D646174653AOutlook Express (dbx)，文件头：CFAD12FEC5FD746FOutlook (pst)，文件头：2142444EMS Word/Excel (xls.or.doc)，文件头：D0CF11E0MS Access (mdb)，文件头：5374616E64617264204AWordPerfect (wpd)，文件头：FF575043Postscript (eps.or.ps)，文件头：252150532D41646F6265Adobe Acrobat (pdf)，文件头：255044462D312EQuicken (qdf)，文件头：AC9EBD8FWindows Password (pwl)，文件头：E3828596ZIP Archive (zip)，文件头：504B0304RAR Archive (rar)，文件头：52617221Wave (wav)，文件头：57415645AVI (avi)，文件头：41564920Real Audio (ram)，文件头：2E7261FDReal Media (rm)，文件头：2E524D46MPEG (mpg)，文件头：000001BAMPEG (mpg)，文件头：000001B3Quicktime (mov)，文件头：6D6F6F76Windows Media (asf)，文件头：3026B2758E66CF11MIDI (mid)，文件头：4D546864 下面在提供一个网上使用java写的根据头文件码判断文件类型 package com;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.IOException;import java.util.Date;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import java.util.Set;public class FileType &#123; public final static Map&lt;String, String&gt; FILE_TYPE_MAP = new HashMap&lt;String, String&gt;(); private FileType()&#123;&#125; static&#123; getAllFileType(); //初始化文件类型信息 &#125; /** * Discription:[getAllFileType,常见文件头信息] */ private static void getAllFileType() &#123; FILE_TYPE_MAP.put(\"ffd8ffe000104a464946\", \"jpg\"); //JPEG (jpg) FILE_TYPE_MAP.put(\"89504e470d0a1a0a0000\", \"png\"); //PNG (png) FILE_TYPE_MAP.put(\"47494638396126026f01\", \"gif\"); //GIF (gif) FILE_TYPE_MAP.put(\"49492a00227105008037\", \"tif\"); //TIFF (tif) FILE_TYPE_MAP.put(\"424d228c010000000000\", \"bmp\"); //16色位图(bmp) FILE_TYPE_MAP.put(\"424d8240090000000000\", \"bmp\"); //24位位图(bmp) FILE_TYPE_MAP.put(\"424d8e1b030000000000\", \"bmp\"); //256色位图(bmp) FILE_TYPE_MAP.put(\"41433130313500000000\", \"dwg\"); //CAD (dwg) FILE_TYPE_MAP.put(\"3c21444f435459504520\", \"html\"); //HTML (html) FILE_TYPE_MAP.put(\"3c21646f637479706520\", \"htm\"); //HTM (htm) FILE_TYPE_MAP.put(\"48544d4c207b0d0a0942\", \"css\"); //css FILE_TYPE_MAP.put(\"696b2e71623d696b2e71\", \"js\"); //js FILE_TYPE_MAP.put(\"7b5c727466315c616e73\", \"rtf\"); //Rich Text Format (rtf) FILE_TYPE_MAP.put(\"38425053000100000000\", \"psd\"); //Photoshop (psd) FILE_TYPE_MAP.put(\"46726f6d3a203d3f6762\", \"eml\"); //Email [Outlook Express 6] (eml) FILE_TYPE_MAP.put(\"d0cf11e0a1b11ae10000\", \"doc\"); //MS Excel 注意：word、msi 和 excel的文件头一样 FILE_TYPE_MAP.put(\"d0cf11e0a1b11ae10000\", \"vsd\"); //Visio 绘图 FILE_TYPE_MAP.put(\"5374616E64617264204A\", \"mdb\"); //MS Access (mdb) FILE_TYPE_MAP.put(\"252150532D41646F6265\", \"ps\"); FILE_TYPE_MAP.put(\"255044462d312e350d0a\", \"pdf\"); //Adobe Acrobat (pdf) FILE_TYPE_MAP.put(\"2e524d46000000120001\", \"rmvb\"); //rmvb/rm相同 FILE_TYPE_MAP.put(\"464c5601050000000900\", \"flv\"); //flv与f4v相同 FILE_TYPE_MAP.put(\"00000020667479706d70\", \"mp4\"); FILE_TYPE_MAP.put(\"49443303000000002176\", \"mp3\"); FILE_TYPE_MAP.put(\"000001ba210001000180\", \"mpg\"); // FILE_TYPE_MAP.put(\"3026b2758e66cf11a6d9\", \"wmv\"); //wmv与asf相同 FILE_TYPE_MAP.put(\"52494646e27807005741\", \"wav\"); //Wave (wav) FILE_TYPE_MAP.put(\"52494646d07d60074156\", \"avi\"); FILE_TYPE_MAP.put(\"4d546864000000060001\", \"mid\"); //MIDI (mid) FILE_TYPE_MAP.put(\"504b0304140000000800\", \"zip\"); FILE_TYPE_MAP.put(\"526172211a0700cf9073\", \"rar\"); FILE_TYPE_MAP.put(\"235468697320636f6e66\", \"ini\"); FILE_TYPE_MAP.put(\"504b03040a0000000000\", \"jar\"); FILE_TYPE_MAP.put(\"4d5a9000030000000400\", \"exe\");//可执行文件 FILE_TYPE_MAP.put(\"3c25402070616765206c\", \"jsp\");//jsp文件 FILE_TYPE_MAP.put(\"4d616e69666573742d56\", \"mf\");//MF文件 FILE_TYPE_MAP.put(\"3c3f786d6c2076657273\", \"xml\");//xml文件 FILE_TYPE_MAP.put(\"494e5345525420494e54\", \"sql\");//xml文件 FILE_TYPE_MAP.put(\"7061636b616765207765\", \"java\");//java文件 FILE_TYPE_MAP.put(\"406563686f206f66660d\", \"bat\");//bat文件 FILE_TYPE_MAP.put(\"1f8b0800000000000000\", \"gz\");//gz文件 FILE_TYPE_MAP.put(\"6c6f67346a2e726f6f74\", \"properties\");//bat文件 FILE_TYPE_MAP.put(\"cafebabe0000002e0041\", \"class\");//bat文件 FILE_TYPE_MAP.put(\"49545346030000006000\", \"chm\");//bat文件 FILE_TYPE_MAP.put(\"04000000010000001300\", \"mxp\");//bat文件 FILE_TYPE_MAP.put(\"504b0304140006000800\", \"docx\");//docx文件 FILE_TYPE_MAP.put(\"d0cf11e0a1b11ae10000\", \"wps\");//WPS文字wps、表格et、演示dps都是一样的 FILE_TYPE_MAP.put(\"6431303a637265617465\", \"torrent\"); FILE_TYPE_MAP.put(\"6D6F6F76\", \"mov\"); //Quicktime (mov) FILE_TYPE_MAP.put(\"FF575043\", \"wpd\"); //WordPerfect (wpd) FILE_TYPE_MAP.put(\"CFAD12FEC5FD746F\", \"dbx\"); //Outlook Express (dbx) FILE_TYPE_MAP.put(\"2142444E\", \"pst\"); //Outlook (pst) FILE_TYPE_MAP.put(\"AC9EBD8F\", \"qdf\"); //Quicken (qdf) FILE_TYPE_MAP.put(\"E3828596\", \"pwl\"); //Windows Password (pwl) FILE_TYPE_MAP.put(\"2E7261FD\", \"ram\"); //Real Audio (ram) &#125; /** * 得到上传文件的文件头 * @param src * @return */ public static String bytesToHexString(byte[] src) &#123; StringBuilder stringBuilder = new StringBuilder(); if (src == null || src.length &lt;= 0) &#123; return null; &#125; for (int i = 0; i &lt; src.length; i++) &#123; int v = src[i] &amp; 0xFF; String hv = Integer.toHexString(v); if (hv.length() &lt; 2) &#123; stringBuilder.append(0); &#125; stringBuilder.append(hv); &#125; return stringBuilder.toString(); &#125; /** * 根据制定文件的文件头判断其文件类型 * @param filePaht * @return */ public static String getFileType(String filePaht)&#123; String res = null; try &#123; FileInputStream is = new FileInputStream(filePaht); byte[] b = new byte[10]; is.read(b, 0, b.length); String fileCode = bytesToHexString(b); System.out.println(fileCode); //这种方法在字典的头代码不够位数的时候可以用但是速度相对慢一点 Iterator&lt;String&gt; keyIter = FILE_TYPE_MAP.keySet().iterator(); while(keyIter.hasNext())&#123; String key = keyIter.next(); if(key.toLowerCase().startsWith(fileCode.toLowerCase()) || fileCode.toLowerCase().startsWith(key.toLowerCase()))&#123; res = FILE_TYPE_MAP.get(key); break; &#125; &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return res; &#125; public static void main(String[] args) throws Exception &#123; String type = getFileType(\"C:/test/eee.WMV\"); System.out.println(\"eee.WMV : \"+type); System.out.println(); type = getFileType(\"C:/test/350996.wav\"); System.out.println(\"350996.wav : \"+type); System.out.println(); &#125;&#125; 这个是反向检测读取文件类型的示例 import java.io.FileInputStream;public class FileType&#123; public static String bytesToHexString(byte[] src) &#123; StringBuilder stringBuilder = new StringBuilder(); if (src == null || src.length &lt;= 0) &#123; return null; &#125; for (int i = 0; i &lt; src.length; i++) &#123; int v = src[i] &amp; 0xFF; String hv = Integer.toHexString(v); if (hv.length() &lt; 2) &#123; stringBuilder.append(0); &#125; stringBuilder.append(hv); &#125; return stringBuilder.toString(); &#125; /** * @param args */ public static void main(String[] args) throws Exception &#123; FileInputStream is = new FileInputStream(\"F:\\\\相册\\\\微信图片\\\\03.jpg\"); byte[] b = new byte[3]; is.read(b, 0, b.length); String xxx = bytesToHexString(b); xxx = xxx.toUpperCase(); System.out.println(\"头文件是：\" + xxx); String ooo = TypeDict.checkType(xxx); System.out.println(\"后缀名是：\" + ooo); &#125; &#125;","path":"2017/12/22/3001741591/","date":"12-22","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"优雅地使用泛型","text":"泛型，一个孤独的守门者。 大家可能会有疑问，我为什么叫做泛型是一个守门者。这其实是我个人的看法而已，我的意思是说泛型没有其看起来那么深不可测，它并不神秘与神奇。泛型是 Java 中一个很小巧的概念，但同时也是一个很容易让人迷惑的知识点，它让人迷惑的地方在于它的许多表现有点违反直觉。 文章开始的地方，先给大家奉上一道经典的测试题。 List&lt;String&gt; l1 = new ArrayList&lt;String&gt;();List&lt;Integer&gt; l2 = new ArrayList&lt;Integer&gt;();System.out.println(l1.getClass() == l2.getClass()); 请问，上面代码最终结果输出的是什么？不了解泛型的和很熟悉泛型的同学应该能够答出来，而对泛型有所了解，但是了解不深入的同学可能会答错。 正确答案是 true。 上面的代码中涉及到了泛型，而输出的结果缘由是类型擦除。先好好说说泛型。 泛型是什么？泛型的英文是 generics，generic 的意思是通用,而翻译成中文，泛应该意为广泛，型是类型。所以泛型就是能广泛适用的类型。 但泛型还有一种较为准确的说法就是为了参数化类型，或者说可以将类型当作参数传递给一个类或者是方法。 那么，如何解释类型参数化呢？ public class Cache &#123; Object value; public Object getValue() &#123; return value; &#125; public void setValue(Object value) &#123; this.value = value; &#125;&#125; 假设 Cache 能够存取任何类型的值，于是，我们可以这样使用它。 Cache cache = new Cache();cache.setValue(134);int value = (int) cache.getValue();cache.setValue(\"hello\");String value1 = (String) cache.getValue(); 使用的方法也很简单，只要我们做正确的强制转换就好了。 但是，泛型却给我们带来了不一样的编程体验。 public class Cache&lt;T&gt; &#123; T value; public Object getValue() &#123; return value; &#125; public void setValue(T value) &#123; this.value = value; &#125;&#125; 这就是泛型，它将 value 这个属性的类型也参数化了，这就是所谓的参数化类型。再看它的使用方法。 Cache&lt;String&gt; cache1 = new Cache&lt;String&gt;();cache1.setValue(\"123\");String value2 = cache1.getValue();Cache&lt;Integer&gt; cache2 = new Cache&lt;Integer&gt;();cache2.setValue(456);int value3 = cache2.getValue(); 最显而易见的好处就是它不再需要对取出来的结果进行强制转换了。但，还有另外一点不同。这里写图片描述泛型除了可以将类型参数化外，而参数一旦确定好，如果类似不匹配，编译器就不通过。上面代码显示，无法将一个 String 对象设置到 cache2 中，因为泛型让它只接受 Integer 的类型。 所以，综合上面信息，我们可以得到下面的结论。 与普通的 Object 代替一切类型这样简单粗暴而言，泛型使得数据的类别可以像参数一样由外部传递进来。它提供了一种扩展能力。它更符合面向抽象开发的软件编程宗旨。当具体的类型确定后，泛型又提供了一种类型检测的机制，只有相匹配的数据才能正常的赋值，否则编译器就不通过。所以说，它是一种类型安全检测机制，一定程度上提高了软件的安全性防止出现低级的失误。泛型提高了程序代码的可读性，不必要等到运行的时候才去强制转换，在定义或者实例化阶段，因为 Cache 这个类型显化的效果，程序员能够一目了然猜测出代码要操作的数据类型。下面的文章，我们正常介绍泛型的相关知识。 泛型的定义和使用泛型按照使用情况可以分为 3 种。 泛型类。 泛型方法。 泛型接口。 泛型类我们可以这样定义一个泛型类。 public class Test&lt;T&gt; &#123; T field1;&#125; 尖括号 &lt;&gt; 中的 T 被称作是类型参数，用于指代任何类型。事实上，T 只是一种习惯性写法，如果你愿意。你可以这样写。 public class Test&lt;Hello&gt; &#123; Hello field1;&#125; 但出于规范的目的，Java 还是建议我们用单个大写字母来代表类型参数。常见的如： T 代表一般的任何类。 E 代表 Element 的意思，或者 Exception 异常的意思。 K 代表 Key 的意思。 V 代表 Value 的意思，通常与 K 一起配合使用。 S 代表 Subtype 的意思，文章后面部分会讲解示意。 如果一个类被 的形式定义，那么它就被称为是泛型类。 那么对于泛型类怎么样使用呢？ Test&lt;String&gt; test1 = new Test&lt;&gt;();Test&lt;Integer&gt; test2 = new Test&lt;&gt;(); 只要在对泛型类创建实例的时候，在尖括号中赋值相应的类型便是。T 就会被替换成对应的类型，如 String 或者是 Integer。你可以相像一下，当一个泛型类被创建时，内部自动扩展成下面的代码。 public class Test&lt;String&gt; &#123; String field1;&#125; 当然，泛型类不至接受一个类型参数，它还可以这样接受多个类型参数。 public class MultiType &lt;E,T&gt;&#123; E value1; T value2; public E getValue1()&#123; return value1; &#125; public T getValue2()&#123; return value2; &#125;&#125; 泛型方法public class Test1 &#123; public &lt;T&gt; void testMethod(T t)&#123; &#125;&#125; 泛型方法与泛型类稍有不同的地方是，类型参数也就是尖括号那一部分是写在返回值前面的。 中的 T 被称为类型参数，而方法中的 T 被称为参数化类型，它不是运行时真正的参数。 当然，声明的类型参数，其实也是可以当作返回值的类型的。 public &lt;T&gt; T testMethod1(T t)&#123; return null;&#125; 泛型类与泛型方法的共存现象public class Test1&lt;T&gt;&#123; public void testMethod(T t)&#123; System.out.println(t.getClass().getName()); &#125; public &lt;T&gt; T testMethod1(T t)&#123; return t; &#125;&#125; 上面代码中，Test1 是泛型类，testMethod 是泛型类中的普通方法，而 testMethod1 是一个泛型方法。而泛型类中的类型参数与泛型方法中的类型参数是没有相应的联系的，泛型方法始终以自己定义的类型参数为准。 所以，针对上面的代码，我们可以这样编写测试代码。 Test1&lt;String&gt; t = new Test1();t.testMethod(\"generic\");Integer i = t.testMethod1(new Integer(1)); 泛型类的实际类型参数是 String，而传递给泛型方法的类型参数是 Integer，两者不想干。 但是，为了避免混淆，如果在一个泛型类中存在泛型方法，那么两者的类型参数最好不要同名。比如，Test1 代码可以更改为这样 public class Test1&lt;T&gt;&#123; public void testMethod(T t)&#123; System.out.println(t.getClass().getName()); &#125; public &lt;E&gt; E testMethod1(E e)&#123; return e; &#125;&#125; 泛型接口泛型接口和泛型类差不多，所以一笔带过。 public interface Iterable {} 通配符 ？除了用 表示泛型外，还有 &lt;?&gt; 这种形式。？ 被称为通配符。 可能有同学会想，已经有了 的形式了，为什么还要引进 &lt;?&gt; 这样的概念呢？ class Base&#123;&#125;class Sub extends Base&#123;&#125;Sub sub = new Sub();Base base = sub; 上面代码显示，Base 是 Sub 的父类，它们之间是继承关系，所以 Sub 的实例可以给一个 Base 引用赋值，那么 List&lt;Sub&gt; lsub = new ArrayList&lt;&gt;();List&lt;Base&gt; lbase = lsub; 最后一行代码成立吗？编译会通过吗？ 答案是否定的。 编译器不会让它通过的。Sub 是 Base 的子类，不代表 List 和 List 有继承关系。 但是，在现实编码中，确实有这样的需求，希望泛型能够处理某一范围内的数据类型，比如某个类和它的子类，对此 Java 引入了通配符这个概念。 所以，通配符的出现是为了指定泛型中的类型范围。 通配符有 3 种形式。 被称作无限定的通配符。 被称作有上限的通配符。 被称作有下限的通配符。 #### 无限定通配符 public void testWildCards(Collection&lt;?&gt; collection)&#123;&#125; 上面的代码中，方法内的参数是被无限定通配符修饰的 Collection 对象，它隐略地表达了一个意图或者可以说是限定，那就是 testWidlCards() 这个方法内部无需关注 Collection 中的真实类型，因为它是未知的。所以，你只能调用 Collection 中与类型无关的方法。 public class Test &#123; public void testWildCards(Collection &lt;?&gt; collection) &#123; collection.add(\"Text\"); // 编译不通过 collection.add(9999999); // 编译不通过 collection.isEmpty(); // 编译通过 collection.clear(); // 编译通过 collection.size(); // 编译通过 &#125;&#125; 我们可以看到，当 存在时，Collection 对象丧失了 add() 方法的功能，编译器不通过。我们再看代码。 List&lt;?&gt; wildlist = new ArrayList&lt;String&gt;();wildlist.add(123);// 编译不通过 有人说，&lt;?&gt; 提供了只读的功能，也就是它删减了增加具体类型元素的能力，只保留与具体类型无关的功能。它不管装载在这个容器内的元素是什么类型，它只关心元素的数量、容器是否为空？我想这种需求还是很常见的吧。 有同学可能会想，&lt;?&gt; 既然作用这么渺小，那么为什么还要引用它呢？  个人认为，提高了代码的可读性，程序员看到这段代码时，就能够迅速对此建立极简洁的印象，能够快速推断源码作者的意图。 &lt;? extends T&gt;&lt;?&gt; 代表着类型未知，但是我们的确需要对于类型的描述再精确一点，我们希望在一个范围内确定类别，比如类型 A 及 类型 A 的子类都可以。 public void testSub(Collection&lt;? extends Base&gt; para)&#123;&#125; 上面代码中，para 这个 Collection 接受 Base 及 Base 的子类的类型。 但是，它仍然丧失了写操作的能力。也就是说 para.add(new Sub());para.add(new Base()); 仍然编译不通过。 没有关系，我们不知道具体类型，但是我们至少清楚了类型的范围。 &lt;? super T&gt;这个和 &lt;? extends T&gt; 相对应，代表 T 及 T 的超类。 public void testSuper(Collection&lt;? super Sub&gt; para)&#123;&#125; &lt;? super T&gt; 神奇的地方在于，它拥有一定程度的写操作的能力。 public void testSuper(Collection&lt;? super Sub&gt; para)&#123; para.add(new Sub());//编译通过 para.add(new Base());//编译不通过&#125; 通配符与类型参数的区别一般而言，通配符能干的事情都可以用类型参数替换。比如 public void testWildCards(Collection&lt;?&gt; collection)&#123;&#125; 可以被 public &lt;T&gt; void test(Collection&lt;T&gt; collection)&#123;&#125; 取代。 值得注意的是，如果用泛型方法来取代通配符，那么上面代码中 collection 是能够进行写操作的。只不过要进行强制转换。 public &lt;T&gt; void test(Collection&lt;T&gt; collection)&#123; collection.add((T)new Integer(12)); collection.add((T)\"123\");&#125; 需要特别注意的是，类型参数适用于参数之间的类别依赖关系，举例说明。 public class Test2 &lt;T,E extends T&gt;&#123; T value1; E value2;&#125;public &lt;D,S extends D&gt; void test(D d,S s)&#123; &#125; E 类型是 T 类型的子类，显然这种情况类型参数更适合。有一种情况是，通配符和类型参数一起使用。 public &lt;T&gt; void test(T t,Collection&lt;? extends T&gt; collection)&#123;&#125; 如果一个方法的返回类型依赖于参数的类型，那么通配符也无能为力。 public T test1(T t)&#123; return value1;&#125; 类型擦除泛型是 Java 1.5 版本才引进的概念，在这之前是没有泛型的概念的，但显然，泛型代码能够很好地和之前版本的代码很好地兼容。 这是因为，泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做类型擦除。 通俗地讲，泛型类和普通类在 java 虚拟机内是没有什么特别的地方。回顾文章开始时的那段代码 List&lt;String&gt; l1 = new ArrayList&lt;String&gt;();List&lt;Integer&gt; l2 = new ArrayList&lt;Integer&gt;();System.out.println(l1.getClass() == l2.getClass()); 打印的结果为 true 是因为 List 和 List 在 jvm 中的 Class 都是 List.class。 泛型信息被擦除了。 可能同学会问，那么类型 String 和 Integer 怎么办？ 答案是泛型转译。 public class Erasure &lt;T&gt;&#123; T object; public Erasure(T object) &#123; this.object = object; &#125;&#125; Erasure 是一个泛型类，我们查看它在运行时的状态信息可以通过反射。 Erasure&lt;String&gt; erasure = new Erasure&lt;String&gt;(\"hello\");Class eclz = erasure.getClass();System.out.println(\"erasure class is:\"+eclz.getName()); 打印的结果是 erasure class is:com.frank.test.Erasure Class 的类型仍然是 Erasure 并不是 Erasure 这种形式，那我们再看看泛型类中 T 的类型在 jvm 中是什么具体类型。 Field[] fs = eclz.getDeclaredFields();for ( Field f:fs) &#123; System.out.println(\"Field name \"+f.getName()+\" type:\"+f.getType().getName());&#125; 打印结果是 Field name object type:java.lang.Object 那我们可不可以说，泛型类被类型擦除后，相应的类型就被替换成 Object 类型呢？ 这种说法，不完全正确。 我们更改一下代码。 public class Erasure &lt;T extends String&gt;&#123;// public class Erasure &lt;T&gt;&#123; T object; public Erasure(T object) &#123; this.object = object; &#125;&#125; 现在再看测试结果： Field name object type:java.lang.String 我们现在可以下结论了，在泛型类被类型擦除的时候，之前泛型类中的类型参数部分如果没有指定上限，如 则会被转译成普通的 Object 类型，如果指定了上限如 则类型参数就被替换成类型上限。 所以，在反射中。 public class Erasure &lt;T&gt;&#123; T object; public Erasure(T object) &#123; this.object = object; &#125; public void add(T object)&#123; &#125;&#125; add() 这个方法对应的 Method 的签名应该是 Object.class。 Erasure&lt;String&gt; erasure = new Erasure&lt;String&gt;(\"hello\");Class eclz = erasure.getClass();System.out.println(\"erasure class is:\"+eclz.getName());Method[] methods = eclz.getDeclaredMethods();for ( Method m:methods )&#123; System.out.println(\" method:\"+m.toString());&#125; 打印结果是 method:public void com.frank.test.Erasure.add(java.lang.Object) 也就是说，如果你要在反射中找到 add 对应的 Method，你应该调用 getDeclaredMethod(“add”,Object.class) 否则程序会报错，提示没有这么一个方法，原因就是类型擦除的时候，T 被替换成 Object 类型了。 类型擦除带来的局限性类型擦除，是泛型能够与之前的 java 版本代码兼容共存的原因。但也因为类型擦除，它会抹掉很多继承相关的特性，这是它带来的局限性。 理解类型擦除有利于我们绕过开发当中可能遇到的雷区，同样理解类型擦除也能让我们绕过泛型本身的一些限制。比如: public class Test &#123; public static void main(String[] args)&#123; List &lt;Integer&gt;list = new ArrayList&lt;&gt;(); list.add(100); list.add(\"一百零一\"); //编译错误 &#125;&#125; 正常情况下，因为泛型的限制，编译器不让最后一行代码编译通过，因为类似不匹配，但是，基于对类型擦除的了解，利用反射，我们可以绕过这个限制。 public interface List&lt;E&gt; extends Collection&lt;E&gt;&#123; boolean add(E e);&#125; 上面是 List 和其中的 add() 方法的源码定义。 因为 E 代表任意的类型，所以类型擦除时，add 方法其实等同于 boolean add(Object obj); 那么，利用反射，我们绕过编译器去调用 add 方法。 public class ToolTest &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; ls = new ArrayList&lt;&gt;(); list.add(100); // list.add(\"一百零一\"); //编译错误 try &#123; Method method = ls.getClass().getDeclaredMethod(\"add\",Object.class); method.invoke(ls,\"test\"); method.invoke(ls,42.9f); &#125; catch (NoSuchMethodException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (SecurityException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (IllegalArgumentException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; for ( Object o: ls)&#123; System.out.println(o); &#125; &#125;&#125; 打印结果是： 23test42.9 可以看到，利用类型擦除的原理，用反射的手段就绕过了正常开发中编译器不允许的操作限制。 泛型中值得注意的地方泛型类或者泛型方法中，不接受 8 种基本数据类型。所以，你没有办法进行这样的编码。 List&lt;int&gt; li = new ArrayList&lt;&gt;();List&lt;boolean&gt; li = new ArrayList&lt;&gt;(); 需要使用它们对应的包装类。 List&lt;Integer&gt; li = new ArrayList&lt;&gt;();List&lt;Boolean&gt; li1 = new ArrayList&lt;&gt;(); 对泛型方法中的困惑public &lt;T&gt; T test(T t)&#123; return null;&#125; 有的同学可能对于连续的两个 T 感到困惑，其实 是为了说明类型参数，是声明,而后面的不带尖括号的 T 是方法的返回值类型。你可以相像一下，如果 test() 这样被调用 test(\"123\"); 那么实际上相当于 public String test(String t); Java 不能创建具体类型的泛型数组这句话可能难以理解，代码说明。 List&lt;Integer&gt;[] li2 = new ArrayList&lt;Integer&gt;[];List&lt;Boolean&gt; li3 = new ArrayList&lt;Boolean&gt;[]; 这两行代码是无法在编译器中编译通过的。原因还是类型擦除带来的影响。 List 和 List 在 jvm 中等同于List ，所有的类型信息都被擦除，程序也无法分辨一个数组中的元素类型具体是 List类型还是 List 类型。 但是， List&lt;?&gt;[] li3 = new ArrayList&lt;?&gt;[10];li3[1] = new ArrayList&lt;String&gt;();List&lt;?&gt; v = li3[1]; 借助于无限定通配符却可以，前面讲过 ？ 代表未知类型，所以它涉及的操作都基本上与类型无关，因此 jvm 不需要针对它对类型作判断，因此它能编译通过，但是，只提供了数组中的元素因为通配符原因，它只能读，不能写。比如，上面的 v 这个局部变量，它只能进行 get() 操作，不能进行 add() 操作，这个在前面通配符的内容小节中已经讲过。 泛型，并不神奇我们可以看到，泛型其实并没有什么神奇的地方，泛型代码能做的非泛型代码也能做。 而类型擦除，是泛型能够与之前的 java 版本代码兼容共存的原因。 可量也正因为类型擦除导致了一些隐患与局限。 但，我还是要建议大家使用泛型，如官方文档所说的，如果可以使用泛型的地方，尽量使用泛型。 毕竟它抽离了数据类型与代码逻辑，本意是提高程序代码的简洁性和可读性，并提供可能的编译时类型转换安全检测功能。 类型擦除不是泛型的全部，但是它却能很好地检测我们对于泛型这个概念的理解程度。 我在文章开头将泛型比作是一个守门人，原因就是他本意是好的，守护我们的代码安全，然后在门牌上写着出入的各项规定，及“xxx 禁止出入”的提醒。但是同我们日常所遇到的那些门卫一般，他们古怪偏执，死板守旧，我们可以利用反射基于类型擦除的认识，来绕过泛型中某些限制，现实生活中，也总会有调皮捣蛋者能够基于对门卫们生活作息的规律，选择性地绕开他们的监视，另辟蹊径溜进或者溜出大门，然后扬长而去，剩下守卫者一个孤独的身影。 所以，我说泛型，并不神秘，也不神奇。","path":"2017/12/22/4264795803/","date":"12-22","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"解决 IDEA 打包输出缺少 mybatis 配置的 SQL 文件问题","text":"IDEA的maven项目中，默认源代码目录下的xml等资源文件并不会在编译的时候一同打包进classes文件夹，而是直接被舍弃掉。解决问题有两种方案： 第一种解决方案是建立src/main/resources文件夹，将xml等资源文件放置到这个目录中。maven工具默认在编译的时候，会将resources文件夹中的资源文件一同打包进classes目录中。 第二种解决方案是配置Maven的pom文件，在pom文件中找到&lt;build&gt;节点，添加下列代码： &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 其中src/main/java表明资源文件的路径，*/.xml表明需要编译打包的文件类型是xml文件，如果有其它资源文件也需要打包，可以修改或添加通配符。","path":"2017/12/22/2700866660/","date":"12-22","excerpt":"","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yihuishou.github.io/tags/IDEA/"}]},{"title":"SpringBoot 使用 Swagger2 生成接口说明","text":"swagger通过注解表明该接口会生成文档，包括接口名、请求方法、参数、返回信息的等等。 @Api：修饰整个类，描述Controller的作用@ApiOperation：描述一个类的一个方法，或者说一个接口@ApiParam：单个参数描述@ApiModel：用对象来接收参数@ApiProperty：用对象接收参数时，描述对象的一个字段@ApiResponse：HTTP响应其中1个描述@ApiResponses：HTTP响应整体描述@ApiIgnore：使用该注解忽略这个API@ApiError ：发生错误返回的信息@ApiParamImplicitL：一个请求参数@ApiParamsImplicit 多个请求参数 @Api：用在类上，说明该类的作用@ApiOperation：用在方法上，说明方法的作用@ApiImplicitParams：用在方法上包含一组参数说明@ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面paramType：参数放在哪个地方header–&gt;请求参数的获取：@RequestHeaderquery–&gt;请求参数的获取：@RequestParampath（用于restful接口）–&gt;请求参数的获取：@PathVariablebody（不常用）form（不常用）name：参数名dataType：参数类型required：参数是否必须传value：参数的意思defaultValue：参数的默认值@ApiResponses：用于表示一组响应@ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息code：数字，例如400message：信息，例如”请求参数没填好”response：抛出异常的类@ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用@ApiImplicitParam注解进行描述的时候）@ApiModelProperty：描述一个model的属性","path":"2017/11/14/766019691/","date":"11-14","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"目标：诺森德！","text":"诺森德后端： Java8 API Java14 API SpringBoot/SpringCloud Quartz Netty Mybatis OAuth2/Spring Scecrity Pagehelper &amp; tk.Mybatis Mybatis Plus Swagger2-ui Gson/JackJson Redis WebFlux SpringBoot 2.0 RocketMQ Dockers ELK(ElasticSearch + Logstash + Kibana) Kettle Disruptor Data 全家桶 Go 持续集成/自动部署： Gitlab Gogs 压力测试： runLoader 前端： ES6/ES7 Vue 3x Webpack Ant-design-Vue Ant-design-Vue-Pro AntV Node/Meteor Electron Google套餐： Go Flutter Dart BeeGo 移动： Flutter 常用业务： 消息推送（WebSocket） 分布式事务(2TC) 分布式事务(本地事物表) 分布式锁 全文搜索（Elasticsearch） 秒杀（消息队列） NoSQL（Redis/MongoDB） 异步操作（RxJava） 二维码（Google.zxing） 验证码（滑动） DI/CI（Docker） 无锁并发（Disruptor） 版本控制（Gitlab/Gitlab-CI）","path":"2017/11/14/946386629/","date":"11-14","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"Java 中判断字符串是否为纯数字","text":"用正则表达式首先要import java.util.regex.Pattern 和 java.util.regex.Matcher public boolean isNumeric(String str)&#123; Pattern pattern = Pattern.compile(\"[0-9]*\"); Matcher isNum = pattern.matcher(str); if( !isNum.matches() )&#123; return false; &#125; return true; &#125; 用JAVA自带的函数public static boolean isNumeric(String str)&#123; for (int i = 0; i &lt; str.length(); i++) &#123; System.out.println(str.charAt(i)); if (!Character.isDigit(str.charAt(i))) &#123; return false; &#125; &#125; return true;&#125; 判断ASCII码值public static boolean isNumeric0(String str)&#123; for(int i=str.length();--i&gt;=0;) &#123; int chr=str.charAt(i); if(chr&lt;48 || chr&gt;57) return false; &#125; return true; &#125; 捕获NumberFormatException异常public static boolean isNumeric00(String str)&#123; try&#123; Integer.parseInt(str); return true; &#125;catch(NumberFormatException e) &#123; System.out.println(\"异常：\\\"\" + str + \"\\\"不是数字/整数...\"); return false; &#125;&#125; 逐个判断str中的字符是否是0-9public static boolean isNumeric3(String str)&#123; final String number = \"0123456789\"; for(int i = 0;i &lt; number.length; i ++) &#123; if(number.indexOf(str.charAt(i)) == -1) &#123; return false; &#125; &#125; return true;&#125;","path":"2017/11/10/723704985/","date":"11-10","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Java 中的占位符","text":"一开始想到用占位符也是在使用sl4j框架时受到启发不用+号来拼接字符串真是very Cooooooool…… String类的format()方法用于创建格式化的字符串以及连接多个字符串对象。熟悉C语言的同学应该记得C语言的sprintf()方法，两者有类似之处。format()方法有两种重载形式。 format(String format, Object… args) 新字符串使用本地语言环境，制定字符串格式和参数生成格式化的新字符串。 format(Locale locale, String format, Object… args) 使用指定的语言环境，制定字符串格式和参数生成格式化的字符串。 显示不同转换符实现不同数据类型到字符串的转换，如图所示。 占 位 符 号 说 明 示 例 col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1","path":"2017/11/10/3226173500/","date":"11-10","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"我喜欢的排序算法","text":"鸡尾酒排序（双重冒泡排序）public static int[] cocktailSort(int[] src)&#123; //将最小值排到队尾 for(int i = 0 ; i &lt; src.length/2 ; i++) &#123; for(int j = i ; j &lt; src.length-i-1 ; j++) &#123; if(src[j] &lt; src[j+1]) &#123; int temp = src[j]; src[j] = src[j+1]; src[j+1] = temp; &#125; System.out.println(\"交换小\"+Arrays.toString(src)); &#125; //将最大值排到队头 for(int j = src.length-1-(i+1); j &gt; i ; j--) &#123; if(src[j] &gt; src[j-1]) &#123; int temp = src[j]; src[j] = src[j-1]; src[j-1] = temp; &#125; System.out.println(\"交换大\"+Arrays.toString(src)); &#125; System.out.println(\"第\"+i+\"次排序结果：\"+Arrays.toString(src)); &#125; return src;&#125; 希尔排序希尔排序严格来说是基于插入排序的思想，又被称为缩小增量排序。 具体流程如下： 1、将包含n个元素的数组，分成n/2个数组序列，第一个数据和第n/2+1个数据为一对… 2、对每对数据进行比较和交换，排好顺序； 3、然后分成n/4个数组序列，再次排序； 4、不断重复以上过程，随着序列减少并直至为1，排序完成。 对于插入排序而言，如果原数组是基本有序的，那排序效率就可大大提高。另外，对于数量较小的序列使用直接插入排序，会因需要移动的数据量少，其效率也会提高。因此，希尔排序具有较高的执行效率。 希尔排序并不稳定，O(1)的额外空间，时间复杂度为O(N*(logN)^2)。 public void sort(int[] arr) &#123; // i表示希尔排序中的第n/2+1个元素（或者n/4+1） // j表示希尔排序中从0到n/2的元素（n/4） // r表示希尔排序中n/2+1或者n/4+1的值 int i, j, r, tmp; // 划组排序 for(r = arr.length / 2; r &gt;= 1; r = r / 2) &#123; for(i = r; i &lt; arr.length; i++) &#123; tmp = arr[i]; j = i - r; // 一轮排序 while(j &gt;= 0 &amp;&amp; tmp &lt; arr[j]) &#123; arr[j+r] = arr[j]; j -= r; &#125; arr[j+r] = tmp; &#125; System.out.println(i + \":\" + Arrays.toString(arr)); &#125; &#125; 快速排序算法思想：基于分治的思想，是冒泡排序的改进型。首先在数组中选择一个基准点（该基准点的选取可能影响快速排序的效率，后面讲解选取的方法），然后分别从数组的两端扫描数组，设两个指示标志（lo指向起始位置，hi指向末尾)，首先从后半部分开始，如果发现有元素比该基准点的值小，就交换lo和hi位置的值，然后从前半部分开始扫秒，发现有元素大于基准点的值，就交换lo和hi位置的值，如此往复循环，直到lo&gt;=hi,然后把基准点的值放到hi这个位置。一次排序就完成了。以后采用递归的方式分别对前半部分和后半部分排序，当前半部分和后半部分均有序时该数组就自然有序了。 public static int partition(int []array,int lo,int hi)&#123; //固定的切分方式 int key=array[lo]; while(lo&lt;hi)&#123; while(array[hi]&gt;=key&amp;&amp;hi&gt;lo)&#123;//从后半部分向前扫描 hi--; &#125; array[lo]=array[hi]; while(array[lo]&lt;=key&amp;&amp;hi&gt;lo)&#123;从前半部分向后扫描 lo++; &#125; array[hi]=array[lo]; &#125; array[hi]=key; return hi; &#125; public static void sort(int[] array,int lo ,int hi)&#123; if(lo&gt;=hi)&#123; return ; &#125; int index=partition(array,lo,hi); sort(array,lo,index-1); sort(array,index+1,hi); &#125;","path":"2017/11/10/2230869343/","date":"11-10","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"SpringDataJPA 生成表列名的控制选项","text":"使用默认配置的SpringBoot的Jpa，自动建表的时候会将驼峰命名的Bean对象的属性 在数据库中格式化为xxx_xxx的形式。 修改配置文件中的spring.jpa.hibernate.naming.physical-strategy属性可以开启或关闭该功能 org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl不进行格式化 org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy进行格式化（默认使用） JPA 语义大全 关键字 示例 生成的SQL And findByLastnameAndFirstname … where x.lastname = ?1 and x.firstname = ?2 Or findByLastnameOrFirstname … where x.lastname = ?1 or x.firstname = ?2 Is,Equals findByFirstnameIs,findByFirstnameEquals … where x.firstname = ?1 Between findByStartDateBetween … where x.startDate between ?1 and ?2 LessThan findByAgeLessThan … where x.age &lt; ?1 LessThanEqual findByAgeLessThanEqual … where x.age &lt;= ?1 GreaterThan findByAgeGreaterThan … where x.age &gt; ?1 GreaterThanEqual findByAgeGreaterThanEqual … where x.age &gt;= ?1 After findByStartDateAfter … where x.startDate &gt; ?1 Before findByStartDateBefore … where x.startDate &lt; ?1 IsNull findByAgeIsNull … where x.age is null IsNotNull,NotNull findByAge(Is)NotNull … where x.age not null Like findByFirstnameLike … where x.firstname like ?1 NotLike findByFirstnameNotLike … where x.firstname not like ?1 StartingWith findByFirstnameStartingWith … where x.firstname like ?1 (parameter bound with appended %) EndingWith findByFirstnameEndingWith … where x.firstname like ?1 (parameter bound with prepended %) Containing findByFirstnameContaining … where x.firstname like ?1 (parameter bound wrapped in %) OrderBy findByAgeOrderByLastnameDesc … where x.age = ?1 order by x.lastname desc Not findByLastnameNot … where x.lastname &lt;&gt; ?1 In findByAgeIn(Collection ages) … where x.age in ?1 NotIn findByAgeNotIn(Collection age) … where x.age not in ?1 TRUE findByActiveTrue() … where x.active = true FALSE findByActiveFalse() … where x.active = false IgnoreCase findByFirstnameIgnoreCase … where UPPER(x.firstame) = UPPER(?1) 嵌套实体: findBy主实体中子实体的属性名称_子实体的属性名称 例如： List findByAddress_ZipCode(ZipCode zipCode) 表示查询所有 Address（地址）的 zipCode（邮编）为指定值的所有Person(人员，主实体) Bean类的注解 @Entity 声明一个类为实体Bean。 @Table 说明此实体类映射的表名，目录，schema的名字。 @Id 声明此表的主键。 @GeneratedValue 定义主键的增长策略。我这里一般交给底层数据库处理，所以调用了名叫generator的增长方式，由下边的@GenericGenerator实现 @GenericGenerator hibernate内部的主键增长方式 @UniqueConstraint 将对应的字段设置唯一性标识 (注：UniqueConstraint只在hibernate.hbm2ddl.auto设置为create-drop才会起作用) @Version 注解用于支持乐观锁版本控制。一般可以用 数字 或者 timestamp 类型来支持 version。 @Column 用于映射对应的字段,其中参数详解如下： 参数 说明 name = “columnName”; name 可选，列名(默认值是属性名) boolean unique() default false; unique 可选，是否在该列上设置唯一约束(默认值false) boolean nullable() default true; nullable 可选，是否设置该列的值可以为空(默认值true) boolean insertable() default true; insertable 可选，该列是否作为生成的insert语句中的一个列(默认值true) boolean updatable() default true; updatable 可选，该列是否作为生成的update语句中的一个列(默认值true) String columnDefinition() default “”; columnDefinition 可选，为这个特定列覆盖SQL DDL片段 (这可能导致无法在不同数据库间移植) String table() default “”; table 可选，定义对应的表(默认为主表) int length() default 255; length 可选，列长度(默认值255) int precision() default 0; precision 可选，列十进制精度(decimal precision)(默认值0) int scale() default 0; scale 可选，如果列十进制数值范围(decimal scale)可用,在此设置(默认值0) @Transient被注解成 @Transient 的 getter 方法或属性，将不会被持久化 @Basic所有没有定义注解的属性，等价于在其上面添加了 @Basic注解可以声明属性的获取策略 ( fetch strategy ) fetch:抓取策略,延时加载与立即加载，optional:指定在生成数据库结构时字段是否允许为 null. @Temporal在核心的 Java API 中并没有定义时间精度 ( temporal precision )。因此处理时间类型数据时，你还需要定义将其存储在数据库中所预期的精度。在数据库中，表示时间类型的数据有 DATE，TIME，和 TIMESTAMP 三种精度 ( 即单纯的日期，时间，或者两者兼备 )。 可使用 @Temporal 注解来调整精度。 第一种：@Temporal(TemporalType.DATE) 实体类会封装成日期“yyyy-MM-dd”的 Date类型。 第二种：@Temporal(TemporalType.TIME) 实体类会封装成时间“hh-MM-ss”的 Date类型。 第三种：@Temporal(TemporalType.TIMESTAMP) 实体类会封装成完整的时间“yyyy-MM-dd hh:MM:ss”的 Date类型。 @Index给某一字段加索引 如果视图是只读的，您应该使用 @Immutable 注解告诉 Hibernate。 然后它将忽略对该实体的所有更改。只读声明 JPA 规范的 @GeneratedValue 注解允许您定义用于创建唯一主键值的策略。您可以选择 SEQUENCE、IDENTITY、TABLE 和 AUTO。 一般来说，我建议使用 SEQUENCE 策略，因为它允许 Hibernate 使用 JDBC 批处理和其他需要延迟执行 SQL INSERT 语句的优化策略。 然而，您不能将此策略与 MySQL 数据库一起使用。因为它需要一个数据库序列，恰好 MySQL 不支持此功能。 因此，您需要在 IDENTITY 和 TABLE 之间进行选择。考虑到 TABLE 策略的性能和可扩展性问题，这很容易作出决定。 如果您正在使用 MySQL 数据库，则应始终使用 GenerationType.IDENTITY。它使用自动增量（autoincremented ）的数据库列，这是最有效的可用方法。 您可以通过使用 @GeneratedValue(strategy = GenerationType.IDENTITY) 注解主键属性来执行此操作。 Hibernate 5 中 GenerationType.AUTO 在旧版本中，Hibernate 为 MySQL 数据库选择 GenerationType.IDENTITY。 这是一个不错的选择。如之前所述，这是最有效的方法。 不幸的是此行为在 Hibernate 5 中发生了改变。现在是选择 GenerationType.TABLE，它使用数据库表来生成主键。 这种方法需要大量数据库查询和悲观锁来生成唯一值。 您可以通过定义一个 @GenericGenerator 来避免这一点，以下代码告诉 Hibernate 使用本地策略生成主键值。 @GenericGenerator(name = “native”, strategy = “native”) @Convert 属性转换器 需要一个现实 AttributeConverter 接口类的转换器，来在实体属性存取数据库时进行转换操作 AttributeConverter 的两个方法： convertToDatabaseColumn（X attribute）用于把输入的类型转成数据库存储的类型 convertToEntityAttribute (Y dbData) 用于把数据库搜出来的类型转成实体中想要的类型 为实体设置默认值的方法，直接在属性上给出初始值。@Column 的 columnDefinition 属性设置初始值仅在 表重新建立时生效 使用UUID做为主键的问题 将数据库中的主键，设置为varchar(32)。 在entity中类头部写入@GenericGenerator(name = “jpa-uuid”, strategy = “uuid”) 在entity中id主键顶部写入@GeneratedValue(generator = “jpa-uuid”)，注意generator中的值必须与注释@GenericGenerator中name属性完全一致。 设置entity中主键ID为string类型。设置长度为32 GenericGenerator是Hibernate中的注释，有两个参数。name是system-uuid“” ，策略strategy是uuid 。 @GenericGenerator支持13种策略，分别是： static &#123; GENERATORS.put(\"uuid\", UUIDHexGenerator.class); GENERATORS.put(\"hilo\", TableHiLoGenerator.class); GENERATORS.put(\"assigned\", Assigned.class); GENERATORS.put(\"identity\", IdentityGenerator.class); GENERATORS.put(\"select\", SelectGenerator.class); GENERATORS.put(\"sequence\", SequenceGenerator.class); GENERATORS.put(\"seqhilo\", SequenceHiLoGenerator.class); GENERATORS.put(\"increment\", IncrementGenerator.class); GENERATORS.put(\"foreign\", ForeignGenerator.class); GENERATORS.put(\"guid\", GUIDGenerator.class); GENERATORS.put(\"uuid.hex\", UUIDHexGenerator.class); //uuid.hex is deprecated GENERATORS.put(\"sequence-identity\", SequenceIdentityGenerator.class); &#125; 上面的12种策略，再加上native，一共是13种。 @GeneratedValue注解属于一个JPA接口（从JAVA EE 5开始，存在于javax.persistence包下），其接口下包含了两个抽象的参数，GenerationType类型的strategy和String类型的generator，并且两个参数都有相应的默认值。 GenerationType同样也位于javax.persistence包下，并且还继承了Enum枚举类，然后其中有4个值供我们使用，分别是：TABLE：使用一个特定的数据库表格来保存主键。SEQUENCE：根据底层数据库的序列来生成主键，条件是数据库支持序列。 这个值要与generator一起使用，generator 指定生成主键使用的生成器（可能是orcale中自己编写的序列）。IDENTITY：主键由数据库自动生成（主要是支持自动增长的数据库，如mysql）AUTO：主键由程序控制，也是GenerationType的默认值。 两个数据库对GenerationType的支持 mysqlGenerationType.TABLEGenerationType.AUTOGenerationType.IDENTITY不支持GenerationType.SEQUENCE oraclestrategy=GenerationType.AUTOGenerationType.SEQUENCEGenerationType.TABLE不支持GenerationType.IDENTITY","path":"2017/11/09/3649790665/","date":"11-09","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"Pojo 与 JavaBean 的理解","text":"POJO 和JavaBean是我们常见的两个关键字，一般容易混淆，POJO全称是Plain Ordinary Java Object / Pure Old Java Object，中文可以翻译成：普通Java类，具有一部分getter/setter方法的那种类就可以称作POJO，但是JavaBean则比 POJO复杂很多， Java Bean 是可复用的组件，对 Java Bean 并没有严格的规范，理论上讲，任何一个 Java 类都可以是一个 Bean 。但通常情况下，由于 Java Bean 是被容器所创建（如 Tomcat) 的，所以 Java Bean 应具有一个无参的构造器，另外，通常 Java Bean 还要实现 Serializable 接口用于实现 Bean 的持久性。 Java Bean 是不能被跨进程访问的。 POJO(Plain Old Java Object)这个名字用来强调它是一个普通java对象，而不是一个特殊的对象。 “POJO”主要用来指代那些没用遵从特定的Java对象模型，约定或框架如EJB的Java对象. 理想地讲，一个POJO是一个不受任何限制的Java对象（除了Java语言规范）。例如一个POJO不应该是 1.扩展预定的类，如 public class Foo extends javax.servlet.http.HttpServlet { … 2.实现预定的接口，如 public class Bar implements javax.ejb.EntityBean { … 3.包含预定的标注，如 @javax.ejb.Entity public class Baz{ … 然后，因为技术上的困难及其他原因，许多兼容POJO风格的软件产品或框架事实上仍然要求使用预定的标注，譬如用于更方便的持久化。 JavaBean 是一种JAVA语言写成的可重用组件。它的方法命名，构造及行为必须符合特定的约定： 1.这个类必须有一个公共的缺省构造函数。 2.这个类的属性使用getter和setter来访问，其他方法遵从标准命名规范。 3.这个类应是可序列化的。 因为这些要求主要是靠约定而不是靠实现接口，所以许多开发者把JavaBean看作遵从特定命名约定的POJO。 简而言之，当一个Pojo可序列化，有一个无参的构造函数，使用getter和setter方法来访问属性时，他就是一个JavaBean。 POJO VO TO BO DAO 各种O到底是个啥？ PO(persistant object) 持久对象在o/r映射的时候出现的概念，如果没有o/r映射，没有这个概念存在了。通常对应数据模型(数据库),本身还有部分业务逻辑的处理。可以看成是与数据库中的表相映射的java对象。最简单的PO就是对应数据库中某个表中的一条记录，多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。 VO(value object) 值对象通常用于业务层之间的数据传递，和PO一样也是仅仅包含数据而已。但应是抽象出的业务对象,可以和表对应,也可以不,这根据业务的需要.个人觉得同DTO(数据传输对象),在web上传递。 TO(Transfer Object)，数据传输对象在应用程序不同tie(关系)之间传输的对象 BO(business object) 业务对象从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法,结合PO,VO进行业务操作。 POJO(plain ordinary java object) 简单无规则java对象纯的传统意义的java对象。就是说在一些Object/Relation Mapping工具中，能够做到维护数据库表记录的persisent object完全是一个符合Java Bean规范的纯Java对象，没有增加别的属性和方法。我的理解就是最基本的Java Bean，只有属性字段及setter和getter方法！。 DAO(data access object) 数据访问对象是一个sun的一个标准j2ee设计模式，这个模式中有个接口就是DAO，它负持久层的操作。为业务层提供接口。此对象用于访问数据库。通常和PO结合使用，DAO中包含了各种数据库的操作方法。通过它的方法,结合PO对数据库进行相关的操作。夹在业务逻辑与数据库资源中间。配合VO, 提供数据库的CRUD操作…","path":"2017/10/31/2173211200/","date":"10-31","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"敏捷软件开发宣言","text":"敏捷软件开发宣言我们一直在实践中探寻更好的软件开发方法身体力行的同时也去帮助他人。由此我们建立了如下价值观： 个体和互动 高于 流程和工具 工作的软件 高于 详尽的文档 客户合作 高于 合同谈判 响应变化 高于 遵循计划 也就是说，尽管右侧的项目有其价值但我们更重视左侧项目的价值。 敏捷宣言遵循的十二条原则 我们最重要的目标，是通过持续不断地及早交付有价值的软件使客户满意。 欣然面对需求变化，即使在开发后期也一样。为了客户的竞争优势，敏捷过程掌控变化。 经常性地交付可工作的软件，相隔几星期或一两个月，倾向于采取较短的周期。 业务人员和开发人员必须相互合作，项目中的每一天都不例外。 激发个体的斗志，以他们为核心搭建项目。提供所需的环境和支援，辅以信任，从而达成目标。 不论团队内外，传递信息效果最好效率也最高的方式是面对面的交谈。 可工作的软件是进度的首要度量标准。 敏捷过程倡导可持续开发。责任人、开发人员和用户要能够共同维持其步调稳定延续。 坚持不懈地追求技术卓越和良好设计，敏捷能力由此增强。 以简洁为本，它是极力减少不必要工作量的艺术。 最好的架构、需求和设计出自自组织团队。 团队定期地反思如何能提高成效，并依此调整自身的举止表现。","path":"2017/10/31/3721925788/","date":"10-31","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"巴克斯·诺尔范式语法","text":"在双引号中的字&quot;word&quot;代表着这些字符本身。而double_quote用来代表双引号。 在双引号外的字（有可能有下划线）代表着语法部分。 尖括号&lt; &gt;内包含的为必选项。 方括号[ ]内包含的为可选项。 大括号{ }内包含的为可重复0至无数次的项。 竖线|表示在其左右两边任选一项，相当于”OR”的意思。 这样一串符号::= 是“被定义为”的意思。 在学习SQL语言的时候经常可以见到这种形式。","path":"2017/10/31/3823926681/","date":"10-31","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"SpringBoot 解决无法访问静态资源的问题","text":"在使用SpringBoot的thymeleaf时，向往常一样编写了&lt;a href=&quot;xxx&quot;&gt;xxx&lt;/a&gt;的超链接。 结果404错误爆炸。还以为自己链接写错了，改得我差点怀疑人生。 度娘了一下发现是SpringBoot本身的配置问题。 在对application.yml文件进行如下配置后，顺利解决了无法访问静态资源的问题。 mvc: static-path-pattern: /** resources: static-locations: classpath:/static/,classpath:/public/,classpath:/templates/,classpath:/resources/,classpath:/META-INF/resources/ 顺带记录一下SpringBoot经典的标签闭合错误问题。默认配置的SpringBoot使用Thymeleaf渲染页面的模式是HTML5 在该模式中Thymeleaf会严格遵循HTML5标准,非闭合标签会导致页面渲染失败。(比如用IDEA新建的HTML页面的Mate标签就没有闭合)。 解决这个问题需要引入第三方工具并修改Thymeleaf的渲染模式。 thymeleaf: mode: LEGACYHTML5 pom.xml 添加下面的依赖 &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt;&lt;/dependency&gt;","path":"2017/10/30/4109869837/","date":"10-30","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot 整合 Mybatis 爬坑之路","text":"最近一直在学习SpringBoot的相关内容，在整合Mybaits的时候踩了个大坑。 尤其是使用了IDEA编辑器，而且还使用了由IDEA生成的目录结构的情况下。我这两个都赶上了… 这个坑的原理其实也很简单： IDEA在编译程序的时候是不会把标记为源码目录中的静态资源文件发布出去的… 所以，要是像在eclipse中那样把Mybatis的mapper文件和源码放在同一目录中的话,就会导致下面的错误： 也就是Mybaits无法找到mapper的错误。 解决办法有两种： 1.将mapper文件放到resource资源目录中，然后修改SpringBoot的配置文件 mybatis.mapper-locations: classpath:xxx/*.xml 重新指定SpringBoot的扫描目录 2.直接使用Mybatis的注解方式进行mapper配置则不会触发上面的问题 3.在pom配置文件中添加打包配置 [java] view plain copy&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;","path":"2017/10/23/618326027/","date":"10-23","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"汉化 IDEA 的各种坑","text":"因为换上了IDEA作为主要IDE，所以就想找个汉化版的用用。但是网络上没有完整的汉化包， 而且汉化包版本兼容问题又导致在新版的IDEA中产生了各种各样的奇葩效果。。。 所以就只好自己动手去进行汉化了。 在这里记录一下汉化中的各种大坑小坑(/ω＼) 搜寻汉化文件基本是基于网上流传的汉化包进化汉化，用的IDE自然就是DIEA自己了 主要汉化的文件是安装目录中lib目录下的resource_en.jar文件。这个文件包含了英文原版的语言信息。 在resource_en.jar文件中的message目录中包含了绝大部分的语言配置信息(也就是那一堆.porperties文件) 这些语言配置文件以键值对的形式保存了显示在界面的语言信息。所以汉化这些配置文件即可产生汉化效果。 注意要转换成unicode的中文ascii码才行。但是，并不是所有的信息都包含在jar包中。有些汉化的键值并不能正常工作， 甚至会让原本的功能失效,比如汉化了git显示历史记录功能的部分，就会导致显示git历史记录功能失效。后来根据研究， 发现plugs中部分插件也带有resource.jar这种语言包。推测主界面的大部分语言是根据resource_en.jar中显示的 但是具体功能部分的显示可能在相应插件中的resource.jar包中。 让汉化包正常工作这部分是在使用汉化包时发现的问题。一般在汉化包不兼容的版本强行在lib目标中插入汉化包将有可能导致主程序不能正常工作 稳妥的方式是将汉化过的配置文件替换掉原版的配置文件。也就是对原版的resource_en.jar包进行修改。 这样虽然能解决大部分的兼容问题。但是一些版本新增或去除的功能，还是会由于兼容性问题而不能正常工作。 在调查了其他的汉化包之后发现在配置文件添加语言类后缀，可以让IDEA优先加载该配置文件 如果配置文件中找不到的项目IDEA会自动加载原版的配置文件。以这种方正进行汉化的话，应该能提高一下版本的兼容性吧。 2020官方汉化官方出中文汉化了，走的是插件扩展路线","path":"2017/10/18/2023601047/","date":"10-18","excerpt":"","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yihuishou.github.io/tags/IDEA/"}]},{"title":"如何使用 IDEA 打包 JavaFX 为 exe 程序","text":"起因最近想要做一个桌面小程序，看着Java8 有推荐使用JavaFX来代替老旧的AWT或Swing。于是便准备使用JavaFX来做。 程序初步完成之后，缺发现在网上到处都找不到打包成exe的办法。（PS：后来想了想，其实先打包成Jar再用exe4J也行……） 无奈只好翻墙去问问神奇的Google，在Youtube上发现了解决办法，于是在此记录下来。 首先添加为JavaFX项目添加对象在项目上按F4进入当前项目配置界面，在Artifact 中点击+添加一个新的Artifact JavaFX Application -&gt; from module xxx 配置新添加的对象来输出exe程序选中新增的Artifact对象，找到JavaFX选项卡 选择程序的入口Application class 修改Native bundle为all 重新生成新的对象重新生成对象,菜单中选择Build Artifacts... 找到新添加的 Artifact -&gt; Rebuild","path":"2017/10/13/4032644071/","date":"10-13","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"解决用 exe4J 封装的 SpringBoot 应用无法运行的问题","text":"因为SpringBoot生成的Jar包应用内置了Tomcat服务器，所以我们在Windows系统下希望可以通过直接运行.exe程序来启动应用。当然这就需要使用exe4J来对Jar包进行封装。 但是封装成功之后运行缺通常会产生如下的错误： java.lang.NoClassDefFoundError: BOOT-INF/classes/com/example/DemoApplication (wrong name: com/example/DemoApplication) at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:467) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at com.exe4j.runtime.LauncherEngine.launch(LauncherEngine.java:59) at com.exe4j.runtime.WinLauncher.main(WinLauncher.java:101) 这是因为我们在用exe4J封装时，选择的main类往往是我们应用的启动类，就是带有@SpringBootApplication的那个。 但是实际上真正的启动类应该是org.springframework.boot.loader.JarLauncher。所以才会产生上面那样的错误。 所以解决办法很简单，就是在使用exe4J封装SpringBoot时，main类选择org.springframework.boot.loader.JarLauncher就好了。","path":"2017/10/12/691142694/","date":"10-12","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot 部署 Jar 包时乱码的解决办法","text":"在执行命令前追加-Dfile.encoding=UTF-8参数，来设置程序启动的字符集便可解决乱码问题。 关于-Dfile.encoding的解释：在命令行中输入java，在给出的提示中会出现-D的说明：-D= # set a system property-D后面需要跟一个键值对，作用是设置一项系统属性对-Dfile.encoding=UTF-8来说就是设置系统属性file.encoding为UTF-8那么file.encoding 什么意思？字面意思为文件编码。搜索java源码，只能找到 4 个文件中包含file.encoding的文件，也就是说，只有四个文件调用了file.encoding这个属性。在java.nio.charset包中的Charset.java中，这段话的意思说的很明确了。简单说就是默认字符集是在java虚拟机启动时决定的，依赖于java虚拟机所在的操作系统的区域以及字符集。代码中可以看到，默认字符集就是从file.encoding这个属性中获取的。","path":"2017/10/11/250328113/","date":"10-11","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"Thymeleaf 中JavaScript 如何获取后台传入的值","text":"使用隐藏域的属性获取例如用js获取指定ID隐藏域的值： &lt;input type=\"hidden\" th:value=\"$&#123;session.user.name&#125;\" id=\"username\"/&gt; &lt;script type=\"text/javascript\"&gt; function test()&#123; var user = document.getElementById(\"username\").value; alert(user); &#125;&lt;/script&gt; 使用脚本内联获取Thymeleaf提供了一系列的“脚本”的内联功能,这样你就可以将你的数据传入到你自己的脚本中。 注意：只有加入了th:inline=”javascript”属性的js代码中，才能能使用[[…]] &lt;script th:inline=\"javascript\"&gt; function test()&#123; var user = [[$&#123;user.username&#125;]]; alert(user); &#125;&lt;/script&gt; 关于内联表达式[[…]]之间的表达式在Thymeleaf中被认为是内联表达式,在其中你可以使用任何类型的表达式,也会产生有效的th:text属性。 例如下面的代码： Hello, [[$&#123;session.user.name&#125;]]! 等同于： Hello, &lt;span th:text=\"$&#123;session.user.name&#125;\"&gt;I`m user&lt;/span&gt;! 为了让内联表达式能正确工作,我们必须使用th:inline 属性来激活它,它有三个可选的模式(text, javascript 和 none )。 &lt;p th:inline=\"text\"&gt;Hello, [[$&#123;session.user.name&#125;]]!&lt;/p&gt; 如果不使用th:inline=&quot;text&quot;,则会直接被当做字符串来显示。th:inline=&quot;javascript&quot;表示能在js中使用[[…]]的值, 而th:inline=&quot;none&quot;表示不进行任何处理直接显示。 最后,标签的th:inline属性不一定需要在本级标签内，任何父标签都行，例如下面的代码也是可以的： &lt;body th:inline=\"text\"&gt; ... &lt;p&gt;Hello, [[$&#123;session.user.name&#125;]]!&lt;/p&gt; ...","path":"2017/10/09/159298361/","date":"10-09","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"对 Java 日志的改造","text":"自从开始使用日志组件后， 每个类都是这样子的结构: public class A &#123; public static final Logger logger = LoggerFactory.getLogger(A.class);&#125; 但是每个使用日志的类都要加上这么一段，绝对是个让人心烦的问题。 于是我们开始想要定义这样一个静态工具类： public class Logger &#123; private static final org.slf4j.Logger logger = LoggerFactory.getLogger(Logger.class); ... public static void debug(...) &#123; logger.debug(...); ... &#125; ...&#125; 这样我们就可以在其他类里用直接Logger.debug(&quot;test&quot;);来输出日志了。一切看起来都很美好， 但经过测试之后发现这种方法会有一个很严重的问题：我们打印的日志通常都会带有调用方的信息， 比如类名、方法名、行号、等信息。其中类名、方法名、行号都是极其关键的信息，然而使用上述的方法输出的日志中，这三个信息都变成了Logger这个类的信息，而不是真正调用者的信息， 这样的错误显然是让人无法忍受的事情。 当然不能就这样了事，既然平时使用日志的方法都能输出正确的信息，那么肯定是有办法可以解决的。我们希望最终输出的日志信息都是完全正确的。 我们发现平时使用的Log4j能准确捕获源代码的所在的类、方法、行。但java并没有提供相应的方法，这似乎很神奇。其实Log4j是通过java错误堆栈来实现的，也就是说通过new一个异常Throwable，然后再捕获，从而得到堆栈信息，在进行分析就可以得到行号等信息了。 所以，我们提出像log4j那样，抛出一个异常，然后捕获分析，从而在我们自己的静态日志工具里实现源代码定位，但是这样就多抛出了一次异常，效率肯定变低了。而且抛出异常过多，引发额外事故的风险也是个大问题。不管怎么说，这毕竟是一个思路，在尝试着寻找其他能得到堆栈信息的方法时，最后在Thread类中找到了一个getStackTrace()方法可以替代抛出异常的解决办法。顺便一提，这个方法是jdk1.5版本以后才有的。 import org.slf4j.LoggerFactory;/** * Logs日志工具类 * 若要自定义可配置打印出执行的方法名和执行行号位置等信息，请修改生成logger对象的方法 */public class Logs &#123; // 本日志类名 private final static String logClassName = Logs.class.getName(); /** * 获取最原始被调用的堆栈信息 */ private static StackTraceElement getCaller() &#123; // 获取堆栈信息 StackTraceElement[] traceElements = Thread.currentThread().getStackTrace(); if (null == traceElements) &#123; return null; &#125; // 最原始被调用的堆栈信息 StackTraceElement caller = null; // 循环遍历到日志类标识 boolean isEachLogFlag = false; // 遍历堆栈信息，获取出最原始被调用的方法信息 for (StackTraceElement element : traceElements) &#123; // 遍历到日志类 if (element.getClassName().equals(logClassName)) &#123; isEachLogFlag = true; &#125; // 下一个非日志类的堆栈，就是最原始被调用的方法 if (isEachLogFlag) &#123; if (!element.getClassName().equals(logClassName)) &#123; caller = element; break; &#125; &#125; &#125; return caller; &#125; /** * 自动匹配请求类名，生成logger对象 */ private static org.slf4j.Logger log() &#123; // 最原始被调用的堆栈对象 StackTraceElement caller = getCaller(); // 空堆栈处理 if (caller == null) &#123; return LoggerFactory.getLogger(Logs.class); &#125; // 与springboot默认显示日志相同，只显示类名 return LoggerFactory.getLogger(caller.getClassName()); &#125; /* * 下列是封装后的方法 * */ public static void debug(String message) &#123; log().debug(message); &#125; public static void debug(String message, Throwable exception) &#123; log().debug(message, exception); &#125; public static void debug(String message, Object object) &#123; log().debug(message, object); &#125; public static void debug(String message, Object... object) &#123; log().debug(message, object); &#125; public static void info(String message) &#123; log().info(message); &#125; public static void info(String message, Throwable exception) &#123; log().info(message, exception); &#125; public static void info(String message, Object object) &#123; log().info(message, object); &#125; public static void info(String message, Object... object) &#123; log().info(message, object); &#125; public static void error(String message) &#123; log().error(message); &#125; public static void error(String message, Throwable exception) &#123; log().error(message, exception); &#125; public static void error(String message, Object object) &#123; log().error(message, object); &#125; public static void error(String message, Object... object) &#123; log().error(message, object); &#125; public static void warn(String message) &#123; log().warn(message); &#125; public static void warn(String message, Throwable exception) &#123; log().warn(message, exception); &#125; public static void warn(String message, Object object) &#123; log().warn(message, object); &#125; public static void warn(String message, Object... object) &#123; log().warn(message, object); &#125;&#125;","path":"2017/10/09/3227681912/","date":"10-09","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://yihuishou.github.io/tags/Java/"}]},{"title":"<![CDATA[]]>和转义字符","text":"CDATA是XML标记语言的语法成分，代表‘字符数据’ Character Data。被&lt;![CDATA[…]]&gt;这个标记所包含的内容将表示为纯文本，比如&lt;![CDATA[&lt;]]&gt;表示文本内容&lt;。此标记用于xml文档中，我们先来看看使用转义符的情况。我们都知道，在xml中，&lt;、&gt;、&amp;等字符是不能直接写入的。否则xml语法检查时将会报错，如果想在xml中使用这些符号，就必须将其转义为实体，如&amp;lt;、&amp;gt;、&amp;amp;这样才能写入到xml文档中。 在使用程序读取xml文档的时候，解析器会自动将这些实体转换回&lt;、&gt;、&amp;。 举个例子： &lt;age&gt; age &lt; 30 &lt;/age&gt;上面这种写法会报错，正确的写法应该是这样：&lt;age&gt; age &amp;lt; 30 &lt;/age&gt; 需要注意的是： (1) 转义字符之间不能有空格；(2) 转义字符必须以;结束；(3) 单独出现的&amp;不会被认为是转义的开始；(4) 转义字符区分大小写。 在XML中，需要转义的字符有： (1)&amp; &amp;amp;(2)&lt; &amp;lt;(3)&gt; &amp;gt;(4)＂ &amp;quot;(5)＇ &amp;apos; 但是严格来说，在XML中只有&lt;和&amp;是非法的，其它三个都是可以合法存在的，但是，把它们都进行转义是一个好习惯。不管怎么样，转义前的字符也好，转义后的字符也好，都会被xml解析器解析，为了方便起见，使用&lt;![CDATA[]]&gt;来包含不需要被 xml解析器解析的内容。 但要注意的是：(1) 此部分不能再包含]]&gt;；(2) 不允许嵌套使用；(3) ]]&gt;这部分不能包含空格或者换行。 最后，&lt;![CDATA[]]&gt;和xml转移字符的功能是一样的，只是应用场景和需求有些不同： (1) &lt;![CDATA[]]&gt;不能适用所有情况，转义字符可以；(2) 对于短字符串&lt;![CDATA[]]&gt;写起来比较啰嗦，对于长字符串转义字符写起来可读性差；(3) &lt;![CDATA[]]&gt;表示xml解析器忽略解析，所以解析的速度更快。","path":"2017/09/30/740759514/","date":"09-30","excerpt":"","tags":[{"name":"Xml","slug":"Xml","permalink":"https://yihuishou.github.io/tags/Xml/"}]},{"title":"代码一定会变烂","text":"这篇全是网上写的，不过可以很好的解释一个面试问题。 面试的时候通常会被问这么一个问题：你为什么离职？ 其中有不少人会提到这么一个原因，现在的项目代码太烂了，前人留下了很多坑，我实在忍受不了了。 这个原因显得未免太不职业了，而且可能把工作想的太过于理想化了。如果因为代码很烂就离职，那么你跳槽到下一个公司依然会面对同样的现状，因为几乎每个人，都会觉得自己公司的项目代码很烂。 我们先说说造成这种现象的原因是什么，首先，我们得相信，没有任何一个人故意把自己的代码写的很烂，每个人都想把自己的代码写的很优雅，扩展性很好，但是可能当初水平不够，在当时看似还不错的代码，日后在别人看来就是所谓的垃圾代码，我们每个人都在进步，别说别人了，你现在看你三个月之前的代码，可能你都会觉得写的很垃圾，如果你没有这种感觉，只能说你在止步不前。 其次，技术更新换代太快，市场的变化也太快，产品自然也一直在演变，也许在当时看起来还不错的代码，随着时间的推移，功能的更新，代码的堆彻，慢慢就变成后来者眼中的烂代码了。 也许你说，我跳到一个新的公司，做一个全新的产品，就不用忍受那些垃圾代码了，我有信心把架构设计的非常牛逼，为之后做足够的扩展性考虑，我只能说你想的过于理想化了，我们永远没法预测未来，随着需求与市场的变化，我们的功能一直在迭代，我们的产品也一直在变化，你会发现很可能你之前花了很多心思设计的架构，完全被推翻了，尤其在新产品刚推出的阶段，这是一个快速验证快速迭代的阶段，你的理想化的技术性思维，对产品没有任何帮助，随着产品的更新迭代，代码的不断增加组合，慢慢的你就会发现，你的那些优雅的代码设计，很可能就是你自己口中的烂代码，这是一个必然的结果。 这里也衍生出一个问题，在产品的初期，不要过多的考虑架构设计、性能优化之类的，先把主要精力把功能实现，把产品的体验提升上去，技术人总是沉醉于先把自己的代码写的完美，其实殊不知，产品能不能成还是一回事呢，先实现再优化，是当今快速发展的互联网市场最基本的原则。但是你也没必要故意把代码写的很烂，想着以后单独抽时间去做重构，我以一个过来人的经验告诉你，给你单独的留出时间去做重构几乎不可能。 所以，如果一家公司各方面发展还不错，仅仅因为代码很烂就离职，跳槽到了另一家公司很可能更糟，而且越是成熟的产品，代码遗留问题就越多，包括 Google、BAT 等大型互联网公司依然如此，如果你觉得这家公司还不错，想一起发展下去，代码很烂的话那就试图去改变一下，给你单独的时间去做重构很难，那就一边开发功能一边重构，一边迭代一边优化，在不影响产品迭代的情况下，尝试着去做些力所能及的改变，在这个过程中你会发现，其实你也在慢慢的成长。 大部分人其实都在抱怨环境，只有极少数人会去做点改变，哪怕这些改变微不足道，有些时候，你很可能会因为这些微不足道的改变，得到一些更好的机会。","path":"2017/09/30/4153119184/","date":"09-30","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"喵喵颜文字","text":"ฅ’ω’ฅ ค(TㅅT)ค ฅ(๑˙o˙๑) ฅ•ω • ฅ&gt;ω&lt;*ฅ (｡・`ω´･) (｡ ・ω・) ฅ( ̳• ◡ • ̳)ฅ (Φ ω Φ) (/ω＼) (/ω・＼) (′・ω・`) (｡･ω･｡)ﾉ♡ (⁄⁄•⁄ω⁄•⁄⁄) (*・ω・) (ฅ&gt;ω&lt;*ฅ) (ಡωಡ) _(:з」∠) (〃ω〃)","path":"2017/09/29/2754764057/","date":"09-29","excerpt":"","tags":[{"name":"随笔","slug":"随笔","permalink":"https://yihuishou.github.io/tags/随笔/"}]},{"title":"SpringBoot 在 IDEA 中实现静态资源热部署","text":"SpringBoot项目在IDEA开发环境下开启热部署调试引入插件在项目中引入maven依赖插件spring-boot-devtools &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 配置项目启动设置使用快捷键Ctrl+Alt+Shift+/调出当前项目的启动设置 选择1.Registry 找到compiler.automake.allow.when.app.running的值 设置为true 开启项目自动编译使用快捷键Ctrl+Alt+Shift+s调出当前项目全局配置 在 Build,Execution,Deployment -&gt; Complier -&gt; Build project automatically 中 勾选改选项启用自动编译功能","path":"2017/09/28/381957246/","date":"09-28","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://yihuishou.github.io/tags/SpringBoot/"}]},{"title":"关于 Mdui 主题中的一些设置问题","text":"如何关闭文章尾部的下载链接？在文章头部中设置export_md: false title: xxxxxxexport_md: false 如何解决代码高亮渲染失效的问题？安装代码渲染器时指定为1.6.0版本 npm install prismjs@1.6.0 --save 如何消除生成页面时的警告信息例如执行hexo d或hexo g命令时会产生如下警告信息 WARN Partial ../_custom/custom_head does not exist. (in _partials/head.ejs)WARN Partial ../_custom/custom_js does not exist. (in _partials/import_js.ejs) 解决办法： 在mdui/layout/_custom目录下新建两个空文件custom_head.ejs和custom_js.ejs即可让警告消失 自定义侧边栏的修改说明在主题配置文件_config.yml中找到如下的设置 pages: 我の朋友们: link: &quot;/friends&quot; md: &quot;home&quot; 画廊: link: &quot;/画廊&quot; fa: &quot;fa-child&quot; 时间线: link: &quot;/timeline&quot; md: &quot;home&quot; 展厅: cascade: true md: &apos;home&apos; pages: 第一个: link: &quot;/画廊&quot; fa: &quot;fa-child&quot; 第二个: link: &quot;/另一个画廊&quot; md: &quot;home&quot; 其中我の朋友们是自定义侧边栏的中菜单显示的内容 link为指向的链接，md和fa表示菜单中显示的图标 cascade为是否启用二级菜单 如何自定义页面使用hexo new -&gt; page -&gt; 页面名称 命令 来创建自定义页面 如何使用画廊与展厅 ( 其实就是相册 ovo )创建画廊首先使用hexo new -&gt; page -&gt; 页面名称 命令 来创建一个自定义页面 在创建的页面头中添加layout: gallery 来声明该页面是一个画廊 ---title: 画廊date: 2017-09-28 09:15:23layout: gallery--- 向画廊中添加图片在画廊的头部中添加如下代码 photos: 显示的图片名: img: 图片地址 descr: '这里是图片描述' 最后整体的代码应该是下面这个样子 ---title: 画廊date: 2017-09-28 09:15:23layout: galleryphotos: a: img: /img/bg.png descr: &apos;这里是图片描述&apos; b: img: /img/bg.png descr: &apos;这里是图片描述&apos; c: img: /img/bg.png descr: &apos;这里是图片描述&apos; d: img: /img/bg.png descr: &apos;这里是图片描述&apos; e: img: /img/bg.png descr: &apos;这里是图片描述&apos; f: img: /img/bg.png descr: &apos;这里是图片描述&apos;--- 使用画廊在展厅的配置文件/source/_data/galleries.yml中，将link指向画廊 或者在自定义侧边栏的菜单中，将菜单的link指向画廊 创建展厅首先使用hexo new -&gt; page -&gt; 页面名称 命令 来创建一个自定义页面 在创建的页面头中添加layout: galleries 来声明该页面是一个画廊 ---title: 展厅date: 2017-09-28 09:18:00layout: galleries--- 创建展厅配置文件并进行配置首先在/source/_data/中创建展厅配置文件galleries.yml 在配置文件中添加如下代码 画廊: link: /example1 descr: 相册描述或其他文字 bg: /img/bg.png logo: /img/bg.png另一个画廊: link: /example2 descr: 相册描述或其他文字 bg: /img/bg.png logo: /img/bg.png其他画廊: link: /example3 descr: 相册描述或其他文字 bg: /img/bg.png logo: /img/bg.png 其中link为画廊的地址descr为展厅中该画廊的描述bg为展厅中该画廊的封面图片logo为展厅中该画廊的圆形Logo 使用展厅和单画廊一样在，在自定义侧边栏的菜单中，将菜单的link指向展厅","path":"2017/09/27/3303306385/","date":"09-27","excerpt":"","tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://yihuishou.github.io/tags/Hexo/"}]}]}